{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final GB Polyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obsk/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16, VGG19, InceptionV3, InceptionResNetV2\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from imgaug import augmenters as iaa\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = (10, 10)#(30, 20) \n",
    "\n",
    "target_width = 299\n",
    "target_height = 299\n",
    "target_size = (target_width, target_height)\n",
    "batch_size = 256\n",
    "transfer_learning_epochs = 1000\n",
    "fine_tuning_epochs = 200\n",
    "train_set_size = 4137\n",
    "validation_set_size = 1033\n",
    "test_set_size = 885\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.0001\n",
    "decay = 0.0001\n",
    "\n",
    "# jarvis\n",
    "#data_dir = '/sdb1/share/gbpolyp/final_data'\n",
    "#work_dir = '/home/jarvis/workspace/gbpolyp'\n",
    "#profundus\n",
    "data_dir = '/share/gbpolyp/final_data'\n",
    "work_dir = '/home/obsk/workspace/gbpolyp'\n",
    "# abdomen\n",
    "#data_dir = '/home/ubuntu/workspace/share/gbpolyp/final_data'\n",
    "#work_dir = '/home/ubuntu/workspace/gbpolyp'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'validation')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "csv_file = os.path.join(data_dir, 'clinical_data.csv')\n",
    "\n",
    "pretrained_wt_dir = os.path.join(work_dir, 'pretrained_wt')\n",
    "log_dir = os.path.join(work_dir, 'log')\n",
    "\n",
    "image_checkpoint_path = os.path.join(pretrained_wt_dir, '1591-0.8519.hdf5')\n",
    "clinical_data_checkpoint_path = os.path.join(pretrained_wt_dir, 'clinical_data_weights.hdf5')\n",
    "ensemble_checkpoint_path = os.path.join(pretrained_wt_dir, '618-0.8858.hdf5')\n",
    "\n",
    "# Augmentation parameters\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    iaa.Multiply((0.9, 1.1)),\n",
    "    iaa.Affine(\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, #{\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, \n",
    "        rotate=(-40, 40),\n",
    "        shear=(-20, 20),\n",
    "        order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "        cval=0,\n",
    "        mode='edge'#['constant', 'edge']\n",
    "    ),\n",
    "    iaa.OneOf([\n",
    "        iaa.GaussianBlur((0, 3.0)),\n",
    "        iaa.AverageBlur(k=(2, 7)),\n",
    "        iaa.Sharpen(alpha=(0, 0.1), lightness=(0.75, 1.5))\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_smoothly(history):\n",
    "    def smooth_curve(points, factor=0.8):\n",
    "      smoothed_points = []\n",
    "      for point in points:\n",
    "        if smoothed_points:\n",
    "          previous = smoothed_points[-1]\n",
    "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "          smoothed_points.append(point)\n",
    "      return smoothed_points\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
    "def auc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n",
    "\n",
    "def plot_learning_rate(epochs, learning_rate, decay):\n",
    "    epoch_list = [i+1 for i in range(epochs)]\n",
    "    lr_list = []\n",
    "    for epoch in range(epochs):\n",
    "        learning_rate = learning_rate * 1/(1 + decay * epoch)\n",
    "        lr_list.append(learning_rate)\n",
    "\n",
    "    plt.plot(epoch_list, lr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, is_train=False):\n",
    "    x /= 255.\n",
    "#    x -= 0.5\n",
    "#    x *= 2.\n",
    "    \n",
    "    if is_train: x = seq.augment_images(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def get_input(file_path):\n",
    "    img = image.load_img(file_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_output(path):\n",
    "    class_name = os.path.basename(os.path.dirname(path))\n",
    "    if class_name == 'neoplastic':\n",
    "        labels = 1\n",
    "    else:\n",
    "        labels = 0\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_data(file_path, df):\n",
    "    # img\n",
    "    img = image.img_to_array(image.load_img(file_path, target_size=target_size))\n",
    "\n",
    "    # num\n",
    "    name = os.path.basename(file_path)[:-9]\n",
    "    try:\n",
    "        size = df[df['name']==name].iloc[0]['size']\n",
    "        multiplicity = df[df['name']==name].iloc[0]['multiplicity']\n",
    "        age = df[df['name']==name].iloc[0]['age']\n",
    "    except IndexError:\n",
    "        print(name)\n",
    "        size = 0\n",
    "        multiplicity = 0\n",
    "        age = 0\n",
    "    num = (size, multiplicity, age)\n",
    "    \n",
    "    # label\n",
    "    class_name = os.path.basename(os.path.dirname(file_path))\n",
    "    if class_name == 'neoplastic':\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    \n",
    "    return img, num, label\n",
    "\n",
    "    \n",
    "def custom_generator(file_list, data_frame, batch_size=batch_size, target_size=target_size, is_train=False, non_image_data=False):\n",
    "    if is_train: shuffle(file_list)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        if i+batch_size < len(file_list):\n",
    "            batch_paths = file_list[i:i+batch_size]\n",
    "        else:\n",
    "            batch_paths = file_list[i:]\n",
    "            \n",
    "        img_list = []\n",
    "        num_list = []\n",
    "        label_list = [] \n",
    "          \n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for file_path in batch_paths:\n",
    "            (img, num, label) = get_data(file_path, df)\n",
    "            #img = get_input(input_path)\n",
    "            #label = get_output(input_path)\n",
    "            img_list.append(img)\n",
    "            num_list.append(num)\n",
    "            label_list.append(label)\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        batch_img = preprocess_input(np.array(img_list), is_train)\n",
    "        batch_num = np.array(num_list)\n",
    "        batch_label = np.array(label_list)\n",
    "        \n",
    "        if i+batch_size >= len(file_list):\n",
    "            i = 0\n",
    "        else:\n",
    "            i = i+batch_size\n",
    "        \n",
    "        if non_image_data:\n",
    "            yield ([batch_img, batch_num], batch_label)\n",
    "        else:\n",
    "            yield (batch_img, batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['name'] = df['name'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "\n",
    "    d1 = df[df['test']==0]\n",
    "\n",
    "    size_mean = d1['size'].mean()\n",
    "    size_std = d1['size'].std()\n",
    "    df['size'] = df['size'].apply(lambda x: (x - size_mean) / size_std)\n",
    "\n",
    "    age_mean = d1['age'].mean()\n",
    "    age_std = d1['age'].std()\n",
    "    df['age'] = df['age'].apply(lambda x: (x - age_mean) / age_std)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_image_data(dir_name, df):\n",
    "    count = 0\n",
    "    for path, dir, files in os.walk(dir_name):\n",
    "            count += len(files)\n",
    "    print('total images = %d' % count)\n",
    "\n",
    "    file_list = []\n",
    "    img_data = np.ndarray((count, target_width, target_height, 3), dtype=np.float32)\n",
    "    clinical_data = np.ndarray((count, 3), dtype=np.float32)\n",
    "    y_data = np.ndarray((count, ), dtype=np.int8)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for path, dir, files in os.walk(dir_name):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(path, file_name)\n",
    "            img = image.load_img(file_path, target_size=(target_width, target_height))\n",
    "            x = image.img_to_array(img)\n",
    "            img_data[i] = x\n",
    "            if os.path.basename(path) == 'neoplastic': y_data[i] = 1\n",
    "            else: y_data[i] = 0\n",
    "            name = os.path.basename(file_path)[:-9]\n",
    "            try:\n",
    "                size = df[df['name']==name].iloc[0]['size']\n",
    "                multiplicity = df[df['name']==name].iloc[0]['multiplicity']\n",
    "                age = df[df['name']==name].iloc[0]['age']\n",
    "            except IndexError:\n",
    "                print(name)\n",
    "                size = 0\n",
    "                multiplicity = 0\n",
    "                age = 0\n",
    "            clinical_data[i] = (size, multiplicity, age)\n",
    "            file_list.append(file_path)\n",
    "            i += 1\n",
    "\n",
    "    return file_list, img_data, clinical_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 []\n",
      "inception_v3 []\n",
      "global_average_pooling2d_1 []\n",
      "dense_1 [<tf.Variable 'dense_1/kernel:0' shape=(2048, 1024) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(1024,) dtype=float32_ref>]\n",
      "dense_2 [<tf.Variable 'dense_2/kernel:0' shape=(1024, 1) dtype=float32_ref>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(target_width, target_height, 3))\n",
    "\n",
    "i1 = conv_base.input\n",
    "x = conv_base(i1)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=i1, outputs=predictions)\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.load_weights(image_checkpoint_path)\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pretained_weights = layer_dict['dense_1'].get_weights() # shape=(2048, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Clinical Data Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_3 [<tf.Variable 'dense_3/kernel:0' shape=(3, 4) dtype=float32_ref>, <tf.Variable 'dense_3/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "dense_4 [<tf.Variable 'dense_4/kernel:0' shape=(4, 4) dtype=float32_ref>, <tf.Variable 'dense_4/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "dense_5 [<tf.Variable 'dense_5/kernel:0' shape=(4, 1) dtype=float32_ref>, <tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_dim=3))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.load_weights(clinical_data_checkpoint_path)\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data_weights1 = layer_dict['dense_3'].get_weights() # shape=(3, 4)\n",
    "clinical_data_weights2 = layer_dict['dense_4'].get_weights() # shape=(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 []\n",
      "inception_v3 []\n",
      "input_2 []\n",
      "global_average_pooling2d_1 []\n",
      "dense_2 [<tf.Variable 'dense_2/kernel:0' shape=(3, 4) dtype=float32_ref>, <tf.Variable 'dense_2/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "dense_1 [<tf.Variable 'dense_1/kernel:0' shape=(2048, 1024) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(1024,) dtype=float32_ref>]\n",
      "dense_3 [<tf.Variable 'dense_3/kernel:0' shape=(4, 4) dtype=float32_ref>, <tf.Variable 'dense_3/bias:0' shape=(4,) dtype=float32_ref>]\n",
      "concatenate_3 []\n",
      "dense_4 [<tf.Variable 'dense_4/kernel:0' shape=(1028, 1) dtype=float32_ref>, <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(target_width, target_height, 3))\n",
    "\n",
    "i1 = conv_base.input\n",
    "x1 = conv_base(i1)\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "x1 = Dense(1024, activation='relu')(x1)\n",
    "\n",
    "i2 = Input(shape=(3,))\n",
    "x2 = Dense(4, activation='relu',)(i2)\n",
    "x2 = Dense(4, activation='relu')(x2)\n",
    "\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=([i1, i2]), outputs=predictions)\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(ensemble_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 8, 8, 2048)   21802784    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            16          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            20          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1028)         0           dense_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            1029        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,902,025\n",
      "Trainable params: 1,029\n",
      "Non-trainable params: 23,900,996\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_dict['dense_6'].set_weights(image_pretained_weights) # shape=(2048, 1024)\n",
    "layer_dict['dense_7'].set_weights(clinical_data_weights1) # shape=(3, 4)\n",
    "layer_dict['dense_8'].set_weights(clinical_data_weights2) # shape=(4, 4)\n",
    "\n",
    "layer_dict['dense_6'].trainable = False # shape=(2048, 1024)\n",
    "layer_dict['dense_7'].trainable = False # shape=(3, 4)\n",
    "layer_dict['dense_8'].trainable = False # shape=(4, 4)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 8, 8, 2048)   21802784    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            16          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            20          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1028)         0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1029        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,902,025\n",
      "Trainable params: 2,099,241\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/2000\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.2596 - acc: 0.9014 - val_loss: 0.3180 - val_acc: 0.8712\n",
      "Epoch 626/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2673 - acc: 0.8968 - val_loss: 0.3012 - val_acc: 0.8761\n",
      "Epoch 627/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2538 - acc: 0.8964 - val_loss: 0.3134 - val_acc: 0.8674\n",
      "Epoch 628/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2541 - acc: 0.8991 - val_loss: 0.2981 - val_acc: 0.8751\n",
      "Epoch 629/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2608 - acc: 0.8950 - val_loss: 0.3145 - val_acc: 0.8722\n",
      "Epoch 630/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2581 - acc: 0.8993 - val_loss: 0.3089 - val_acc: 0.8780\n",
      "Epoch 631/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2573 - acc: 0.8991 - val_loss: 0.2999 - val_acc: 0.8771\n",
      "Epoch 632/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2556 - acc: 0.8996 - val_loss: 0.3008 - val_acc: 0.8751\n",
      "Epoch 633/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2590 - acc: 0.8950 - val_loss: 0.2933 - val_acc: 0.8742\n",
      "Epoch 634/2000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2547 - acc: 0.8984 - val_loss: 0.2945 - val_acc: 0.8771\n",
      "Epoch 635/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2575 - acc: 0.9021 - val_loss: 0.3059 - val_acc: 0.8771\n",
      "Epoch 636/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2512 - acc: 0.9085 - val_loss: 0.3000 - val_acc: 0.8780\n",
      "Epoch 637/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2515 - acc: 0.8980 - val_loss: 0.3313 - val_acc: 0.8683\n",
      "Epoch 638/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2569 - acc: 0.8989 - val_loss: 0.3039 - val_acc: 0.8780\n",
      "Epoch 639/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2587 - acc: 0.8991 - val_loss: 0.3206 - val_acc: 0.8732\n",
      "Epoch 640/2000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2564 - acc: 0.8911 - val_loss: 0.3077 - val_acc: 0.8732\n",
      "Epoch 641/2000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2497 - acc: 0.9033 - val_loss: 0.3057 - val_acc: 0.8790\n",
      "Epoch 642/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2546 - acc: 0.9007 - val_loss: 0.3134 - val_acc: 0.8732\n",
      "Epoch 643/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2517 - acc: 0.8971 - val_loss: 0.3051 - val_acc: 0.8732\n",
      "Epoch 644/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2532 - acc: 0.8982 - val_loss: 0.3182 - val_acc: 0.8751\n",
      "Epoch 645/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2478 - acc: 0.9095 - val_loss: 0.3178 - val_acc: 0.8732\n",
      "Epoch 646/2000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2456 - acc: 0.9012 - val_loss: 0.3567 - val_acc: 0.8674\n",
      "Epoch 647/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2531 - acc: 0.8975 - val_loss: 0.3330 - val_acc: 0.8742\n",
      "Epoch 648/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2611 - acc: 0.8973 - val_loss: 0.3216 - val_acc: 0.8742\n",
      "Epoch 649/2000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2469 - acc: 0.8973 - val_loss: 0.3237 - val_acc: 0.8732\n",
      "Epoch 650/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2478 - acc: 0.9042 - val_loss: 0.2997 - val_acc: 0.8780\n",
      "Epoch 651/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2502 - acc: 0.9005 - val_loss: 0.3000 - val_acc: 0.8771\n",
      "Epoch 652/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2558 - acc: 0.8989 - val_loss: 0.3191 - val_acc: 0.8693\n",
      "Epoch 653/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2500 - acc: 0.9010 - val_loss: 0.3131 - val_acc: 0.8712\n",
      "Epoch 654/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2483 - acc: 0.9035 - val_loss: 0.2927 - val_acc: 0.8790\n",
      "Epoch 655/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2547 - acc: 0.8970 - val_loss: 0.3024 - val_acc: 0.8761\n",
      "Epoch 656/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2468 - acc: 0.9019 - val_loss: 0.3034 - val_acc: 0.8819\n",
      "Epoch 657/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2500 - acc: 0.9028 - val_loss: 0.3229 - val_acc: 0.8742\n",
      "Epoch 658/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2437 - acc: 0.9072 - val_loss: 0.3226 - val_acc: 0.8742\n",
      "Epoch 659/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2492 - acc: 0.9019 - val_loss: 0.3132 - val_acc: 0.8800\n",
      "Epoch 660/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2413 - acc: 0.9053 - val_loss: 0.3230 - val_acc: 0.8712\n",
      "Epoch 661/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2495 - acc: 0.9049 - val_loss: 0.3173 - val_acc: 0.8732\n",
      "Epoch 662/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2554 - acc: 0.9007 - val_loss: 0.3106 - val_acc: 0.8790\n",
      "Epoch 663/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2482 - acc: 0.9040 - val_loss: 0.3088 - val_acc: 0.8790\n",
      "Epoch 664/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2544 - acc: 0.9003 - val_loss: 0.3302 - val_acc: 0.8722\n",
      "Epoch 665/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2489 - acc: 0.9023 - val_loss: 0.3050 - val_acc: 0.8742\n",
      "Epoch 666/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2571 - acc: 0.8980 - val_loss: 0.3121 - val_acc: 0.8722\n",
      "Epoch 667/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2526 - acc: 0.8971 - val_loss: 0.2950 - val_acc: 0.8790\n",
      "Epoch 668/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2469 - acc: 0.9060 - val_loss: 0.3219 - val_acc: 0.8683\n",
      "Epoch 669/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2566 - acc: 0.8948 - val_loss: 0.3151 - val_acc: 0.8664\n",
      "Epoch 670/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2504 - acc: 0.8989 - val_loss: 0.3154 - val_acc: 0.8712\n",
      "Epoch 671/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2502 - acc: 0.8950 - val_loss: 0.3056 - val_acc: 0.8751\n",
      "Epoch 672/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2470 - acc: 0.9002 - val_loss: 0.3073 - val_acc: 0.8722\n",
      "Epoch 673/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2488 - acc: 0.9040 - val_loss: 0.3129 - val_acc: 0.8722\n",
      "Epoch 674/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2460 - acc: 0.9001 - val_loss: 0.3181 - val_acc: 0.8751\n",
      "Epoch 675/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2483 - acc: 0.9033 - val_loss: 0.3275 - val_acc: 0.8664\n",
      "Epoch 676/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2473 - acc: 0.9035 - val_loss: 0.3258 - val_acc: 0.8683\n",
      "Epoch 677/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2473 - acc: 0.9047 - val_loss: 0.3417 - val_acc: 0.8645\n",
      "Epoch 678/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2456 - acc: 0.9005 - val_loss: 0.3355 - val_acc: 0.8654\n",
      "Epoch 679/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2500 - acc: 0.9012 - val_loss: 0.3254 - val_acc: 0.8732\n",
      "Epoch 680/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2510 - acc: 0.8991 - val_loss: 0.3226 - val_acc: 0.8674\n",
      "Epoch 681/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2508 - acc: 0.9021 - val_loss: 0.2997 - val_acc: 0.8771\n",
      "Epoch 682/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2447 - acc: 0.9058 - val_loss: 0.3117 - val_acc: 0.8751\n",
      "Epoch 683/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2514 - acc: 0.9021 - val_loss: 0.3027 - val_acc: 0.8800\n",
      "Epoch 684/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2448 - acc: 0.9012 - val_loss: 0.3101 - val_acc: 0.8742\n",
      "Epoch 685/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2469 - acc: 0.9023 - val_loss: 0.3205 - val_acc: 0.8693\n",
      "Epoch 686/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2519 - acc: 0.9010 - val_loss: 0.3087 - val_acc: 0.8751\n",
      "Epoch 687/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2501 - acc: 0.9030 - val_loss: 0.3396 - val_acc: 0.8703\n",
      "Epoch 688/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2530 - acc: 0.9014 - val_loss: 0.3315 - val_acc: 0.8732\n",
      "Epoch 689/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2474 - acc: 0.9030 - val_loss: 0.3058 - val_acc: 0.8819\n",
      "Epoch 690/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2505 - acc: 0.9053 - val_loss: 0.3113 - val_acc: 0.8800\n",
      "Epoch 691/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2447 - acc: 0.9058 - val_loss: 0.2983 - val_acc: 0.8809\n",
      "Epoch 692/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2461 - acc: 0.9033 - val_loss: 0.2899 - val_acc: 0.8848\n",
      "Epoch 693/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2459 - acc: 0.9033 - val_loss: 0.3114 - val_acc: 0.8771\n",
      "Epoch 694/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2431 - acc: 0.9044 - val_loss: 0.3161 - val_acc: 0.8722\n",
      "Epoch 695/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2447 - acc: 0.9051 - val_loss: 0.3102 - val_acc: 0.8771\n",
      "Epoch 696/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2446 - acc: 0.8989 - val_loss: 0.3156 - val_acc: 0.8771\n",
      "Epoch 697/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2512 - acc: 0.8998 - val_loss: 0.3116 - val_acc: 0.8742\n",
      "Epoch 698/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2470 - acc: 0.9030 - val_loss: 0.3104 - val_acc: 0.8712\n",
      "Epoch 699/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2469 - acc: 0.9023 - val_loss: 0.3205 - val_acc: 0.8703\n",
      "Epoch 700/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2445 - acc: 0.9005 - val_loss: 0.3070 - val_acc: 0.8790\n",
      "Epoch 701/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2462 - acc: 0.9010 - val_loss: 0.3214 - val_acc: 0.8722\n",
      "Epoch 702/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2517 - acc: 0.9010 - val_loss: 0.3066 - val_acc: 0.8732\n",
      "Epoch 703/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2413 - acc: 0.9061 - val_loss: 0.3223 - val_acc: 0.8635\n",
      "Epoch 704/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2541 - acc: 0.9016 - val_loss: 0.3110 - val_acc: 0.8683\n",
      "Epoch 705/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2523 - acc: 0.8950 - val_loss: 0.2968 - val_acc: 0.8771\n",
      "Epoch 706/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2384 - acc: 0.9042 - val_loss: 0.3120 - val_acc: 0.8722\n",
      "Epoch 707/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2451 - acc: 0.9046 - val_loss: 0.3120 - val_acc: 0.8722\n",
      "Epoch 708/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2459 - acc: 0.9023 - val_loss: 0.3162 - val_acc: 0.8742\n",
      "Epoch 709/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2495 - acc: 0.9014 - val_loss: 0.2920 - val_acc: 0.8809\n",
      "Epoch 710/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2401 - acc: 0.9049 - val_loss: 0.2997 - val_acc: 0.8800\n",
      "Epoch 711/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2468 - acc: 0.9033 - val_loss: 0.3279 - val_acc: 0.8732\n",
      "Epoch 712/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2417 - acc: 0.9099 - val_loss: 0.3124 - val_acc: 0.8800\n",
      "Epoch 713/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2385 - acc: 0.9070 - val_loss: 0.3163 - val_acc: 0.8771\n",
      "Epoch 714/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2325 - acc: 0.9069 - val_loss: 0.3160 - val_acc: 0.8742\n",
      "Epoch 715/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2417 - acc: 0.9026 - val_loss: 0.3207 - val_acc: 0.8732\n",
      "Epoch 716/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2488 - acc: 0.9065 - val_loss: 0.2994 - val_acc: 0.8819\n",
      "Epoch 717/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2451 - acc: 0.9037 - val_loss: 0.3473 - val_acc: 0.8664\n",
      "Epoch 718/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2454 - acc: 0.9010 - val_loss: 0.2921 - val_acc: 0.8800\n",
      "Epoch 719/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2434 - acc: 0.9060 - val_loss: 0.3325 - val_acc: 0.8674\n",
      "Epoch 720/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2427 - acc: 0.9072 - val_loss: 0.3165 - val_acc: 0.8703\n",
      "Epoch 721/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2344 - acc: 0.9115 - val_loss: 0.3070 - val_acc: 0.8761\n",
      "Epoch 722/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2364 - acc: 0.9083 - val_loss: 0.3499 - val_acc: 0.8625\n",
      "Epoch 723/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2410 - acc: 0.9035 - val_loss: 0.3177 - val_acc: 0.8742\n",
      "Epoch 724/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2428 - acc: 0.9056 - val_loss: 0.3079 - val_acc: 0.8780\n",
      "Epoch 725/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2369 - acc: 0.9074 - val_loss: 0.3009 - val_acc: 0.8761\n",
      "Epoch 726/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2478 - acc: 0.8975 - val_loss: 0.3008 - val_acc: 0.8838\n",
      "Epoch 727/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2448 - acc: 0.9030 - val_loss: 0.3449 - val_acc: 0.8664\n",
      "Epoch 728/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2408 - acc: 0.9049 - val_loss: 0.3121 - val_acc: 0.8722\n",
      "Epoch 729/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2425 - acc: 0.9017 - val_loss: 0.3231 - val_acc: 0.8722\n",
      "Epoch 730/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2415 - acc: 0.9005 - val_loss: 0.3269 - val_acc: 0.8703\n",
      "Epoch 731/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2419 - acc: 0.9021 - val_loss: 0.3525 - val_acc: 0.8674\n",
      "Epoch 732/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2366 - acc: 0.9085 - val_loss: 0.3133 - val_acc: 0.8722\n",
      "Epoch 733/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2358 - acc: 0.9124 - val_loss: 0.3480 - val_acc: 0.8674\n",
      "Epoch 734/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2415 - acc: 0.9056 - val_loss: 0.3180 - val_acc: 0.8732\n",
      "Epoch 735/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2366 - acc: 0.9026 - val_loss: 0.3504 - val_acc: 0.8654\n",
      "Epoch 736/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2401 - acc: 0.9021 - val_loss: 0.3458 - val_acc: 0.8654\n",
      "Epoch 737/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2394 - acc: 0.9049 - val_loss: 0.3502 - val_acc: 0.8693\n",
      "Epoch 738/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2456 - acc: 0.9000 - val_loss: 0.3215 - val_acc: 0.8761\n",
      "Epoch 739/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2491 - acc: 0.8980 - val_loss: 0.3061 - val_acc: 0.8790\n",
      "Epoch 740/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2393 - acc: 0.9100 - val_loss: 0.3115 - val_acc: 0.8751\n",
      "Epoch 741/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2451 - acc: 0.9060 - val_loss: 0.3192 - val_acc: 0.8712\n",
      "Epoch 742/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2323 - acc: 0.9115 - val_loss: 0.3158 - val_acc: 0.8742\n",
      "Epoch 743/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2436 - acc: 0.9049 - val_loss: 0.3118 - val_acc: 0.8712\n",
      "Epoch 744/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2389 - acc: 0.8991 - val_loss: 0.3188 - val_acc: 0.8703\n",
      "Epoch 745/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2392 - acc: 0.9076 - val_loss: 0.3247 - val_acc: 0.8742\n",
      "Epoch 746/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2368 - acc: 0.9056 - val_loss: 0.3080 - val_acc: 0.8751\n",
      "Epoch 747/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 87s 5s/step - loss: 0.2396 - acc: 0.9053 - val_loss: 0.3036 - val_acc: 0.8790\n",
      "Epoch 748/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2343 - acc: 0.9095 - val_loss: 0.3261 - val_acc: 0.8722\n",
      "Epoch 749/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2443 - acc: 0.9035 - val_loss: 0.3188 - val_acc: 0.8722\n",
      "Epoch 750/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2392 - acc: 0.9065 - val_loss: 0.3203 - val_acc: 0.8683\n",
      "Epoch 751/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2423 - acc: 0.9044 - val_loss: 0.3149 - val_acc: 0.8693\n",
      "Epoch 752/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2354 - acc: 0.9051 - val_loss: 0.3125 - val_acc: 0.8732\n",
      "Epoch 753/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2459 - acc: 0.9028 - val_loss: 0.3130 - val_acc: 0.8751\n",
      "Epoch 754/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2334 - acc: 0.9081 - val_loss: 0.3289 - val_acc: 0.8683\n",
      "Epoch 755/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2311 - acc: 0.9090 - val_loss: 0.3003 - val_acc: 0.8780\n",
      "Epoch 756/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2406 - acc: 0.9014 - val_loss: 0.3203 - val_acc: 0.8693\n",
      "Epoch 757/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2380 - acc: 0.9070 - val_loss: 0.3149 - val_acc: 0.8703\n",
      "Epoch 758/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2387 - acc: 0.9014 - val_loss: 0.3224 - val_acc: 0.8693\n",
      "Epoch 759/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2400 - acc: 0.9042 - val_loss: 0.3169 - val_acc: 0.8693\n",
      "Epoch 760/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2353 - acc: 0.9035 - val_loss: 0.2828 - val_acc: 0.8848\n",
      "Epoch 761/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2337 - acc: 0.9074 - val_loss: 0.3278 - val_acc: 0.8683\n",
      "Epoch 762/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2385 - acc: 0.9074 - val_loss: 0.3271 - val_acc: 0.8722\n",
      "Epoch 763/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2492 - acc: 0.9037 - val_loss: 0.3505 - val_acc: 0.8645\n",
      "Epoch 764/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2323 - acc: 0.9102 - val_loss: 0.3089 - val_acc: 0.8780\n",
      "Epoch 765/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2380 - acc: 0.9090 - val_loss: 0.3145 - val_acc: 0.8751\n",
      "Epoch 766/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2457 - acc: 0.9026 - val_loss: 0.3254 - val_acc: 0.8703\n",
      "Epoch 767/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2253 - acc: 0.9102 - val_loss: 0.3389 - val_acc: 0.8654\n",
      "Epoch 768/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2329 - acc: 0.9065 - val_loss: 0.3179 - val_acc: 0.8722\n",
      "Epoch 769/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2366 - acc: 0.9072 - val_loss: 0.3101 - val_acc: 0.8732\n",
      "Epoch 770/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2367 - acc: 0.9033 - val_loss: 0.3358 - val_acc: 0.8654\n",
      "Epoch 771/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2387 - acc: 0.9074 - val_loss: 0.3193 - val_acc: 0.8683\n",
      "Epoch 772/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2415 - acc: 0.9022 - val_loss: 0.3078 - val_acc: 0.8722\n",
      "Epoch 773/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2307 - acc: 0.9086 - val_loss: 0.2919 - val_acc: 0.8800\n",
      "Epoch 774/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2376 - acc: 0.9001 - val_loss: 0.3056 - val_acc: 0.8742\n",
      "Epoch 775/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2343 - acc: 0.9065 - val_loss: 0.2933 - val_acc: 0.8761\n",
      "Epoch 776/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2376 - acc: 0.9026 - val_loss: 0.3122 - val_acc: 0.8693\n",
      "Epoch 777/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2431 - acc: 0.9056 - val_loss: 0.3240 - val_acc: 0.8693\n",
      "Epoch 778/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2345 - acc: 0.9122 - val_loss: 0.3074 - val_acc: 0.8742\n",
      "Epoch 779/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2315 - acc: 0.9037 - val_loss: 0.3057 - val_acc: 0.8761\n",
      "Epoch 780/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2321 - acc: 0.9116 - val_loss: 0.3316 - val_acc: 0.8674\n",
      "Epoch 781/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2219 - acc: 0.9155 - val_loss: 0.3182 - val_acc: 0.8693\n",
      "Epoch 782/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2324 - acc: 0.9122 - val_loss: 0.3013 - val_acc: 0.8751\n",
      "Epoch 783/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2344 - acc: 0.9060 - val_loss: 0.3086 - val_acc: 0.8742\n",
      "Epoch 784/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2398 - acc: 0.9104 - val_loss: 0.2876 - val_acc: 0.8819\n",
      "Epoch 785/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2300 - acc: 0.9099 - val_loss: 0.3242 - val_acc: 0.8664\n",
      "Epoch 786/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2388 - acc: 0.9081 - val_loss: 0.3079 - val_acc: 0.8732\n",
      "Epoch 787/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2372 - acc: 0.9063 - val_loss: 0.2928 - val_acc: 0.8761\n",
      "Epoch 788/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2304 - acc: 0.9123 - val_loss: 0.3398 - val_acc: 0.8674\n",
      "Epoch 789/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2346 - acc: 0.9062 - val_loss: 0.2996 - val_acc: 0.8732\n",
      "Epoch 790/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2413 - acc: 0.9021 - val_loss: 0.3239 - val_acc: 0.8703\n",
      "Epoch 791/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2346 - acc: 0.8987 - val_loss: 0.3376 - val_acc: 0.8625\n",
      "Epoch 792/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2402 - acc: 0.9065 - val_loss: 0.3322 - val_acc: 0.8635\n",
      "Epoch 793/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2328 - acc: 0.9079 - val_loss: 0.2841 - val_acc: 0.8780\n",
      "Epoch 794/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2307 - acc: 0.9079 - val_loss: 0.3183 - val_acc: 0.8664\n",
      "Epoch 795/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2345 - acc: 0.9111 - val_loss: 0.3304 - val_acc: 0.8625\n",
      "Epoch 796/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2332 - acc: 0.9104 - val_loss: 0.3405 - val_acc: 0.8625\n",
      "Epoch 797/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2339 - acc: 0.9106 - val_loss: 0.3276 - val_acc: 0.8693\n",
      "Epoch 798/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2301 - acc: 0.9152 - val_loss: 0.3210 - val_acc: 0.8722\n",
      "Epoch 799/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2321 - acc: 0.9120 - val_loss: 0.3380 - val_acc: 0.8625\n",
      "Epoch 800/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2368 - acc: 0.9056 - val_loss: 0.3140 - val_acc: 0.8761\n",
      "Epoch 801/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2323 - acc: 0.9088 - val_loss: 0.3064 - val_acc: 0.8780\n",
      "Epoch 802/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2382 - acc: 0.9093 - val_loss: 0.3140 - val_acc: 0.8742\n",
      "Epoch 803/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2281 - acc: 0.9067 - val_loss: 0.3009 - val_acc: 0.8800\n",
      "Epoch 804/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2294 - acc: 0.9111 - val_loss: 0.2975 - val_acc: 0.8790\n",
      "Epoch 805/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2309 - acc: 0.9111 - val_loss: 0.3506 - val_acc: 0.8683\n",
      "Epoch 806/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2363 - acc: 0.9074 - val_loss: 0.3167 - val_acc: 0.8722\n",
      "Epoch 807/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2329 - acc: 0.9079 - val_loss: 0.3069 - val_acc: 0.8751\n",
      "Epoch 808/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2278 - acc: 0.9143 - val_loss: 0.3013 - val_acc: 0.8780\n",
      "Epoch 809/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2259 - acc: 0.9106 - val_loss: 0.3288 - val_acc: 0.8664\n",
      "Epoch 810/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2322 - acc: 0.9040 - val_loss: 0.3079 - val_acc: 0.8712\n",
      "Epoch 811/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2221 - acc: 0.9157 - val_loss: 0.3149 - val_acc: 0.8722\n",
      "Epoch 812/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2365 - acc: 0.9077 - val_loss: 0.3079 - val_acc: 0.8742\n",
      "Epoch 813/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2353 - acc: 0.9065 - val_loss: 0.3076 - val_acc: 0.8742\n",
      "Epoch 814/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2300 - acc: 0.9113 - val_loss: 0.3090 - val_acc: 0.8712\n",
      "Epoch 815/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2348 - acc: 0.9071 - val_loss: 0.3017 - val_acc: 0.8751\n",
      "Epoch 816/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2271 - acc: 0.9129 - val_loss: 0.3234 - val_acc: 0.8703\n",
      "Epoch 817/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2272 - acc: 0.9072 - val_loss: 0.3120 - val_acc: 0.8722\n",
      "Epoch 818/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2307 - acc: 0.9067 - val_loss: 0.3122 - val_acc: 0.8683\n",
      "Epoch 819/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2340 - acc: 0.9118 - val_loss: 0.3259 - val_acc: 0.8674\n",
      "Epoch 820/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2271 - acc: 0.9097 - val_loss: 0.3014 - val_acc: 0.8712\n",
      "Epoch 821/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2304 - acc: 0.9079 - val_loss: 0.3104 - val_acc: 0.8722\n",
      "Epoch 822/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2256 - acc: 0.9109 - val_loss: 0.3151 - val_acc: 0.8742\n",
      "Epoch 823/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2327 - acc: 0.9081 - val_loss: 0.3046 - val_acc: 0.8722\n",
      "Epoch 824/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2312 - acc: 0.9113 - val_loss: 0.3053 - val_acc: 0.8674\n",
      "Epoch 825/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2360 - acc: 0.9069 - val_loss: 0.3111 - val_acc: 0.8712\n",
      "Epoch 826/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2378 - acc: 0.9085 - val_loss: 0.2930 - val_acc: 0.8819\n",
      "Epoch 827/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2242 - acc: 0.9120 - val_loss: 0.3575 - val_acc: 0.8645\n",
      "Epoch 828/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2367 - acc: 0.9035 - val_loss: 0.3063 - val_acc: 0.8742\n",
      "Epoch 829/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2297 - acc: 0.9083 - val_loss: 0.3326 - val_acc: 0.8712\n",
      "Epoch 830/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2383 - acc: 0.9014 - val_loss: 0.3245 - val_acc: 0.8693\n",
      "Epoch 831/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2308 - acc: 0.9058 - val_loss: 0.3157 - val_acc: 0.8722\n",
      "Epoch 832/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2340 - acc: 0.9155 - val_loss: 0.3315 - val_acc: 0.8712\n",
      "Epoch 833/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2333 - acc: 0.9067 - val_loss: 0.3153 - val_acc: 0.8771\n",
      "Epoch 834/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2278 - acc: 0.9104 - val_loss: 0.3697 - val_acc: 0.8558\n",
      "Epoch 835/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2334 - acc: 0.9058 - val_loss: 0.3065 - val_acc: 0.8771\n",
      "Epoch 836/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2254 - acc: 0.9106 - val_loss: 0.3384 - val_acc: 0.8712\n",
      "Epoch 837/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2317 - acc: 0.9074 - val_loss: 0.3382 - val_acc: 0.8674\n",
      "Epoch 838/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2305 - acc: 0.9003 - val_loss: 0.3305 - val_acc: 0.8722\n",
      "Epoch 839/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2300 - acc: 0.9104 - val_loss: 0.3007 - val_acc: 0.8771\n",
      "Epoch 840/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2342 - acc: 0.9060 - val_loss: 0.3087 - val_acc: 0.8751\n",
      "Epoch 841/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2266 - acc: 0.9097 - val_loss: 0.3253 - val_acc: 0.8751\n",
      "Epoch 842/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2333 - acc: 0.9090 - val_loss: 0.3033 - val_acc: 0.8809\n",
      "Epoch 843/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2286 - acc: 0.9063 - val_loss: 0.3214 - val_acc: 0.8751\n",
      "Epoch 844/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2360 - acc: 0.9035 - val_loss: 0.3025 - val_acc: 0.8742\n",
      "Epoch 845/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2306 - acc: 0.9090 - val_loss: 0.3087 - val_acc: 0.8742\n",
      "Epoch 846/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2325 - acc: 0.9070 - val_loss: 0.2997 - val_acc: 0.8751\n",
      "Epoch 847/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2249 - acc: 0.9152 - val_loss: 0.2916 - val_acc: 0.8790\n",
      "Epoch 848/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2317 - acc: 0.9099 - val_loss: 0.2999 - val_acc: 0.8761\n",
      "Epoch 849/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2273 - acc: 0.9071 - val_loss: 0.2977 - val_acc: 0.8790\n",
      "Epoch 850/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2322 - acc: 0.9118 - val_loss: 0.3161 - val_acc: 0.8761\n",
      "Epoch 851/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2233 - acc: 0.9127 - val_loss: 0.3029 - val_acc: 0.8712\n",
      "Epoch 852/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2263 - acc: 0.9102 - val_loss: 0.3564 - val_acc: 0.8558\n",
      "Epoch 853/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2306 - acc: 0.9077 - val_loss: 0.3241 - val_acc: 0.8674\n",
      "Epoch 854/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2281 - acc: 0.9090 - val_loss: 0.3081 - val_acc: 0.8742\n",
      "Epoch 855/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2219 - acc: 0.9138 - val_loss: 0.3156 - val_acc: 0.8645\n",
      "Epoch 856/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2268 - acc: 0.9083 - val_loss: 0.3124 - val_acc: 0.8683\n",
      "Epoch 857/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2354 - acc: 0.9049 - val_loss: 0.3111 - val_acc: 0.8732\n",
      "Epoch 858/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2352 - acc: 0.9056 - val_loss: 0.3425 - val_acc: 0.8654\n",
      "Epoch 859/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2324 - acc: 0.9042 - val_loss: 0.3423 - val_acc: 0.8587\n",
      "Epoch 860/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2250 - acc: 0.9090 - val_loss: 0.3560 - val_acc: 0.8596\n",
      "Epoch 861/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2303 - acc: 0.9104 - val_loss: 0.2970 - val_acc: 0.8771\n",
      "Epoch 862/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2302 - acc: 0.9076 - val_loss: 0.3143 - val_acc: 0.8732\n",
      "Epoch 863/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2272 - acc: 0.9088 - val_loss: 0.3116 - val_acc: 0.8732\n",
      "Epoch 864/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2300 - acc: 0.9111 - val_loss: 0.3122 - val_acc: 0.8703\n",
      "Epoch 865/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2287 - acc: 0.9115 - val_loss: 0.3351 - val_acc: 0.8674\n",
      "Epoch 866/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2329 - acc: 0.9111 - val_loss: 0.2956 - val_acc: 0.8751\n",
      "Epoch 867/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2269 - acc: 0.9138 - val_loss: 0.3116 - val_acc: 0.8722\n",
      "Epoch 868/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2329 - acc: 0.9090 - val_loss: 0.3051 - val_acc: 0.8790\n",
      "Epoch 869/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 85s 5s/step - loss: 0.2244 - acc: 0.9123 - val_loss: 0.3169 - val_acc: 0.8712\n",
      "Epoch 870/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2325 - acc: 0.9069 - val_loss: 0.3292 - val_acc: 0.8654\n",
      "Epoch 871/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2297 - acc: 0.9104 - val_loss: 0.3305 - val_acc: 0.8654\n",
      "Epoch 872/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2246 - acc: 0.9083 - val_loss: 0.3231 - val_acc: 0.8693\n",
      "Epoch 873/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2315 - acc: 0.9053 - val_loss: 0.3022 - val_acc: 0.8771\n",
      "Epoch 874/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2263 - acc: 0.9104 - val_loss: 0.3076 - val_acc: 0.8761\n",
      "Epoch 875/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2354 - acc: 0.9104 - val_loss: 0.3010 - val_acc: 0.8771\n",
      "Epoch 876/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2210 - acc: 0.9171 - val_loss: 0.3006 - val_acc: 0.8790\n",
      "Epoch 877/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2256 - acc: 0.9170 - val_loss: 0.3387 - val_acc: 0.8683\n",
      "Epoch 878/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2253 - acc: 0.9086 - val_loss: 0.3322 - val_acc: 0.8683\n",
      "Epoch 879/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2271 - acc: 0.9118 - val_loss: 0.3250 - val_acc: 0.8654\n",
      "Epoch 880/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2223 - acc: 0.9155 - val_loss: 0.3281 - val_acc: 0.8722\n",
      "Epoch 881/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2249 - acc: 0.9124 - val_loss: 0.3212 - val_acc: 0.8693\n",
      "Epoch 882/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2321 - acc: 0.9099 - val_loss: 0.2967 - val_acc: 0.8790\n",
      "Epoch 883/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2230 - acc: 0.9115 - val_loss: 0.3156 - val_acc: 0.8742\n",
      "Epoch 884/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2312 - acc: 0.9113 - val_loss: 0.3128 - val_acc: 0.8645\n",
      "Epoch 885/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2261 - acc: 0.9145 - val_loss: 0.3250 - val_acc: 0.8683\n",
      "Epoch 886/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2278 - acc: 0.9068 - val_loss: 0.3091 - val_acc: 0.8771\n",
      "Epoch 887/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2261 - acc: 0.9108 - val_loss: 0.3101 - val_acc: 0.8732\n",
      "Epoch 888/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2277 - acc: 0.9099 - val_loss: 0.3072 - val_acc: 0.8771\n",
      "Epoch 889/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2328 - acc: 0.9102 - val_loss: 0.3284 - val_acc: 0.8712\n",
      "Epoch 890/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2235 - acc: 0.9116 - val_loss: 0.3180 - val_acc: 0.8751\n",
      "Epoch 891/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2348 - acc: 0.9060 - val_loss: 0.3239 - val_acc: 0.8693\n",
      "Epoch 892/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2308 - acc: 0.9152 - val_loss: 0.3325 - val_acc: 0.8693\n",
      "Epoch 893/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2309 - acc: 0.9106 - val_loss: 0.2892 - val_acc: 0.8761\n",
      "Epoch 894/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2247 - acc: 0.9086 - val_loss: 0.3006 - val_acc: 0.8771\n",
      "Epoch 895/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2285 - acc: 0.9088 - val_loss: 0.3206 - val_acc: 0.8703\n",
      "Epoch 896/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2290 - acc: 0.9053 - val_loss: 0.2844 - val_acc: 0.8800\n",
      "Epoch 897/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2317 - acc: 0.9086 - val_loss: 0.3006 - val_acc: 0.8751\n",
      "Epoch 898/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2353 - acc: 0.9092 - val_loss: 0.3053 - val_acc: 0.8751\n",
      "Epoch 899/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2300 - acc: 0.9092 - val_loss: 0.3105 - val_acc: 0.8703\n",
      "Epoch 900/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2245 - acc: 0.9086 - val_loss: 0.3209 - val_acc: 0.8703\n",
      "Epoch 901/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2302 - acc: 0.9092 - val_loss: 0.3060 - val_acc: 0.8712\n",
      "Epoch 902/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2348 - acc: 0.9083 - val_loss: 0.3392 - val_acc: 0.8674\n",
      "Epoch 903/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2256 - acc: 0.9141 - val_loss: 0.3150 - val_acc: 0.8732\n",
      "Epoch 904/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2209 - acc: 0.9148 - val_loss: 0.2784 - val_acc: 0.8838\n",
      "Epoch 905/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2273 - acc: 0.9111 - val_loss: 0.2935 - val_acc: 0.8761\n",
      "Epoch 906/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2249 - acc: 0.9129 - val_loss: 0.3124 - val_acc: 0.8722\n",
      "Epoch 907/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2282 - acc: 0.9088 - val_loss: 0.3275 - val_acc: 0.8722\n",
      "Epoch 908/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2321 - acc: 0.9093 - val_loss: 0.3360 - val_acc: 0.8674\n",
      "Epoch 909/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2212 - acc: 0.9111 - val_loss: 0.3031 - val_acc: 0.8800\n",
      "Epoch 910/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2242 - acc: 0.9157 - val_loss: 0.3004 - val_acc: 0.8742\n",
      "Epoch 911/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2183 - acc: 0.9159 - val_loss: 0.3132 - val_acc: 0.8703\n",
      "Epoch 912/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2229 - acc: 0.9099 - val_loss: 0.3291 - val_acc: 0.8751\n",
      "Epoch 913/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2214 - acc: 0.9143 - val_loss: 0.3337 - val_acc: 0.8761\n",
      "Epoch 914/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2267 - acc: 0.9099 - val_loss: 0.3110 - val_acc: 0.8742\n",
      "Epoch 915/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2253 - acc: 0.9095 - val_loss: 0.3359 - val_acc: 0.8693\n",
      "Epoch 916/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2303 - acc: 0.9083 - val_loss: 0.3374 - val_acc: 0.8693\n",
      "Epoch 917/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2220 - acc: 0.9152 - val_loss: 0.3197 - val_acc: 0.8722\n",
      "Epoch 918/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2238 - acc: 0.9168 - val_loss: 0.3556 - val_acc: 0.8616\n",
      "Epoch 919/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2277 - acc: 0.9081 - val_loss: 0.3097 - val_acc: 0.8780\n",
      "Epoch 920/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2233 - acc: 0.9132 - val_loss: 0.3271 - val_acc: 0.8683\n",
      "Epoch 921/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2258 - acc: 0.9113 - val_loss: 0.3025 - val_acc: 0.8732\n",
      "Epoch 922/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2289 - acc: 0.9104 - val_loss: 0.2930 - val_acc: 0.8809\n",
      "Epoch 923/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2163 - acc: 0.9175 - val_loss: 0.3142 - val_acc: 0.8761\n",
      "Epoch 924/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2312 - acc: 0.9134 - val_loss: 0.3108 - val_acc: 0.8761\n",
      "Epoch 925/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2241 - acc: 0.9143 - val_loss: 0.3025 - val_acc: 0.8771\n",
      "Epoch 926/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2275 - acc: 0.9083 - val_loss: 0.3110 - val_acc: 0.8742\n",
      "Epoch 927/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2328 - acc: 0.9127 - val_loss: 0.3131 - val_acc: 0.8771\n",
      "Epoch 928/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2338 - acc: 0.9088 - val_loss: 0.2800 - val_acc: 0.8829\n",
      "Epoch 929/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2371 - acc: 0.9076 - val_loss: 0.2946 - val_acc: 0.8780\n",
      "Epoch 930/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2288 - acc: 0.9116 - val_loss: 0.3140 - val_acc: 0.8751\n",
      "Epoch 931/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2259 - acc: 0.9088 - val_loss: 0.2947 - val_acc: 0.8819\n",
      "Epoch 932/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2204 - acc: 0.9136 - val_loss: 0.3060 - val_acc: 0.8761\n",
      "Epoch 933/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2276 - acc: 0.9138 - val_loss: 0.3132 - val_acc: 0.8761\n",
      "Epoch 934/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2254 - acc: 0.9086 - val_loss: 0.3161 - val_acc: 0.8732\n",
      "Epoch 935/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2254 - acc: 0.9076 - val_loss: 0.3521 - val_acc: 0.8703\n",
      "Epoch 936/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2259 - acc: 0.9102 - val_loss: 0.3102 - val_acc: 0.8790\n",
      "Epoch 937/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2214 - acc: 0.9099 - val_loss: 0.3322 - val_acc: 0.8703\n",
      "Epoch 938/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2286 - acc: 0.9115 - val_loss: 0.3122 - val_acc: 0.8751\n",
      "Epoch 939/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2291 - acc: 0.9092 - val_loss: 0.3359 - val_acc: 0.8683\n",
      "Epoch 940/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2312 - acc: 0.9104 - val_loss: 0.3188 - val_acc: 0.8712\n",
      "Epoch 941/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2195 - acc: 0.9161 - val_loss: 0.3203 - val_acc: 0.8693\n",
      "Epoch 942/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2321 - acc: 0.9012 - val_loss: 0.2958 - val_acc: 0.8829\n",
      "Epoch 943/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2251 - acc: 0.9132 - val_loss: 0.3623 - val_acc: 0.8635\n",
      "Epoch 944/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2274 - acc: 0.9106 - val_loss: 0.3269 - val_acc: 0.8674\n",
      "Epoch 945/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2267 - acc: 0.9134 - val_loss: 0.3263 - val_acc: 0.8712\n",
      "Epoch 946/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2233 - acc: 0.9106 - val_loss: 0.3299 - val_acc: 0.8693\n",
      "Epoch 947/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2231 - acc: 0.9100 - val_loss: 0.2912 - val_acc: 0.8819\n",
      "Epoch 948/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2215 - acc: 0.9124 - val_loss: 0.3029 - val_acc: 0.8751\n",
      "Epoch 949/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2238 - acc: 0.9111 - val_loss: 0.2947 - val_acc: 0.8780\n",
      "Epoch 950/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2246 - acc: 0.9113 - val_loss: 0.3317 - val_acc: 0.8712\n",
      "Epoch 951/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2223 - acc: 0.9129 - val_loss: 0.3049 - val_acc: 0.8800\n",
      "Epoch 952/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2213 - acc: 0.9148 - val_loss: 0.3124 - val_acc: 0.8790\n",
      "Epoch 953/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2205 - acc: 0.9134 - val_loss: 0.3045 - val_acc: 0.8800\n",
      "Epoch 954/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2263 - acc: 0.9104 - val_loss: 0.3185 - val_acc: 0.8761\n",
      "Epoch 955/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2205 - acc: 0.9122 - val_loss: 0.2874 - val_acc: 0.8819\n",
      "Epoch 956/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2211 - acc: 0.9116 - val_loss: 0.3040 - val_acc: 0.8819\n",
      "Epoch 957/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2234 - acc: 0.9106 - val_loss: 0.3168 - val_acc: 0.8722\n",
      "Epoch 958/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2288 - acc: 0.9136 - val_loss: 0.2997 - val_acc: 0.8800\n",
      "Epoch 959/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2243 - acc: 0.9099 - val_loss: 0.2972 - val_acc: 0.8751\n",
      "Epoch 960/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2238 - acc: 0.9118 - val_loss: 0.3277 - val_acc: 0.8703\n",
      "Epoch 961/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2294 - acc: 0.9051 - val_loss: 0.3132 - val_acc: 0.8712\n",
      "Epoch 962/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2184 - acc: 0.9203 - val_loss: 0.3107 - val_acc: 0.8683\n",
      "Epoch 963/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2267 - acc: 0.9132 - val_loss: 0.2935 - val_acc: 0.8771\n",
      "Epoch 964/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2166 - acc: 0.9182 - val_loss: 0.2990 - val_acc: 0.8771\n",
      "Epoch 965/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2305 - acc: 0.9091 - val_loss: 0.3116 - val_acc: 0.8780\n",
      "Epoch 966/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2228 - acc: 0.9180 - val_loss: 0.3118 - val_acc: 0.8722\n",
      "Epoch 967/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2262 - acc: 0.9114 - val_loss: 0.2880 - val_acc: 0.8809\n",
      "Epoch 968/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2181 - acc: 0.9157 - val_loss: 0.3225 - val_acc: 0.8664\n",
      "Epoch 969/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2126 - acc: 0.9139 - val_loss: 0.3078 - val_acc: 0.8703\n",
      "Epoch 970/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2211 - acc: 0.9115 - val_loss: 0.3163 - val_acc: 0.8674\n",
      "Epoch 971/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2149 - acc: 0.9178 - val_loss: 0.3080 - val_acc: 0.8800\n",
      "Epoch 972/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2226 - acc: 0.9168 - val_loss: 0.2930 - val_acc: 0.8829\n",
      "Epoch 973/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2259 - acc: 0.9113 - val_loss: 0.3030 - val_acc: 0.8751\n",
      "Epoch 974/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2294 - acc: 0.9127 - val_loss: 0.3381 - val_acc: 0.8616\n",
      "Epoch 975/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2202 - acc: 0.9138 - val_loss: 0.3182 - val_acc: 0.8703\n",
      "Epoch 976/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2316 - acc: 0.9063 - val_loss: 0.3211 - val_acc: 0.8703\n",
      "Epoch 977/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2273 - acc: 0.9127 - val_loss: 0.2920 - val_acc: 0.8848\n",
      "Epoch 978/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2257 - acc: 0.9132 - val_loss: 0.2910 - val_acc: 0.8819\n",
      "Epoch 979/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2171 - acc: 0.9157 - val_loss: 0.3147 - val_acc: 0.8654\n",
      "Epoch 980/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2168 - acc: 0.9187 - val_loss: 0.3072 - val_acc: 0.8732\n",
      "Epoch 981/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2187 - acc: 0.9145 - val_loss: 0.3008 - val_acc: 0.8780\n",
      "Epoch 982/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2234 - acc: 0.9161 - val_loss: 0.3074 - val_acc: 0.8751\n",
      "Epoch 983/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2235 - acc: 0.9081 - val_loss: 0.2873 - val_acc: 0.8858\n",
      "Epoch 984/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2238 - acc: 0.9111 - val_loss: 0.2984 - val_acc: 0.8751\n",
      "Epoch 985/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2221 - acc: 0.9182 - val_loss: 0.3184 - val_acc: 0.8703\n",
      "Epoch 986/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2259 - acc: 0.9143 - val_loss: 0.2954 - val_acc: 0.8780\n",
      "Epoch 987/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2224 - acc: 0.9136 - val_loss: 0.3313 - val_acc: 0.8654\n",
      "Epoch 988/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2311 - acc: 0.9065 - val_loss: 0.2946 - val_acc: 0.8800\n",
      "Epoch 989/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2195 - acc: 0.9161 - val_loss: 0.3210 - val_acc: 0.8742\n",
      "Epoch 990/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2228 - acc: 0.9097 - val_loss: 0.2839 - val_acc: 0.8761\n",
      "Epoch 991/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 87s 5s/step - loss: 0.2187 - acc: 0.9097 - val_loss: 0.3072 - val_acc: 0.8751\n",
      "Epoch 992/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2163 - acc: 0.9194 - val_loss: 0.2750 - val_acc: 0.8848\n",
      "Epoch 993/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2254 - acc: 0.9123 - val_loss: 0.3078 - val_acc: 0.8722\n",
      "Epoch 994/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2272 - acc: 0.9141 - val_loss: 0.3028 - val_acc: 0.8771\n",
      "Epoch 995/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2216 - acc: 0.9153 - val_loss: 0.3068 - val_acc: 0.8751\n",
      "Epoch 996/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2256 - acc: 0.9052 - val_loss: 0.2856 - val_acc: 0.8829\n",
      "Epoch 997/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2226 - acc: 0.9106 - val_loss: 0.3032 - val_acc: 0.8771\n",
      "Epoch 998/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2199 - acc: 0.9203 - val_loss: 0.3100 - val_acc: 0.8761\n",
      "Epoch 999/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2201 - acc: 0.9139 - val_loss: 0.3167 - val_acc: 0.8703\n",
      "Epoch 1000/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2264 - acc: 0.9125 - val_loss: 0.2985 - val_acc: 0.8780\n",
      "Epoch 1001/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2203 - acc: 0.9166 - val_loss: 0.3407 - val_acc: 0.8616\n",
      "Epoch 1002/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2269 - acc: 0.9095 - val_loss: 0.3323 - val_acc: 0.8703\n",
      "Epoch 1003/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2241 - acc: 0.9171 - val_loss: 0.3117 - val_acc: 0.8742\n",
      "Epoch 1004/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2236 - acc: 0.9118 - val_loss: 0.3387 - val_acc: 0.8674\n",
      "Epoch 1005/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2301 - acc: 0.9129 - val_loss: 0.3095 - val_acc: 0.8800\n",
      "Epoch 1006/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2171 - acc: 0.9155 - val_loss: 0.2951 - val_acc: 0.8819\n",
      "Epoch 1007/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2171 - acc: 0.9132 - val_loss: 0.3160 - val_acc: 0.8732\n",
      "Epoch 1008/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2255 - acc: 0.9127 - val_loss: 0.2890 - val_acc: 0.8780\n",
      "Epoch 1009/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2203 - acc: 0.9129 - val_loss: 0.2853 - val_acc: 0.8858\n",
      "Epoch 1010/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2225 - acc: 0.9125 - val_loss: 0.3078 - val_acc: 0.8809\n",
      "Epoch 1011/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2240 - acc: 0.9134 - val_loss: 0.3038 - val_acc: 0.8761\n",
      "Epoch 1012/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2200 - acc: 0.9169 - val_loss: 0.3174 - val_acc: 0.8674\n",
      "Epoch 1013/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2246 - acc: 0.9134 - val_loss: 0.3170 - val_acc: 0.8722\n",
      "Epoch 1014/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2216 - acc: 0.9148 - val_loss: 0.2973 - val_acc: 0.8790\n",
      "Epoch 1015/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2218 - acc: 0.9150 - val_loss: 0.3042 - val_acc: 0.8829\n",
      "Epoch 1016/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2229 - acc: 0.9148 - val_loss: 0.3044 - val_acc: 0.8751\n",
      "Epoch 1017/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2172 - acc: 0.9120 - val_loss: 0.3184 - val_acc: 0.8742\n",
      "Epoch 1018/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2194 - acc: 0.9155 - val_loss: 0.3055 - val_acc: 0.8790\n",
      "Epoch 1019/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2224 - acc: 0.9162 - val_loss: 0.3212 - val_acc: 0.8732\n",
      "Epoch 1020/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2190 - acc: 0.9157 - val_loss: 0.3047 - val_acc: 0.8771\n",
      "Epoch 1021/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2221 - acc: 0.9136 - val_loss: 0.3064 - val_acc: 0.8771\n",
      "Epoch 1022/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2214 - acc: 0.9111 - val_loss: 0.3194 - val_acc: 0.8722\n",
      "Epoch 1023/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2226 - acc: 0.9159 - val_loss: 0.2902 - val_acc: 0.8800\n",
      "Epoch 1024/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2150 - acc: 0.9194 - val_loss: 0.3450 - val_acc: 0.8645\n",
      "Epoch 1025/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2199 - acc: 0.9154 - val_loss: 0.3298 - val_acc: 0.8683\n",
      "Epoch 1026/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2275 - acc: 0.9127 - val_loss: 0.3429 - val_acc: 0.8654\n",
      "Epoch 1027/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2172 - acc: 0.9148 - val_loss: 0.3263 - val_acc: 0.8664\n",
      "Epoch 1028/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2270 - acc: 0.9129 - val_loss: 0.3016 - val_acc: 0.8800\n",
      "Epoch 1029/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2157 - acc: 0.9214 - val_loss: 0.3063 - val_acc: 0.8780\n",
      "Epoch 1030/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2141 - acc: 0.9159 - val_loss: 0.3396 - val_acc: 0.8722\n",
      "Epoch 1031/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2188 - acc: 0.9148 - val_loss: 0.3336 - val_acc: 0.8693\n",
      "Epoch 1032/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2243 - acc: 0.9125 - val_loss: 0.3131 - val_acc: 0.8790\n",
      "Epoch 1033/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2119 - acc: 0.9203 - val_loss: 0.3031 - val_acc: 0.8800\n",
      "Epoch 1034/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2217 - acc: 0.9139 - val_loss: 0.3188 - val_acc: 0.8771\n",
      "Epoch 1035/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2183 - acc: 0.9120 - val_loss: 0.3056 - val_acc: 0.8751\n",
      "Epoch 1036/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2163 - acc: 0.9219 - val_loss: 0.2915 - val_acc: 0.8800\n",
      "Epoch 1037/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2092 - acc: 0.9203 - val_loss: 0.2900 - val_acc: 0.8809\n",
      "Epoch 1038/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2183 - acc: 0.9171 - val_loss: 0.3606 - val_acc: 0.8625\n",
      "Epoch 1039/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2267 - acc: 0.9138 - val_loss: 0.3314 - val_acc: 0.8664\n",
      "Epoch 1040/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2280 - acc: 0.9092 - val_loss: 0.3135 - val_acc: 0.8722\n",
      "Epoch 1041/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2165 - acc: 0.9139 - val_loss: 0.3255 - val_acc: 0.8732\n",
      "Epoch 1042/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2213 - acc: 0.9122 - val_loss: 0.2845 - val_acc: 0.8848\n",
      "Epoch 1043/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2207 - acc: 0.9148 - val_loss: 0.3049 - val_acc: 0.8800\n",
      "Epoch 1044/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2209 - acc: 0.9145 - val_loss: 0.3043 - val_acc: 0.8761\n",
      "Epoch 1045/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2211 - acc: 0.9090 - val_loss: 0.3035 - val_acc: 0.8761\n",
      "Epoch 1046/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2240 - acc: 0.9107 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 1047/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2185 - acc: 0.9129 - val_loss: 0.2881 - val_acc: 0.8877\n",
      "Epoch 1048/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2231 - acc: 0.9102 - val_loss: 0.3312 - val_acc: 0.8693\n",
      "Epoch 1049/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2219 - acc: 0.9155 - val_loss: 0.3182 - val_acc: 0.8771\n",
      "Epoch 1050/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2233 - acc: 0.9097 - val_loss: 0.3252 - val_acc: 0.8742\n",
      "Epoch 1051/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2249 - acc: 0.9102 - val_loss: 0.3291 - val_acc: 0.8771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1052/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2187 - acc: 0.9145 - val_loss: 0.3335 - val_acc: 0.8703\n",
      "Epoch 1053/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2219 - acc: 0.9116 - val_loss: 0.3223 - val_acc: 0.8674\n",
      "Epoch 1054/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2224 - acc: 0.9141 - val_loss: 0.3276 - val_acc: 0.8722\n",
      "Epoch 1055/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2135 - acc: 0.9180 - val_loss: 0.3139 - val_acc: 0.8712\n",
      "Epoch 1056/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2179 - acc: 0.9124 - val_loss: 0.3195 - val_acc: 0.8722\n",
      "Epoch 1057/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2138 - acc: 0.9201 - val_loss: 0.3238 - val_acc: 0.8664\n",
      "Epoch 1058/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2220 - acc: 0.9164 - val_loss: 0.3022 - val_acc: 0.8790\n",
      "Epoch 1059/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2191 - acc: 0.9159 - val_loss: 0.3052 - val_acc: 0.8800\n",
      "Epoch 1060/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2209 - acc: 0.9139 - val_loss: 0.2923 - val_acc: 0.8819\n",
      "Epoch 1061/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2234 - acc: 0.9106 - val_loss: 0.3215 - val_acc: 0.8742\n",
      "Epoch 1062/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2214 - acc: 0.9138 - val_loss: 0.2867 - val_acc: 0.8829\n",
      "Epoch 1063/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2175 - acc: 0.9127 - val_loss: 0.2920 - val_acc: 0.8829\n",
      "Epoch 1064/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2164 - acc: 0.9189 - val_loss: 0.2967 - val_acc: 0.8761\n",
      "Epoch 1065/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2222 - acc: 0.9178 - val_loss: 0.2981 - val_acc: 0.8848\n",
      "Epoch 1066/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2195 - acc: 0.9178 - val_loss: 0.2906 - val_acc: 0.8780\n",
      "Epoch 1067/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2165 - acc: 0.9127 - val_loss: 0.3145 - val_acc: 0.8771\n",
      "Epoch 1068/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2239 - acc: 0.9127 - val_loss: 0.3329 - val_acc: 0.8722\n",
      "Epoch 1069/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2190 - acc: 0.9141 - val_loss: 0.2839 - val_acc: 0.8867\n",
      "Epoch 1070/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2193 - acc: 0.9152 - val_loss: 0.2791 - val_acc: 0.8877\n",
      "Epoch 1071/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2135 - acc: 0.9217 - val_loss: 0.3085 - val_acc: 0.8771\n",
      "Epoch 1072/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2235 - acc: 0.9136 - val_loss: 0.2896 - val_acc: 0.8838\n",
      "Epoch 1073/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2150 - acc: 0.9148 - val_loss: 0.2965 - val_acc: 0.8829\n",
      "Epoch 1074/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2205 - acc: 0.9123 - val_loss: 0.3046 - val_acc: 0.8790\n",
      "Epoch 1075/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2147 - acc: 0.9150 - val_loss: 0.3016 - val_acc: 0.8819\n",
      "Epoch 1076/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2219 - acc: 0.9148 - val_loss: 0.2854 - val_acc: 0.8838\n",
      "Epoch 1077/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2215 - acc: 0.9191 - val_loss: 0.3221 - val_acc: 0.8751\n",
      "Epoch 1078/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2146 - acc: 0.9118 - val_loss: 0.3516 - val_acc: 0.8674\n",
      "Epoch 1079/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2272 - acc: 0.9125 - val_loss: 0.3200 - val_acc: 0.8712\n",
      "Epoch 1080/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2240 - acc: 0.9090 - val_loss: 0.3119 - val_acc: 0.8790\n",
      "Epoch 1081/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2204 - acc: 0.9109 - val_loss: 0.3156 - val_acc: 0.8693\n",
      "Epoch 1082/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2198 - acc: 0.9150 - val_loss: 0.2961 - val_acc: 0.8761\n",
      "Epoch 1083/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2200 - acc: 0.9114 - val_loss: 0.2816 - val_acc: 0.8848\n",
      "Epoch 1084/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2126 - acc: 0.9180 - val_loss: 0.2905 - val_acc: 0.8838\n",
      "Epoch 1085/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2183 - acc: 0.9143 - val_loss: 0.2793 - val_acc: 0.8829\n",
      "Epoch 1086/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2277 - acc: 0.9109 - val_loss: 0.3248 - val_acc: 0.8722\n",
      "Epoch 1087/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2185 - acc: 0.9132 - val_loss: 0.2961 - val_acc: 0.8829\n",
      "Epoch 1088/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2114 - acc: 0.9171 - val_loss: 0.3032 - val_acc: 0.8809\n",
      "Epoch 1089/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2171 - acc: 0.9173 - val_loss: 0.2870 - val_acc: 0.8838\n",
      "Epoch 1090/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2147 - acc: 0.9178 - val_loss: 0.3155 - val_acc: 0.8722\n",
      "Epoch 1091/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2218 - acc: 0.9109 - val_loss: 0.3239 - val_acc: 0.8722\n",
      "Epoch 1092/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2195 - acc: 0.9150 - val_loss: 0.3043 - val_acc: 0.8790\n",
      "Epoch 1093/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2170 - acc: 0.9171 - val_loss: 0.2878 - val_acc: 0.8819\n",
      "Epoch 1094/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2094 - acc: 0.9175 - val_loss: 0.3240 - val_acc: 0.8742\n",
      "Epoch 1095/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2178 - acc: 0.9125 - val_loss: 0.3045 - val_acc: 0.8771\n",
      "Epoch 1096/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2175 - acc: 0.9169 - val_loss: 0.3220 - val_acc: 0.8761\n",
      "Epoch 1097/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2182 - acc: 0.9187 - val_loss: 0.3006 - val_acc: 0.8809\n",
      "Epoch 1098/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2124 - acc: 0.9194 - val_loss: 0.2902 - val_acc: 0.8800\n",
      "Epoch 1099/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2169 - acc: 0.9198 - val_loss: 0.3426 - val_acc: 0.8664\n",
      "Epoch 1100/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2158 - acc: 0.9182 - val_loss: 0.3008 - val_acc: 0.8829\n",
      "Epoch 1101/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2237 - acc: 0.9145 - val_loss: 0.2974 - val_acc: 0.8790\n",
      "Epoch 1102/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2177 - acc: 0.9109 - val_loss: 0.3093 - val_acc: 0.8771\n",
      "Epoch 1103/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2159 - acc: 0.9221 - val_loss: 0.2959 - val_acc: 0.8751\n",
      "Epoch 1104/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2099 - acc: 0.9162 - val_loss: 0.3274 - val_acc: 0.8761\n",
      "Epoch 1105/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2230 - acc: 0.9111 - val_loss: 0.3017 - val_acc: 0.8800\n",
      "Epoch 1106/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2168 - acc: 0.9164 - val_loss: 0.3103 - val_acc: 0.8751\n",
      "Epoch 1107/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2124 - acc: 0.9116 - val_loss: 0.3035 - val_acc: 0.8761\n",
      "Epoch 1108/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2171 - acc: 0.9141 - val_loss: 0.3356 - val_acc: 0.8693\n",
      "Epoch 1109/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2246 - acc: 0.9129 - val_loss: 0.2970 - val_acc: 0.8771\n",
      "Epoch 1110/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2121 - acc: 0.9138 - val_loss: 0.2925 - val_acc: 0.8809\n",
      "Epoch 1111/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2207 - acc: 0.9095 - val_loss: 0.3301 - val_acc: 0.8722\n",
      "Epoch 1112/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2244 - acc: 0.9143 - val_loss: 0.2878 - val_acc: 0.8780\n",
      "Epoch 1113/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2155 - acc: 0.9207 - val_loss: 0.3062 - val_acc: 0.8780\n",
      "Epoch 1114/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2236 - acc: 0.9136 - val_loss: 0.3202 - val_acc: 0.8693\n",
      "Epoch 1115/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2167 - acc: 0.9161 - val_loss: 0.3408 - val_acc: 0.8683\n",
      "Epoch 1116/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2177 - acc: 0.9157 - val_loss: 0.3295 - val_acc: 0.8693\n",
      "Epoch 1117/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2227 - acc: 0.9166 - val_loss: 0.3277 - val_acc: 0.8693\n",
      "Epoch 1118/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2143 - acc: 0.9196 - val_loss: 0.3274 - val_acc: 0.8722\n",
      "Epoch 1119/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2180 - acc: 0.9155 - val_loss: 0.2947 - val_acc: 0.8819\n",
      "Epoch 1120/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2163 - acc: 0.9155 - val_loss: 0.2914 - val_acc: 0.8809\n",
      "Epoch 1121/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2131 - acc: 0.9194 - val_loss: 0.3084 - val_acc: 0.8751\n",
      "Epoch 1122/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2191 - acc: 0.9127 - val_loss: 0.3278 - val_acc: 0.8683\n",
      "Epoch 1123/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2197 - acc: 0.9123 - val_loss: 0.3055 - val_acc: 0.8761\n",
      "Epoch 1124/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2118 - acc: 0.9123 - val_loss: 0.3221 - val_acc: 0.8712\n",
      "Epoch 1125/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2164 - acc: 0.9141 - val_loss: 0.3059 - val_acc: 0.8732\n",
      "Epoch 1126/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2179 - acc: 0.9109 - val_loss: 0.3395 - val_acc: 0.8645\n",
      "Epoch 1127/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2166 - acc: 0.9136 - val_loss: 0.3256 - val_acc: 0.8712\n",
      "Epoch 1128/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2202 - acc: 0.9141 - val_loss: 0.2934 - val_acc: 0.8742\n",
      "Epoch 1129/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2176 - acc: 0.9173 - val_loss: 0.3205 - val_acc: 0.8693\n",
      "Epoch 1130/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2098 - acc: 0.9182 - val_loss: 0.3090 - val_acc: 0.8790\n",
      "Epoch 1131/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2154 - acc: 0.9196 - val_loss: 0.3030 - val_acc: 0.8771\n",
      "Epoch 1132/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2119 - acc: 0.9189 - val_loss: 0.3002 - val_acc: 0.8771\n",
      "Epoch 1133/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2272 - acc: 0.9106 - val_loss: 0.3158 - val_acc: 0.8790\n",
      "Epoch 1134/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2134 - acc: 0.9201 - val_loss: 0.2996 - val_acc: 0.8780\n",
      "Epoch 1135/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2207 - acc: 0.9148 - val_loss: 0.3009 - val_acc: 0.8761\n",
      "Epoch 1136/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2205 - acc: 0.9171 - val_loss: 0.3067 - val_acc: 0.8761\n",
      "Epoch 1137/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2177 - acc: 0.9178 - val_loss: 0.3045 - val_acc: 0.8780\n",
      "Epoch 1138/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2152 - acc: 0.9192 - val_loss: 0.3001 - val_acc: 0.8732\n",
      "Epoch 1139/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2201 - acc: 0.9134 - val_loss: 0.2853 - val_acc: 0.8819\n",
      "Epoch 1140/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2173 - acc: 0.9157 - val_loss: 0.3149 - val_acc: 0.8712\n",
      "Epoch 1141/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2153 - acc: 0.9109 - val_loss: 0.3064 - val_acc: 0.8751\n",
      "Epoch 1142/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2177 - acc: 0.9182 - val_loss: 0.3335 - val_acc: 0.8664\n",
      "Epoch 1143/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2099 - acc: 0.9212 - val_loss: 0.3207 - val_acc: 0.8703\n",
      "Epoch 1144/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2182 - acc: 0.9164 - val_loss: 0.3096 - val_acc: 0.8771\n",
      "Epoch 1145/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2082 - acc: 0.9224 - val_loss: 0.2944 - val_acc: 0.8800\n",
      "Epoch 1146/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2225 - acc: 0.9143 - val_loss: 0.3150 - val_acc: 0.8742\n",
      "Epoch 1147/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2183 - acc: 0.9129 - val_loss: 0.3001 - val_acc: 0.8751\n",
      "Epoch 1148/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2106 - acc: 0.9169 - val_loss: 0.3488 - val_acc: 0.8645\n",
      "Epoch 1149/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2212 - acc: 0.9143 - val_loss: 0.3032 - val_acc: 0.8771\n",
      "Epoch 1150/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2146 - acc: 0.9201 - val_loss: 0.3201 - val_acc: 0.8722\n",
      "Epoch 1151/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2133 - acc: 0.9166 - val_loss: 0.3051 - val_acc: 0.8780\n",
      "Epoch 1152/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2159 - acc: 0.9184 - val_loss: 0.2925 - val_acc: 0.8809\n",
      "Epoch 1153/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2152 - acc: 0.9191 - val_loss: 0.2804 - val_acc: 0.8867\n",
      "Epoch 1154/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2215 - acc: 0.9138 - val_loss: 0.3023 - val_acc: 0.8751\n",
      "Epoch 1155/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2162 - acc: 0.9141 - val_loss: 0.2849 - val_acc: 0.8790\n",
      "Epoch 1156/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2143 - acc: 0.9148 - val_loss: 0.3250 - val_acc: 0.8712\n",
      "Epoch 1157/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2160 - acc: 0.9159 - val_loss: 0.2957 - val_acc: 0.8780\n",
      "Epoch 1158/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2232 - acc: 0.9141 - val_loss: 0.3231 - val_acc: 0.8751\n",
      "Epoch 1159/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2126 - acc: 0.9205 - val_loss: 0.3029 - val_acc: 0.8819\n",
      "Epoch 1160/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2119 - acc: 0.9171 - val_loss: 0.2885 - val_acc: 0.8819\n",
      "Epoch 1161/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2112 - acc: 0.9189 - val_loss: 0.2963 - val_acc: 0.8819\n",
      "Epoch 1162/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2116 - acc: 0.9150 - val_loss: 0.3184 - val_acc: 0.8751\n",
      "Epoch 1163/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2136 - acc: 0.9145 - val_loss: 0.3246 - val_acc: 0.8703\n",
      "Epoch 1164/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2171 - acc: 0.9150 - val_loss: 0.2893 - val_acc: 0.8829\n",
      "Epoch 1165/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2169 - acc: 0.9173 - val_loss: 0.2716 - val_acc: 0.8848\n",
      "Epoch 1166/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2159 - acc: 0.9173 - val_loss: 0.2862 - val_acc: 0.8800\n",
      "Epoch 1167/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2221 - acc: 0.9136 - val_loss: 0.2838 - val_acc: 0.8829\n",
      "Epoch 1168/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2140 - acc: 0.9194 - val_loss: 0.3224 - val_acc: 0.8761\n",
      "Epoch 1169/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2177 - acc: 0.9162 - val_loss: 0.3133 - val_acc: 0.8780\n",
      "Epoch 1170/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2166 - acc: 0.9194 - val_loss: 0.2954 - val_acc: 0.8809\n",
      "Epoch 1171/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2088 - acc: 0.9226 - val_loss: 0.3049 - val_acc: 0.8800\n",
      "Epoch 1172/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2091 - acc: 0.9182 - val_loss: 0.2947 - val_acc: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1173/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2205 - acc: 0.9182 - val_loss: 0.3063 - val_acc: 0.8761\n",
      "Epoch 1174/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2224 - acc: 0.9113 - val_loss: 0.3123 - val_acc: 0.8790\n",
      "Epoch 1175/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2247 - acc: 0.9123 - val_loss: 0.3251 - val_acc: 0.8722\n",
      "Epoch 1176/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2148 - acc: 0.9143 - val_loss: 0.3136 - val_acc: 0.8790\n",
      "Epoch 1177/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2121 - acc: 0.9164 - val_loss: 0.3136 - val_acc: 0.8790\n",
      "Epoch 1178/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2142 - acc: 0.9157 - val_loss: 0.3331 - val_acc: 0.8654\n",
      "Epoch 1179/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2209 - acc: 0.9111 - val_loss: 0.3312 - val_acc: 0.8674\n",
      "Epoch 1180/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2231 - acc: 0.9127 - val_loss: 0.3037 - val_acc: 0.8838\n",
      "Epoch 1181/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2148 - acc: 0.9173 - val_loss: 0.3295 - val_acc: 0.8674\n",
      "Epoch 1182/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2246 - acc: 0.9171 - val_loss: 0.2844 - val_acc: 0.8800\n",
      "Epoch 1183/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2153 - acc: 0.9196 - val_loss: 0.2991 - val_acc: 0.8809\n",
      "Epoch 1184/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2047 - acc: 0.9208 - val_loss: 0.3138 - val_acc: 0.8819\n",
      "Epoch 1185/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2122 - acc: 0.9141 - val_loss: 0.3436 - val_acc: 0.8606\n",
      "Epoch 1186/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2152 - acc: 0.9176 - val_loss: 0.3153 - val_acc: 0.8761\n",
      "Epoch 1187/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2045 - acc: 0.9201 - val_loss: 0.3276 - val_acc: 0.8712\n",
      "Epoch 1188/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2163 - acc: 0.9164 - val_loss: 0.2957 - val_acc: 0.8858\n",
      "Epoch 1189/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2108 - acc: 0.9212 - val_loss: 0.2989 - val_acc: 0.8829\n",
      "Epoch 1190/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2104 - acc: 0.9203 - val_loss: 0.3053 - val_acc: 0.8848\n",
      "Epoch 1191/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2149 - acc: 0.9164 - val_loss: 0.3428 - val_acc: 0.8732\n",
      "Epoch 1192/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2078 - acc: 0.9205 - val_loss: 0.3172 - val_acc: 0.8742\n",
      "Epoch 1193/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2172 - acc: 0.9161 - val_loss: 0.3206 - val_acc: 0.8712\n",
      "Epoch 1194/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2192 - acc: 0.9148 - val_loss: 0.3013 - val_acc: 0.8819\n",
      "Epoch 1195/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2120 - acc: 0.9175 - val_loss: 0.3265 - val_acc: 0.8761\n",
      "Epoch 1196/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2060 - acc: 0.9217 - val_loss: 0.3018 - val_acc: 0.8771\n",
      "Epoch 1197/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2147 - acc: 0.9153 - val_loss: 0.3487 - val_acc: 0.8625\n",
      "Epoch 1198/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2164 - acc: 0.9159 - val_loss: 0.3316 - val_acc: 0.8693\n",
      "Epoch 1199/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2227 - acc: 0.9118 - val_loss: 0.2990 - val_acc: 0.8819\n",
      "Epoch 1200/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2131 - acc: 0.9187 - val_loss: 0.3143 - val_acc: 0.8809\n",
      "Epoch 1201/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2187 - acc: 0.9120 - val_loss: 0.3123 - val_acc: 0.8751\n",
      "Epoch 1202/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2100 - acc: 0.9210 - val_loss: 0.2881 - val_acc: 0.8858\n",
      "Epoch 1203/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1979 - acc: 0.9265 - val_loss: 0.3419 - val_acc: 0.8664\n",
      "Epoch 1204/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2200 - acc: 0.9132 - val_loss: 0.3179 - val_acc: 0.8722\n",
      "Epoch 1205/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2089 - acc: 0.9217 - val_loss: 0.3346 - val_acc: 0.8664\n",
      "Epoch 1206/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2119 - acc: 0.9180 - val_loss: 0.3221 - val_acc: 0.8703\n",
      "Epoch 1207/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2157 - acc: 0.9113 - val_loss: 0.3340 - val_acc: 0.8683\n",
      "Epoch 1208/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2181 - acc: 0.9139 - val_loss: 0.3066 - val_acc: 0.8761\n",
      "Epoch 1209/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2128 - acc: 0.9219 - val_loss: 0.3018 - val_acc: 0.8780\n",
      "Epoch 1210/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2229 - acc: 0.9132 - val_loss: 0.3288 - val_acc: 0.8722\n",
      "Epoch 1211/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2127 - acc: 0.9155 - val_loss: 0.2950 - val_acc: 0.8838\n",
      "Epoch 1212/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2107 - acc: 0.9164 - val_loss: 0.2944 - val_acc: 0.8829\n",
      "Epoch 1213/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2156 - acc: 0.9168 - val_loss: 0.2974 - val_acc: 0.8751\n",
      "Epoch 1214/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2185 - acc: 0.9139 - val_loss: 0.2952 - val_acc: 0.8829\n",
      "Epoch 1215/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2165 - acc: 0.9180 - val_loss: 0.3048 - val_acc: 0.8761\n",
      "Epoch 1216/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2099 - acc: 0.9171 - val_loss: 0.3288 - val_acc: 0.8703\n",
      "Epoch 1217/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2190 - acc: 0.9182 - val_loss: 0.3481 - val_acc: 0.8683\n",
      "Epoch 1218/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2117 - acc: 0.9145 - val_loss: 0.3584 - val_acc: 0.8674\n",
      "Epoch 1219/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2100 - acc: 0.9152 - val_loss: 0.3360 - val_acc: 0.8693\n",
      "Epoch 1220/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2137 - acc: 0.9175 - val_loss: 0.3111 - val_acc: 0.8751\n",
      "Epoch 1221/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2118 - acc: 0.9166 - val_loss: 0.2889 - val_acc: 0.8848\n",
      "Epoch 1222/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2122 - acc: 0.9164 - val_loss: 0.3170 - val_acc: 0.8732\n",
      "Epoch 1223/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2193 - acc: 0.9150 - val_loss: 0.2923 - val_acc: 0.8848\n",
      "Epoch 1224/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2133 - acc: 0.9159 - val_loss: 0.3018 - val_acc: 0.8771\n",
      "Epoch 1225/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2059 - acc: 0.9189 - val_loss: 0.2931 - val_acc: 0.8800\n",
      "Epoch 1226/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2085 - acc: 0.9157 - val_loss: 0.3252 - val_acc: 0.8732\n",
      "Epoch 1227/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2128 - acc: 0.9184 - val_loss: 0.3066 - val_acc: 0.8761\n",
      "Epoch 1228/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2052 - acc: 0.9199 - val_loss: 0.3507 - val_acc: 0.8703\n",
      "Epoch 1229/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2190 - acc: 0.9118 - val_loss: 0.3065 - val_acc: 0.8819\n",
      "Epoch 1230/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2131 - acc: 0.9163 - val_loss: 0.3013 - val_acc: 0.8809\n",
      "Epoch 1231/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2083 - acc: 0.9205 - val_loss: 0.2822 - val_acc: 0.8848\n",
      "Epoch 1232/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2119 - acc: 0.9166 - val_loss: 0.3090 - val_acc: 0.8790\n",
      "Epoch 1233/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2190 - acc: 0.9180 - val_loss: 0.3314 - val_acc: 0.8732\n",
      "Epoch 1234/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2140 - acc: 0.9180 - val_loss: 0.3340 - val_acc: 0.8722\n",
      "Epoch 1235/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2061 - acc: 0.9214 - val_loss: 0.3389 - val_acc: 0.8683\n",
      "Epoch 1236/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2099 - acc: 0.9180 - val_loss: 0.3651 - val_acc: 0.8635\n",
      "Epoch 1237/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2151 - acc: 0.9175 - val_loss: 0.3785 - val_acc: 0.8567\n",
      "Epoch 1238/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2227 - acc: 0.9042 - val_loss: 0.3126 - val_acc: 0.8790\n",
      "Epoch 1239/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2144 - acc: 0.9173 - val_loss: 0.2936 - val_acc: 0.8848\n",
      "Epoch 1240/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2111 - acc: 0.9166 - val_loss: 0.3243 - val_acc: 0.8761\n",
      "Epoch 1241/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2192 - acc: 0.9132 - val_loss: 0.2913 - val_acc: 0.8809\n",
      "Epoch 1242/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2101 - acc: 0.9182 - val_loss: 0.2931 - val_acc: 0.8800\n",
      "Epoch 1243/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2116 - acc: 0.9161 - val_loss: 0.2912 - val_acc: 0.8809\n",
      "Epoch 1244/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2186 - acc: 0.9187 - val_loss: 0.2982 - val_acc: 0.8800\n",
      "Epoch 1245/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2118 - acc: 0.9173 - val_loss: 0.2728 - val_acc: 0.8916\n",
      "Epoch 1246/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2211 - acc: 0.9100 - val_loss: 0.3159 - val_acc: 0.8693\n",
      "Epoch 1247/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2189 - acc: 0.9194 - val_loss: 0.3076 - val_acc: 0.8780\n",
      "Epoch 1248/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2203 - acc: 0.9153 - val_loss: 0.3386 - val_acc: 0.8664\n",
      "Epoch 1249/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2083 - acc: 0.9210 - val_loss: 0.3015 - val_acc: 0.8809\n",
      "Epoch 1250/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2119 - acc: 0.9166 - val_loss: 0.3022 - val_acc: 0.8761\n",
      "Epoch 1251/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2121 - acc: 0.9178 - val_loss: 0.3359 - val_acc: 0.8722\n",
      "Epoch 1252/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2075 - acc: 0.9233 - val_loss: 0.3236 - val_acc: 0.8771\n",
      "Epoch 1253/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2159 - acc: 0.9161 - val_loss: 0.3185 - val_acc: 0.8771\n",
      "Epoch 1254/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2115 - acc: 0.9228 - val_loss: 0.3237 - val_acc: 0.8761\n",
      "Epoch 1255/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2089 - acc: 0.9169 - val_loss: 0.3351 - val_acc: 0.8722\n",
      "Epoch 1256/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2166 - acc: 0.9157 - val_loss: 0.3088 - val_acc: 0.8761\n",
      "Epoch 1257/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2061 - acc: 0.9196 - val_loss: 0.2981 - val_acc: 0.8790\n",
      "Epoch 1258/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2157 - acc: 0.9164 - val_loss: 0.2998 - val_acc: 0.8732\n",
      "Epoch 1259/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2134 - acc: 0.9182 - val_loss: 0.3218 - val_acc: 0.8703\n",
      "Epoch 1260/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2169 - acc: 0.9113 - val_loss: 0.2988 - val_acc: 0.8761\n",
      "Epoch 1261/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2103 - acc: 0.9136 - val_loss: 0.3445 - val_acc: 0.8712\n",
      "Epoch 1262/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2155 - acc: 0.9224 - val_loss: 0.2951 - val_acc: 0.8751\n",
      "Epoch 1263/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2151 - acc: 0.9120 - val_loss: 0.3367 - val_acc: 0.8761\n",
      "Epoch 1264/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2087 - acc: 0.9207 - val_loss: 0.3302 - val_acc: 0.8742\n",
      "Epoch 1265/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2128 - acc: 0.9164 - val_loss: 0.2908 - val_acc: 0.8780\n",
      "Epoch 1266/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2103 - acc: 0.9205 - val_loss: 0.3093 - val_acc: 0.8771\n",
      "Epoch 1267/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2115 - acc: 0.9148 - val_loss: 0.3190 - val_acc: 0.8819\n",
      "Epoch 1268/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2073 - acc: 0.9196 - val_loss: 0.3150 - val_acc: 0.8819\n",
      "Epoch 1269/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2194 - acc: 0.9152 - val_loss: 0.3126 - val_acc: 0.8829\n",
      "Epoch 1270/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2106 - acc: 0.9212 - val_loss: 0.2935 - val_acc: 0.8780\n",
      "Epoch 1271/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2144 - acc: 0.9258 - val_loss: 0.3001 - val_acc: 0.8800\n",
      "Epoch 1272/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2120 - acc: 0.9217 - val_loss: 0.3336 - val_acc: 0.8761\n",
      "Epoch 1273/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2078 - acc: 0.9164 - val_loss: 0.3117 - val_acc: 0.8800\n",
      "Epoch 1274/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2147 - acc: 0.9157 - val_loss: 0.2976 - val_acc: 0.8858\n",
      "Epoch 1275/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2185 - acc: 0.9093 - val_loss: 0.3406 - val_acc: 0.8722\n",
      "Epoch 1276/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2136 - acc: 0.9111 - val_loss: 0.3173 - val_acc: 0.8780\n",
      "Epoch 1277/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2147 - acc: 0.9148 - val_loss: 0.3095 - val_acc: 0.8809\n",
      "Epoch 1278/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2023 - acc: 0.9226 - val_loss: 0.3166 - val_acc: 0.8800\n",
      "Epoch 1279/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2183 - acc: 0.9205 - val_loss: 0.2941 - val_acc: 0.8848\n",
      "Epoch 1280/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2056 - acc: 0.9203 - val_loss: 0.3058 - val_acc: 0.8771\n",
      "Epoch 1281/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2063 - acc: 0.9226 - val_loss: 0.2974 - val_acc: 0.8858\n",
      "Epoch 1282/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2214 - acc: 0.9196 - val_loss: 0.2796 - val_acc: 0.8877\n",
      "Epoch 1283/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2114 - acc: 0.9205 - val_loss: 0.2913 - val_acc: 0.8838\n",
      "Epoch 1284/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2126 - acc: 0.9152 - val_loss: 0.2832 - val_acc: 0.8848\n",
      "Epoch 1285/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2153 - acc: 0.9155 - val_loss: 0.2825 - val_acc: 0.8867\n",
      "Epoch 1286/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2088 - acc: 0.9192 - val_loss: 0.2916 - val_acc: 0.8800\n",
      "Epoch 1287/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2104 - acc: 0.9180 - val_loss: 0.3032 - val_acc: 0.8751\n",
      "Epoch 1288/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2075 - acc: 0.9237 - val_loss: 0.3253 - val_acc: 0.8712\n",
      "Epoch 1289/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2092 - acc: 0.9203 - val_loss: 0.2962 - val_acc: 0.8790\n",
      "Epoch 1290/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2132 - acc: 0.9164 - val_loss: 0.2876 - val_acc: 0.8771\n",
      "Epoch 1291/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2144 - acc: 0.9180 - val_loss: 0.3337 - val_acc: 0.8712\n",
      "Epoch 1292/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2203 - acc: 0.9129 - val_loss: 0.3047 - val_acc: 0.8771\n",
      "Epoch 1293/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2121 - acc: 0.9159 - val_loss: 0.3164 - val_acc: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1294/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2190 - acc: 0.9116 - val_loss: 0.3491 - val_acc: 0.8674\n",
      "Epoch 1295/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2054 - acc: 0.9205 - val_loss: 0.2914 - val_acc: 0.8780\n",
      "Epoch 1296/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2073 - acc: 0.9251 - val_loss: 0.2755 - val_acc: 0.8887\n",
      "Epoch 1297/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2149 - acc: 0.9203 - val_loss: 0.2752 - val_acc: 0.8858\n",
      "Epoch 1298/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2113 - acc: 0.9162 - val_loss: 0.3265 - val_acc: 0.8751\n",
      "Epoch 1299/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2055 - acc: 0.9228 - val_loss: 0.2950 - val_acc: 0.8809\n",
      "Epoch 1300/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2143 - acc: 0.9143 - val_loss: 0.2770 - val_acc: 0.8858\n",
      "Epoch 1301/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2080 - acc: 0.9244 - val_loss: 0.3020 - val_acc: 0.8800\n",
      "Epoch 1302/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2134 - acc: 0.9189 - val_loss: 0.2883 - val_acc: 0.8819\n",
      "Epoch 1303/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2133 - acc: 0.9182 - val_loss: 0.3380 - val_acc: 0.8664\n",
      "Epoch 1304/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2138 - acc: 0.9187 - val_loss: 0.3017 - val_acc: 0.8800\n",
      "Epoch 1305/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2128 - acc: 0.9191 - val_loss: 0.3144 - val_acc: 0.8722\n",
      "Epoch 1306/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2059 - acc: 0.9215 - val_loss: 0.3331 - val_acc: 0.8693\n",
      "Epoch 1307/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2077 - acc: 0.9203 - val_loss: 0.2968 - val_acc: 0.8742\n",
      "Epoch 1308/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2127 - acc: 0.9109 - val_loss: 0.3003 - val_acc: 0.8703\n",
      "Epoch 1309/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2135 - acc: 0.9196 - val_loss: 0.3072 - val_acc: 0.8732\n",
      "Epoch 1310/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2117 - acc: 0.9139 - val_loss: 0.3510 - val_acc: 0.8654\n",
      "Epoch 1311/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2036 - acc: 0.9219 - val_loss: 0.2844 - val_acc: 0.8800\n",
      "Epoch 1312/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2075 - acc: 0.9221 - val_loss: 0.3220 - val_acc: 0.8703\n",
      "Epoch 1313/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2130 - acc: 0.9138 - val_loss: 0.3038 - val_acc: 0.8742\n",
      "Epoch 1314/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2053 - acc: 0.9212 - val_loss: 0.3055 - val_acc: 0.8742\n",
      "Epoch 1315/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2082 - acc: 0.9217 - val_loss: 0.3095 - val_acc: 0.8683\n",
      "Epoch 1316/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2160 - acc: 0.9180 - val_loss: 0.3323 - val_acc: 0.8674\n",
      "Epoch 1317/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2073 - acc: 0.9212 - val_loss: 0.3222 - val_acc: 0.8693\n",
      "Epoch 1318/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2100 - acc: 0.9187 - val_loss: 0.3131 - val_acc: 0.8712\n",
      "Epoch 1319/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2103 - acc: 0.9198 - val_loss: 0.3129 - val_acc: 0.8722\n",
      "Epoch 1320/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2102 - acc: 0.9191 - val_loss: 0.3034 - val_acc: 0.8761\n",
      "Epoch 1321/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2068 - acc: 0.9247 - val_loss: 0.2962 - val_acc: 0.8867\n",
      "Epoch 1322/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2090 - acc: 0.9166 - val_loss: 0.2959 - val_acc: 0.8771\n",
      "Epoch 1323/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2131 - acc: 0.9168 - val_loss: 0.2770 - val_acc: 0.8896\n",
      "Epoch 1324/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2168 - acc: 0.9189 - val_loss: 0.3311 - val_acc: 0.8664\n",
      "Epoch 1325/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2090 - acc: 0.9230 - val_loss: 0.3416 - val_acc: 0.8693\n",
      "Epoch 1326/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2058 - acc: 0.9200 - val_loss: 0.3025 - val_acc: 0.8771\n",
      "Epoch 1327/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2018 - acc: 0.9228 - val_loss: 0.2784 - val_acc: 0.8887\n",
      "Epoch 1328/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2091 - acc: 0.9258 - val_loss: 0.3123 - val_acc: 0.8751\n",
      "Epoch 1329/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2086 - acc: 0.9212 - val_loss: 0.3403 - val_acc: 0.8635\n",
      "Epoch 1330/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2118 - acc: 0.9194 - val_loss: 0.3200 - val_acc: 0.8780\n",
      "Epoch 1331/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2102 - acc: 0.9254 - val_loss: 0.3137 - val_acc: 0.8780\n",
      "Epoch 1332/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2112 - acc: 0.9203 - val_loss: 0.3047 - val_acc: 0.8742\n",
      "Epoch 1333/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2099 - acc: 0.9155 - val_loss: 0.3369 - val_acc: 0.8674\n",
      "Epoch 1334/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2071 - acc: 0.9224 - val_loss: 0.3056 - val_acc: 0.8790\n",
      "Epoch 1335/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2085 - acc: 0.9127 - val_loss: 0.3379 - val_acc: 0.8683\n",
      "Epoch 1336/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2134 - acc: 0.9169 - val_loss: 0.3262 - val_acc: 0.8712\n",
      "Epoch 1337/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2014 - acc: 0.9233 - val_loss: 0.2854 - val_acc: 0.8887\n",
      "Epoch 1338/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2048 - acc: 0.9210 - val_loss: 0.3095 - val_acc: 0.8819\n",
      "Epoch 1339/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2152 - acc: 0.9159 - val_loss: 0.3207 - val_acc: 0.8780\n",
      "Epoch 1340/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2167 - acc: 0.9180 - val_loss: 0.2884 - val_acc: 0.8887\n",
      "Epoch 1341/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2102 - acc: 0.9180 - val_loss: 0.3127 - val_acc: 0.8800\n",
      "Epoch 1342/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2131 - acc: 0.9166 - val_loss: 0.2932 - val_acc: 0.8858\n",
      "Epoch 1343/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2143 - acc: 0.9194 - val_loss: 0.2773 - val_acc: 0.8858\n",
      "Epoch 1344/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2089 - acc: 0.9201 - val_loss: 0.3086 - val_acc: 0.8780\n",
      "Epoch 1345/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2111 - acc: 0.9231 - val_loss: 0.2957 - val_acc: 0.8906\n",
      "Epoch 1346/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2074 - acc: 0.9212 - val_loss: 0.3344 - val_acc: 0.8625\n",
      "Epoch 1347/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2113 - acc: 0.9196 - val_loss: 0.3369 - val_acc: 0.8674\n",
      "Epoch 1348/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2199 - acc: 0.9123 - val_loss: 0.2937 - val_acc: 0.8829\n",
      "Epoch 1349/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2119 - acc: 0.9207 - val_loss: 0.2972 - val_acc: 0.8829\n",
      "Epoch 1350/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2195 - acc: 0.9097 - val_loss: 0.2946 - val_acc: 0.8867\n",
      "Epoch 1351/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2142 - acc: 0.9203 - val_loss: 0.2849 - val_acc: 0.8858\n",
      "Epoch 1352/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2160 - acc: 0.9155 - val_loss: 0.3006 - val_acc: 0.8819\n",
      "Epoch 1353/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2171 - acc: 0.9182 - val_loss: 0.3233 - val_acc: 0.8780\n",
      "Epoch 1354/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2080 - acc: 0.9169 - val_loss: 0.2951 - val_acc: 0.8838\n",
      "Epoch 1355/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2102 - acc: 0.9233 - val_loss: 0.2900 - val_acc: 0.8819\n",
      "Epoch 1356/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2129 - acc: 0.9162 - val_loss: 0.2928 - val_acc: 0.8800\n",
      "Epoch 1357/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2083 - acc: 0.9192 - val_loss: 0.2862 - val_acc: 0.8896\n",
      "Epoch 1358/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2099 - acc: 0.9205 - val_loss: 0.2992 - val_acc: 0.8838\n",
      "Epoch 1359/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2130 - acc: 0.9111 - val_loss: 0.3118 - val_acc: 0.8761\n",
      "Epoch 1360/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2042 - acc: 0.9228 - val_loss: 0.2919 - val_acc: 0.8790\n",
      "Epoch 1361/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2171 - acc: 0.9173 - val_loss: 0.3153 - val_acc: 0.8761\n",
      "Epoch 1362/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2094 - acc: 0.9175 - val_loss: 0.2890 - val_acc: 0.8829\n",
      "Epoch 1363/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2175 - acc: 0.9182 - val_loss: 0.3402 - val_acc: 0.8712\n",
      "Epoch 1364/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2022 - acc: 0.9242 - val_loss: 0.2969 - val_acc: 0.8751\n",
      "Epoch 1365/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2115 - acc: 0.9148 - val_loss: 0.3107 - val_acc: 0.8761\n",
      "Epoch 1366/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2087 - acc: 0.9189 - val_loss: 0.3202 - val_acc: 0.8761\n",
      "Epoch 1367/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2083 - acc: 0.9210 - val_loss: 0.3365 - val_acc: 0.8742\n",
      "Epoch 1368/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2088 - acc: 0.9155 - val_loss: 0.2911 - val_acc: 0.8896\n",
      "Epoch 1369/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2059 - acc: 0.9201 - val_loss: 0.3196 - val_acc: 0.8722\n",
      "Epoch 1370/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2076 - acc: 0.9175 - val_loss: 0.2999 - val_acc: 0.8800\n",
      "Epoch 1371/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2068 - acc: 0.9208 - val_loss: 0.3090 - val_acc: 0.8780\n",
      "Epoch 1372/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2061 - acc: 0.9224 - val_loss: 0.3326 - val_acc: 0.8674\n",
      "Epoch 1373/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2112 - acc: 0.9251 - val_loss: 0.2944 - val_acc: 0.8858\n",
      "Epoch 1374/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2058 - acc: 0.9189 - val_loss: 0.3061 - val_acc: 0.8838\n",
      "Epoch 1375/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2027 - acc: 0.9191 - val_loss: 0.3103 - val_acc: 0.8829\n",
      "Epoch 1376/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2062 - acc: 0.9212 - val_loss: 0.3270 - val_acc: 0.8751\n",
      "Epoch 1377/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2122 - acc: 0.9187 - val_loss: 0.3094 - val_acc: 0.8819\n",
      "Epoch 1378/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1994 - acc: 0.9265 - val_loss: 0.3360 - val_acc: 0.8712\n",
      "Epoch 1379/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2094 - acc: 0.9215 - val_loss: 0.3341 - val_acc: 0.8674\n",
      "Epoch 1380/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2010 - acc: 0.9221 - val_loss: 0.3218 - val_acc: 0.8712\n",
      "Epoch 1381/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2134 - acc: 0.9196 - val_loss: 0.3113 - val_acc: 0.8751\n",
      "Epoch 1382/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2058 - acc: 0.9224 - val_loss: 0.3424 - val_acc: 0.8683\n",
      "Epoch 1383/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2094 - acc: 0.9223 - val_loss: 0.2857 - val_acc: 0.8867\n",
      "Epoch 1384/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2034 - acc: 0.9198 - val_loss: 0.2918 - val_acc: 0.8780\n",
      "Epoch 1385/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2034 - acc: 0.9182 - val_loss: 0.3326 - val_acc: 0.8742\n",
      "Epoch 1386/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2044 - acc: 0.9189 - val_loss: 0.3305 - val_acc: 0.8771\n",
      "Epoch 1387/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2178 - acc: 0.9150 - val_loss: 0.3099 - val_acc: 0.8829\n",
      "Epoch 1388/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2120 - acc: 0.9173 - val_loss: 0.3015 - val_acc: 0.8896\n",
      "Epoch 1389/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2053 - acc: 0.9173 - val_loss: 0.3220 - val_acc: 0.8742\n",
      "Epoch 1390/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2067 - acc: 0.9240 - val_loss: 0.3236 - val_acc: 0.8751\n",
      "Epoch 1391/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2218 - acc: 0.9173 - val_loss: 0.3458 - val_acc: 0.8645\n",
      "Epoch 1392/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2168 - acc: 0.9153 - val_loss: 0.3059 - val_acc: 0.8771\n",
      "Epoch 1393/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2053 - acc: 0.9214 - val_loss: 0.3305 - val_acc: 0.8722\n",
      "Epoch 1394/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2173 - acc: 0.9184 - val_loss: 0.3057 - val_acc: 0.8819\n",
      "Epoch 1395/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2119 - acc: 0.9182 - val_loss: 0.3156 - val_acc: 0.8790\n",
      "Epoch 1396/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2023 - acc: 0.9244 - val_loss: 0.2923 - val_acc: 0.8819\n",
      "Epoch 1397/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2136 - acc: 0.9205 - val_loss: 0.2917 - val_acc: 0.8800\n",
      "Epoch 1398/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2027 - acc: 0.9272 - val_loss: 0.2966 - val_acc: 0.8800\n",
      "Epoch 1399/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2134 - acc: 0.9185 - val_loss: 0.2942 - val_acc: 0.8867\n",
      "Epoch 1400/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2160 - acc: 0.9169 - val_loss: 0.3255 - val_acc: 0.8771\n",
      "Epoch 1401/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2045 - acc: 0.9267 - val_loss: 0.3023 - val_acc: 0.8800\n",
      "Epoch 1402/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2124 - acc: 0.9196 - val_loss: 0.2956 - val_acc: 0.8858\n",
      "Epoch 1403/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2086 - acc: 0.9191 - val_loss: 0.2919 - val_acc: 0.8848\n",
      "Epoch 1404/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2073 - acc: 0.9194 - val_loss: 0.2999 - val_acc: 0.8809\n",
      "Epoch 1405/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2059 - acc: 0.9175 - val_loss: 0.3387 - val_acc: 0.8742\n",
      "Epoch 1406/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2121 - acc: 0.9152 - val_loss: 0.3438 - val_acc: 0.8645\n",
      "Epoch 1407/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2098 - acc: 0.9203 - val_loss: 0.3102 - val_acc: 0.8800\n",
      "Epoch 1408/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2132 - acc: 0.9212 - val_loss: 0.3039 - val_acc: 0.8780\n",
      "Epoch 1409/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2088 - acc: 0.9189 - val_loss: 0.3483 - val_acc: 0.8654\n",
      "Epoch 1410/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2071 - acc: 0.9238 - val_loss: 0.3037 - val_acc: 0.8800\n",
      "Epoch 1411/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2077 - acc: 0.9168 - val_loss: 0.2921 - val_acc: 0.8809\n",
      "Epoch 1412/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2089 - acc: 0.9221 - val_loss: 0.2829 - val_acc: 0.8877\n",
      "Epoch 1413/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2080 - acc: 0.9226 - val_loss: 0.2963 - val_acc: 0.8829\n",
      "Epoch 1414/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2182 - acc: 0.9116 - val_loss: 0.3263 - val_acc: 0.8742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1415/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2062 - acc: 0.9224 - val_loss: 0.3055 - val_acc: 0.8809\n",
      "Epoch 1416/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2041 - acc: 0.9217 - val_loss: 0.2989 - val_acc: 0.8790\n",
      "Epoch 1417/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2043 - acc: 0.9210 - val_loss: 0.2999 - val_acc: 0.8819\n",
      "Epoch 1418/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1996 - acc: 0.9219 - val_loss: 0.3100 - val_acc: 0.8780\n",
      "Epoch 1419/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2171 - acc: 0.9127 - val_loss: 0.2996 - val_acc: 0.8751\n",
      "Epoch 1420/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2174 - acc: 0.9141 - val_loss: 0.3025 - val_acc: 0.8771\n",
      "Epoch 1421/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2036 - acc: 0.9242 - val_loss: 0.2868 - val_acc: 0.8867\n",
      "Epoch 1422/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2054 - acc: 0.9208 - val_loss: 0.2809 - val_acc: 0.8906\n",
      "Epoch 1423/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2025 - acc: 0.9217 - val_loss: 0.3149 - val_acc: 0.8751\n",
      "Epoch 1424/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2006 - acc: 0.9265 - val_loss: 0.3370 - val_acc: 0.8645\n",
      "Epoch 1425/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2061 - acc: 0.9226 - val_loss: 0.3013 - val_acc: 0.8809\n",
      "Epoch 1426/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2050 - acc: 0.9219 - val_loss: 0.3033 - val_acc: 0.8751\n",
      "Epoch 1427/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2035 - acc: 0.9242 - val_loss: 0.2995 - val_acc: 0.8790\n",
      "Epoch 1428/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2176 - acc: 0.9136 - val_loss: 0.3016 - val_acc: 0.8800\n",
      "Epoch 1429/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2055 - acc: 0.9207 - val_loss: 0.3109 - val_acc: 0.8751\n",
      "Epoch 1430/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2160 - acc: 0.9160 - val_loss: 0.3206 - val_acc: 0.8683\n",
      "Epoch 1431/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2076 - acc: 0.9205 - val_loss: 0.3011 - val_acc: 0.8809\n",
      "Epoch 1432/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2088 - acc: 0.9224 - val_loss: 0.3316 - val_acc: 0.8674\n",
      "Epoch 1433/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2063 - acc: 0.9210 - val_loss: 0.2939 - val_acc: 0.8771\n",
      "Epoch 1434/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2101 - acc: 0.9185 - val_loss: 0.3002 - val_acc: 0.8780\n",
      "Epoch 1435/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1956 - acc: 0.9265 - val_loss: 0.2958 - val_acc: 0.8819\n",
      "Epoch 1436/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2095 - acc: 0.9230 - val_loss: 0.3228 - val_acc: 0.8712\n",
      "Epoch 1437/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2046 - acc: 0.9196 - val_loss: 0.2940 - val_acc: 0.8800\n",
      "Epoch 1438/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2104 - acc: 0.9224 - val_loss: 0.3262 - val_acc: 0.8683\n",
      "Epoch 1439/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2047 - acc: 0.9226 - val_loss: 0.3332 - val_acc: 0.8703\n",
      "Epoch 1440/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2133 - acc: 0.9182 - val_loss: 0.3339 - val_acc: 0.8683\n",
      "Epoch 1441/2000\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.2107 - acc: 0.9109 - val_loss: 0.3158 - val_acc: 0.8742\n",
      "Epoch 1442/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2057 - acc: 0.9221 - val_loss: 0.3192 - val_acc: 0.8703\n",
      "Epoch 1443/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2105 - acc: 0.9191 - val_loss: 0.3139 - val_acc: 0.8732\n",
      "Epoch 1444/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2104 - acc: 0.9196 - val_loss: 0.2907 - val_acc: 0.8800\n",
      "Epoch 1445/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2001 - acc: 0.9201 - val_loss: 0.3154 - val_acc: 0.8751\n",
      "Epoch 1446/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2106 - acc: 0.9203 - val_loss: 0.2872 - val_acc: 0.8819\n",
      "Epoch 1447/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2068 - acc: 0.9215 - val_loss: 0.3614 - val_acc: 0.8616\n",
      "Epoch 1448/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2138 - acc: 0.9214 - val_loss: 0.2977 - val_acc: 0.8838\n",
      "Epoch 1449/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2142 - acc: 0.9185 - val_loss: 0.3154 - val_acc: 0.8703\n",
      "Epoch 1450/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2097 - acc: 0.9189 - val_loss: 0.2970 - val_acc: 0.8819\n",
      "Epoch 1451/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2079 - acc: 0.9189 - val_loss: 0.3342 - val_acc: 0.8712\n",
      "Epoch 1452/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2013 - acc: 0.9274 - val_loss: 0.3086 - val_acc: 0.8800\n",
      "Epoch 1453/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1999 - acc: 0.9253 - val_loss: 0.2984 - val_acc: 0.8800\n",
      "Epoch 1454/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2061 - acc: 0.9189 - val_loss: 0.3029 - val_acc: 0.8790\n",
      "Epoch 1455/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2136 - acc: 0.9173 - val_loss: 0.3050 - val_acc: 0.8790\n",
      "Epoch 1456/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2028 - acc: 0.9233 - val_loss: 0.2990 - val_acc: 0.8819\n",
      "Epoch 1457/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2061 - acc: 0.9182 - val_loss: 0.3236 - val_acc: 0.8761\n",
      "Epoch 1458/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2079 - acc: 0.9203 - val_loss: 0.3068 - val_acc: 0.8790\n",
      "Epoch 1459/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2069 - acc: 0.9180 - val_loss: 0.2914 - val_acc: 0.8858\n",
      "Epoch 1460/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2122 - acc: 0.9191 - val_loss: 0.3091 - val_acc: 0.8761\n",
      "Epoch 1461/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2010 - acc: 0.9249 - val_loss: 0.3317 - val_acc: 0.8742\n",
      "Epoch 1462/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2109 - acc: 0.9249 - val_loss: 0.3068 - val_acc: 0.8771\n",
      "Epoch 1463/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2114 - acc: 0.9184 - val_loss: 0.2970 - val_acc: 0.8751\n",
      "Epoch 1464/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2093 - acc: 0.9240 - val_loss: 0.3214 - val_acc: 0.8742\n",
      "Epoch 1465/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2060 - acc: 0.9221 - val_loss: 0.3067 - val_acc: 0.8703\n",
      "Epoch 1466/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2042 - acc: 0.9228 - val_loss: 0.3392 - val_acc: 0.8712\n",
      "Epoch 1467/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2074 - acc: 0.9205 - val_loss: 0.3482 - val_acc: 0.8625\n",
      "Epoch 1468/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2016 - acc: 0.9233 - val_loss: 0.2959 - val_acc: 0.8819\n",
      "Epoch 1469/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2164 - acc: 0.9125 - val_loss: 0.3321 - val_acc: 0.8722\n",
      "Epoch 1470/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2007 - acc: 0.9201 - val_loss: 0.3620 - val_acc: 0.8674\n",
      "Epoch 1471/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2047 - acc: 0.9205 - val_loss: 0.2995 - val_acc: 0.8790\n",
      "Epoch 1472/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2080 - acc: 0.9148 - val_loss: 0.2999 - val_acc: 0.8790\n",
      "Epoch 1473/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2082 - acc: 0.9203 - val_loss: 0.2803 - val_acc: 0.8887\n",
      "Epoch 1474/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1996 - acc: 0.9265 - val_loss: 0.2833 - val_acc: 0.8867\n",
      "Epoch 1475/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2024 - acc: 0.9201 - val_loss: 0.3190 - val_acc: 0.8732\n",
      "Epoch 1476/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2138 - acc: 0.9173 - val_loss: 0.3021 - val_acc: 0.8848\n",
      "Epoch 1477/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2088 - acc: 0.9219 - val_loss: 0.3083 - val_acc: 0.8780\n",
      "Epoch 1478/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2049 - acc: 0.9194 - val_loss: 0.3113 - val_acc: 0.8751\n",
      "Epoch 1479/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2058 - acc: 0.9159 - val_loss: 0.3235 - val_acc: 0.8712\n",
      "Epoch 1480/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2098 - acc: 0.9224 - val_loss: 0.3222 - val_acc: 0.8712\n",
      "Epoch 1481/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2050 - acc: 0.9242 - val_loss: 0.3447 - val_acc: 0.8635\n",
      "Epoch 1482/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1987 - acc: 0.9240 - val_loss: 0.3029 - val_acc: 0.8732\n",
      "Epoch 1483/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2025 - acc: 0.9235 - val_loss: 0.3191 - val_acc: 0.8771\n",
      "Epoch 1484/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2130 - acc: 0.9210 - val_loss: 0.3146 - val_acc: 0.8751\n",
      "Epoch 1485/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2107 - acc: 0.9200 - val_loss: 0.3109 - val_acc: 0.8771\n",
      "Epoch 1486/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1990 - acc: 0.9226 - val_loss: 0.3328 - val_acc: 0.8674\n",
      "Epoch 1487/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2041 - acc: 0.9192 - val_loss: 0.3301 - val_acc: 0.8761\n",
      "Epoch 1488/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1995 - acc: 0.9260 - val_loss: 0.2971 - val_acc: 0.8790\n",
      "Epoch 1489/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2095 - acc: 0.9129 - val_loss: 0.3453 - val_acc: 0.8674\n",
      "Epoch 1490/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2080 - acc: 0.9198 - val_loss: 0.2903 - val_acc: 0.8819\n",
      "Epoch 1491/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2071 - acc: 0.9208 - val_loss: 0.3083 - val_acc: 0.8703\n",
      "Epoch 1492/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1996 - acc: 0.9281 - val_loss: 0.3338 - val_acc: 0.8654\n",
      "Epoch 1493/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2158 - acc: 0.9136 - val_loss: 0.3498 - val_acc: 0.8645\n",
      "Epoch 1494/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1992 - acc: 0.9237 - val_loss: 0.2978 - val_acc: 0.8838\n",
      "Epoch 1495/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2162 - acc: 0.9157 - val_loss: 0.2946 - val_acc: 0.8800\n",
      "Epoch 1496/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1999 - acc: 0.9267 - val_loss: 0.2812 - val_acc: 0.8896\n",
      "Epoch 1497/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2052 - acc: 0.9201 - val_loss: 0.2959 - val_acc: 0.8809\n",
      "Epoch 1498/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2072 - acc: 0.9219 - val_loss: 0.3262 - val_acc: 0.8693\n",
      "Epoch 1499/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2035 - acc: 0.9214 - val_loss: 0.2921 - val_acc: 0.8819\n",
      "Epoch 1500/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2005 - acc: 0.9237 - val_loss: 0.3044 - val_acc: 0.8742\n",
      "Epoch 1501/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2040 - acc: 0.9237 - val_loss: 0.3006 - val_acc: 0.8751\n",
      "Epoch 1502/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2074 - acc: 0.9222 - val_loss: 0.3101 - val_acc: 0.8780\n",
      "Epoch 1503/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2040 - acc: 0.9214 - val_loss: 0.3225 - val_acc: 0.8683\n",
      "Epoch 1504/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2007 - acc: 0.9231 - val_loss: 0.2904 - val_acc: 0.8867\n",
      "Epoch 1505/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2137 - acc: 0.9182 - val_loss: 0.2802 - val_acc: 0.8829\n",
      "Epoch 1506/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2097 - acc: 0.9242 - val_loss: 0.3182 - val_acc: 0.8712\n",
      "Epoch 1507/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2035 - acc: 0.9198 - val_loss: 0.2949 - val_acc: 0.8829\n",
      "Epoch 1508/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1967 - acc: 0.9268 - val_loss: 0.3033 - val_acc: 0.8780\n",
      "Epoch 1509/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1968 - acc: 0.9279 - val_loss: 0.3146 - val_acc: 0.8732\n",
      "Epoch 1510/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1995 - acc: 0.9258 - val_loss: 0.2822 - val_acc: 0.8858\n",
      "Epoch 1511/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1992 - acc: 0.9281 - val_loss: 0.3069 - val_acc: 0.8742\n",
      "Epoch 1512/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2058 - acc: 0.9228 - val_loss: 0.3067 - val_acc: 0.8809\n",
      "Epoch 1513/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1994 - acc: 0.9189 - val_loss: 0.3142 - val_acc: 0.8751\n",
      "Epoch 1514/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2163 - acc: 0.9171 - val_loss: 0.3114 - val_acc: 0.8751\n",
      "Epoch 1515/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2073 - acc: 0.9194 - val_loss: 0.3065 - val_acc: 0.8761\n",
      "Epoch 1516/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2026 - acc: 0.9192 - val_loss: 0.3267 - val_acc: 0.8664\n",
      "Epoch 1517/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2002 - acc: 0.9242 - val_loss: 0.3057 - val_acc: 0.8732\n",
      "Epoch 1518/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1994 - acc: 0.9198 - val_loss: 0.3036 - val_acc: 0.8771\n",
      "Epoch 1519/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2071 - acc: 0.9219 - val_loss: 0.2937 - val_acc: 0.8838\n",
      "Epoch 1520/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1946 - acc: 0.9284 - val_loss: 0.3204 - val_acc: 0.8664\n",
      "Epoch 1521/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2040 - acc: 0.9242 - val_loss: 0.3012 - val_acc: 0.8732\n",
      "Epoch 1522/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2210 - acc: 0.9093 - val_loss: 0.3414 - val_acc: 0.8674\n",
      "Epoch 1523/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2153 - acc: 0.9118 - val_loss: 0.3310 - val_acc: 0.8693\n",
      "Epoch 1524/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2064 - acc: 0.9203 - val_loss: 0.2994 - val_acc: 0.8790\n",
      "Epoch 1525/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2057 - acc: 0.9194 - val_loss: 0.3181 - val_acc: 0.8722\n",
      "Epoch 1526/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2047 - acc: 0.9219 - val_loss: 0.3415 - val_acc: 0.8703\n",
      "Epoch 1527/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2112 - acc: 0.9201 - val_loss: 0.3144 - val_acc: 0.8742\n",
      "Epoch 1528/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2052 - acc: 0.9240 - val_loss: 0.3466 - val_acc: 0.8654\n",
      "Epoch 1529/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2023 - acc: 0.9256 - val_loss: 0.3187 - val_acc: 0.8771\n",
      "Epoch 1530/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2112 - acc: 0.9217 - val_loss: 0.3537 - val_acc: 0.8645\n",
      "Epoch 1531/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2024 - acc: 0.9244 - val_loss: 0.3335 - val_acc: 0.8693\n",
      "Epoch 1532/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2147 - acc: 0.9180 - val_loss: 0.3172 - val_acc: 0.8771\n",
      "Epoch 1533/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2013 - acc: 0.9235 - val_loss: 0.3091 - val_acc: 0.8838\n",
      "Epoch 1534/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1994 - acc: 0.9274 - val_loss: 0.3142 - val_acc: 0.8819\n",
      "Epoch 1535/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2001 - acc: 0.9267 - val_loss: 0.3245 - val_acc: 0.8751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1536/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2027 - acc: 0.9242 - val_loss: 0.3176 - val_acc: 0.8761\n",
      "Epoch 1537/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2015 - acc: 0.9226 - val_loss: 0.3367 - val_acc: 0.8674\n",
      "Epoch 1538/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2057 - acc: 0.9208 - val_loss: 0.3041 - val_acc: 0.8819\n",
      "Epoch 1539/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2022 - acc: 0.9231 - val_loss: 0.3011 - val_acc: 0.8829\n",
      "Epoch 1540/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1977 - acc: 0.9228 - val_loss: 0.3059 - val_acc: 0.8800\n",
      "Epoch 1541/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2107 - acc: 0.9201 - val_loss: 0.3051 - val_acc: 0.8809\n",
      "Epoch 1542/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2010 - acc: 0.9244 - val_loss: 0.3399 - val_acc: 0.8722\n",
      "Epoch 1543/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2141 - acc: 0.9153 - val_loss: 0.3150 - val_acc: 0.8809\n",
      "Epoch 1544/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2067 - acc: 0.9226 - val_loss: 0.2843 - val_acc: 0.8935\n",
      "Epoch 1545/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1994 - acc: 0.9240 - val_loss: 0.3422 - val_acc: 0.8693\n",
      "Epoch 1546/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2092 - acc: 0.9244 - val_loss: 0.3181 - val_acc: 0.8838\n",
      "Epoch 1547/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2050 - acc: 0.9242 - val_loss: 0.3015 - val_acc: 0.8858\n",
      "Epoch 1548/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2132 - acc: 0.9199 - val_loss: 0.3381 - val_acc: 0.8654\n",
      "Epoch 1549/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2112 - acc: 0.9219 - val_loss: 0.3083 - val_acc: 0.8829\n",
      "Epoch 1550/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2012 - acc: 0.9221 - val_loss: 0.3169 - val_acc: 0.8722\n",
      "Epoch 1551/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2041 - acc: 0.9203 - val_loss: 0.2931 - val_acc: 0.8858\n",
      "Epoch 1552/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1981 - acc: 0.9205 - val_loss: 0.3188 - val_acc: 0.8780\n",
      "Epoch 1553/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1960 - acc: 0.9201 - val_loss: 0.3303 - val_acc: 0.8722\n",
      "Epoch 1554/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2073 - acc: 0.9175 - val_loss: 0.3601 - val_acc: 0.8635\n",
      "Epoch 1555/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2017 - acc: 0.9201 - val_loss: 0.3865 - val_acc: 0.8606\n",
      "Epoch 1556/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1953 - acc: 0.9304 - val_loss: 0.3146 - val_acc: 0.8771\n",
      "Epoch 1557/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2006 - acc: 0.9256 - val_loss: 0.3023 - val_acc: 0.8877\n",
      "Epoch 1558/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2084 - acc: 0.9198 - val_loss: 0.2874 - val_acc: 0.8848\n",
      "Epoch 1559/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2057 - acc: 0.9208 - val_loss: 0.2935 - val_acc: 0.8916\n",
      "Epoch 1560/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2110 - acc: 0.9201 - val_loss: 0.3030 - val_acc: 0.8877\n",
      "Epoch 1561/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2090 - acc: 0.9178 - val_loss: 0.3064 - val_acc: 0.8800\n",
      "Epoch 1562/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2060 - acc: 0.9203 - val_loss: 0.3220 - val_acc: 0.8819\n",
      "Epoch 1563/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1980 - acc: 0.9263 - val_loss: 0.3192 - val_acc: 0.8838\n",
      "Epoch 1564/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2014 - acc: 0.9233 - val_loss: 0.2864 - val_acc: 0.8916\n",
      "Epoch 1565/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2015 - acc: 0.9210 - val_loss: 0.3039 - val_acc: 0.8925\n",
      "Epoch 1566/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2003 - acc: 0.9230 - val_loss: 0.3061 - val_acc: 0.8896\n",
      "Epoch 1567/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1997 - acc: 0.9240 - val_loss: 0.2920 - val_acc: 0.8887\n",
      "Epoch 1568/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2029 - acc: 0.9219 - val_loss: 0.2963 - val_acc: 0.8877\n",
      "Epoch 1569/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1978 - acc: 0.9253 - val_loss: 0.2845 - val_acc: 0.8974\n",
      "Epoch 1570/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1982 - acc: 0.9254 - val_loss: 0.3061 - val_acc: 0.8838\n",
      "Epoch 1571/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2013 - acc: 0.9270 - val_loss: 0.3105 - val_acc: 0.8780\n",
      "Epoch 1572/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2074 - acc: 0.9231 - val_loss: 0.2942 - val_acc: 0.8858\n",
      "Epoch 1573/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1968 - acc: 0.9233 - val_loss: 0.2980 - val_acc: 0.8877\n",
      "Epoch 1574/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2045 - acc: 0.9254 - val_loss: 0.2845 - val_acc: 0.8906\n",
      "Epoch 1575/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1944 - acc: 0.9251 - val_loss: 0.3001 - val_acc: 0.8858\n",
      "Epoch 1576/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1971 - acc: 0.9265 - val_loss: 0.3010 - val_acc: 0.8867\n",
      "Epoch 1577/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2123 - acc: 0.9212 - val_loss: 0.3167 - val_acc: 0.8838\n",
      "Epoch 1578/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2066 - acc: 0.9180 - val_loss: 0.2887 - val_acc: 0.8867\n",
      "Epoch 1579/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2051 - acc: 0.9191 - val_loss: 0.2774 - val_acc: 0.8877\n",
      "Epoch 1580/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2077 - acc: 0.9164 - val_loss: 0.2956 - val_acc: 0.8829\n",
      "Epoch 1581/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1970 - acc: 0.9212 - val_loss: 0.2899 - val_acc: 0.8887\n",
      "Epoch 1582/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1979 - acc: 0.9221 - val_loss: 0.3213 - val_acc: 0.8722\n",
      "Epoch 1583/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1962 - acc: 0.9235 - val_loss: 0.3043 - val_acc: 0.8848\n",
      "Epoch 1584/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1909 - acc: 0.9260 - val_loss: 0.3477 - val_acc: 0.8674\n",
      "Epoch 1585/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2020 - acc: 0.9178 - val_loss: 0.3100 - val_acc: 0.8809\n",
      "Epoch 1586/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1986 - acc: 0.9240 - val_loss: 0.2718 - val_acc: 0.8848\n",
      "Epoch 1587/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2006 - acc: 0.9214 - val_loss: 0.2996 - val_acc: 0.8867\n",
      "Epoch 1588/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1961 - acc: 0.9313 - val_loss: 0.3171 - val_acc: 0.8790\n",
      "Epoch 1589/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2046 - acc: 0.9208 - val_loss: 0.2885 - val_acc: 0.8838\n",
      "Epoch 1590/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2019 - acc: 0.9230 - val_loss: 0.2930 - val_acc: 0.8877\n",
      "Epoch 1591/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2111 - acc: 0.9171 - val_loss: 0.3134 - val_acc: 0.8809\n",
      "Epoch 1592/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2052 - acc: 0.9214 - val_loss: 0.3067 - val_acc: 0.8858\n",
      "Epoch 1593/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2045 - acc: 0.9212 - val_loss: 0.2971 - val_acc: 0.8829\n",
      "Epoch 1594/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2103 - acc: 0.9159 - val_loss: 0.3108 - val_acc: 0.8838\n",
      "Epoch 1595/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2079 - acc: 0.9251 - val_loss: 0.3178 - val_acc: 0.8771\n",
      "Epoch 1596/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2036 - acc: 0.9263 - val_loss: 0.3072 - val_acc: 0.8771\n",
      "Epoch 1597/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2022 - acc: 0.9210 - val_loss: 0.3080 - val_acc: 0.8800\n",
      "Epoch 1598/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2025 - acc: 0.9187 - val_loss: 0.3304 - val_acc: 0.8712\n",
      "Epoch 1599/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2057 - acc: 0.9233 - val_loss: 0.2879 - val_acc: 0.8848\n",
      "Epoch 1600/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2094 - acc: 0.9196 - val_loss: 0.3089 - val_acc: 0.8751\n",
      "Epoch 1601/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2036 - acc: 0.9233 - val_loss: 0.2971 - val_acc: 0.8838\n",
      "Epoch 1602/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2039 - acc: 0.9226 - val_loss: 0.2887 - val_acc: 0.8809\n",
      "Epoch 1603/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1985 - acc: 0.9263 - val_loss: 0.3128 - val_acc: 0.8790\n",
      "Epoch 1604/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2007 - acc: 0.9240 - val_loss: 0.2990 - val_acc: 0.8800\n",
      "Epoch 1605/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1989 - acc: 0.9233 - val_loss: 0.2920 - val_acc: 0.8896\n",
      "Epoch 1606/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1997 - acc: 0.9210 - val_loss: 0.3039 - val_acc: 0.8848\n",
      "Epoch 1607/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1977 - acc: 0.9252 - val_loss: 0.3699 - val_acc: 0.8616\n",
      "Epoch 1608/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2037 - acc: 0.9201 - val_loss: 0.3032 - val_acc: 0.8848\n",
      "Epoch 1609/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2039 - acc: 0.9221 - val_loss: 0.3257 - val_acc: 0.8712\n",
      "Epoch 1610/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2000 - acc: 0.9219 - val_loss: 0.3437 - val_acc: 0.8664\n",
      "Epoch 1611/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2127 - acc: 0.9182 - val_loss: 0.3304 - val_acc: 0.8703\n",
      "Epoch 1612/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2054 - acc: 0.9221 - val_loss: 0.3058 - val_acc: 0.8800\n",
      "Epoch 1613/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2087 - acc: 0.9210 - val_loss: 0.2833 - val_acc: 0.8838\n",
      "Epoch 1614/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2011 - acc: 0.9217 - val_loss: 0.3081 - val_acc: 0.8790\n",
      "Epoch 1615/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2044 - acc: 0.9228 - val_loss: 0.3697 - val_acc: 0.8577\n",
      "Epoch 1616/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2153 - acc: 0.9171 - val_loss: 0.3614 - val_acc: 0.8625\n",
      "Epoch 1617/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2047 - acc: 0.9175 - val_loss: 0.3231 - val_acc: 0.8780\n",
      "Epoch 1618/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2126 - acc: 0.9180 - val_loss: 0.3048 - val_acc: 0.8790\n",
      "Epoch 1619/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2053 - acc: 0.9173 - val_loss: 0.3120 - val_acc: 0.8780\n",
      "Epoch 1620/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2033 - acc: 0.9224 - val_loss: 0.3067 - val_acc: 0.8790\n",
      "Epoch 1621/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2111 - acc: 0.9150 - val_loss: 0.3185 - val_acc: 0.8848\n",
      "Epoch 1622/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2024 - acc: 0.9210 - val_loss: 0.2872 - val_acc: 0.8819\n",
      "Epoch 1623/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2018 - acc: 0.9194 - val_loss: 0.2900 - val_acc: 0.8925\n",
      "Epoch 1624/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2022 - acc: 0.9254 - val_loss: 0.2962 - val_acc: 0.8800\n",
      "Epoch 1625/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1957 - acc: 0.9258 - val_loss: 0.3521 - val_acc: 0.8654\n",
      "Epoch 1626/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2012 - acc: 0.9228 - val_loss: 0.3234 - val_acc: 0.8742\n",
      "Epoch 1627/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2049 - acc: 0.9228 - val_loss: 0.2995 - val_acc: 0.8800\n",
      "Epoch 1628/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2064 - acc: 0.9191 - val_loss: 0.2835 - val_acc: 0.8848\n",
      "Epoch 1629/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2011 - acc: 0.9191 - val_loss: 0.3016 - val_acc: 0.8800\n",
      "Epoch 1630/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1992 - acc: 0.9233 - val_loss: 0.2856 - val_acc: 0.8887\n",
      "Epoch 1631/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1987 - acc: 0.9210 - val_loss: 0.3217 - val_acc: 0.8732\n",
      "Epoch 1632/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2007 - acc: 0.9214 - val_loss: 0.2862 - val_acc: 0.8887\n",
      "Epoch 1633/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1962 - acc: 0.9251 - val_loss: 0.3036 - val_acc: 0.8838\n",
      "Epoch 1634/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2126 - acc: 0.9180 - val_loss: 0.3166 - val_acc: 0.8761\n",
      "Epoch 1635/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2110 - acc: 0.9196 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 1636/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2099 - acc: 0.9212 - val_loss: 0.2911 - val_acc: 0.8877\n",
      "Epoch 1637/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1957 - acc: 0.9247 - val_loss: 0.2913 - val_acc: 0.8877\n",
      "Epoch 1638/2000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2011 - acc: 0.9215 - val_loss: 0.3544 - val_acc: 0.8635\n",
      "Epoch 1639/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2004 - acc: 0.9231 - val_loss: 0.3177 - val_acc: 0.8800\n",
      "Epoch 1640/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2023 - acc: 0.9258 - val_loss: 0.3436 - val_acc: 0.8712\n",
      "Epoch 1641/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2007 - acc: 0.9238 - val_loss: 0.2996 - val_acc: 0.8858\n",
      "Epoch 1642/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1983 - acc: 0.9205 - val_loss: 0.3063 - val_acc: 0.8819\n",
      "Epoch 1643/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1993 - acc: 0.9240 - val_loss: 0.3008 - val_acc: 0.8790\n",
      "Epoch 1644/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1931 - acc: 0.9251 - val_loss: 0.3309 - val_acc: 0.8732\n",
      "Epoch 1645/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2093 - acc: 0.9180 - val_loss: 0.3135 - val_acc: 0.8771\n",
      "Epoch 1646/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1943 - acc: 0.9291 - val_loss: 0.3202 - val_acc: 0.8751\n",
      "Epoch 1647/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2044 - acc: 0.9210 - val_loss: 0.3143 - val_acc: 0.8722\n",
      "Epoch 1648/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2096 - acc: 0.9224 - val_loss: 0.3698 - val_acc: 0.8645\n",
      "Epoch 1649/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2069 - acc: 0.9208 - val_loss: 0.3498 - val_acc: 0.8732\n",
      "Epoch 1650/2000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1993 - acc: 0.9247 - val_loss: 0.2891 - val_acc: 0.8838\n",
      "Epoch 1651/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2078 - acc: 0.9228 - val_loss: 0.3085 - val_acc: 0.8848\n",
      "Epoch 1652/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2054 - acc: 0.9201 - val_loss: 0.3252 - val_acc: 0.8742\n",
      "Epoch 1653/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2005 - acc: 0.9244 - val_loss: 0.3068 - val_acc: 0.8829\n",
      "Epoch 1654/2000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2075 - acc: 0.9157 - val_loss: 0.3202 - val_acc: 0.8809\n",
      "Epoch 1655/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1967 - acc: 0.9251 - val_loss: 0.2811 - val_acc: 0.8935\n",
      "Epoch 1656/2000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1996 - acc: 0.9235 - val_loss: 0.2873 - val_acc: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1657/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1968 - acc: 0.9233 - val_loss: 0.3265 - val_acc: 0.8732\n",
      "Epoch 1658/2000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2005 - acc: 0.9231 - val_loss: 0.3025 - val_acc: 0.8867\n",
      "Epoch 1659/2000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2056 - acc: 0.9205 - val_loss: 0.3157 - val_acc: 0.8809\n",
      "Epoch 1660/2000\n",
      " 5/17 [=======>......................] - ETA: 1:05 - loss: 0.2290 - acc: 0.9187"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-74ed3cea20d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_image_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_learning_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     validation_steps=math.ceil(validation_set_size/batch_size))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "transfer_learning_epochs = 2000\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "\n",
    "checkpoint_dir = os.path.join(work_dir, 'checkpoint/ensemble')\n",
    "log_dir = os.path.join(work_dir, 'log/ensemble')\n",
    "if not os.path.exists(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "\n",
    "df = get_clinical_data(csv_file)\n",
    "\n",
    "train_file_list = []\n",
    "for path, dirs, files in os.walk(train_dir):\n",
    "    train_file_list += [os.path.join(path, file) for file in files]    \n",
    "\n",
    "validation_file_list = []\n",
    "for path, dirs, files in os.walk(validation_dir):\n",
    "    validation_file_list += [os.path.join(path, file) for file in files]    \n",
    "\n",
    "model_path = os.path.join(checkpoint_dir, '{epoch:02d}-{val_acc:.4f}.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc', period=10)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=False)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    custom_generator(train_file_list, df, is_train=True, non_image_data=True),\n",
    "    steps_per_epoch=math.ceil(train_set_size/batch_size),\n",
    "    callbacks=[checkpoint, tensorboard],\n",
    "    validation_data=custom_generator(validation_file_list, df, is_train=False, non_image_data=True),\n",
    "    epochs=transfer_learning_epochs,\n",
    "    validation_steps=math.ceil(validation_set_size/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 8, 8, 2048)   21802784    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            16          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            20          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1028)         0           dense_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            1029        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,902,025\n",
      "Trainable params: 8,172,777\n",
      "Non-trainable params: 15,729,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_dict['dense_6'].trainable = False # shape=(2048, 1024)\n",
    "layer_dict['dense_7'].trainable = False # shape=(3, 4)\n",
    "layer_dict['dense_8'].trainable = False # shape=(4, 4)\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_path = os.path.join(work_dir, 'checkpoint/ensemble/448-0.8858.hdf5')\n",
    "model.load_weights(model_path)\n",
    "\n",
    "layer_dict['dense_6'].trainable = True # shape=(2048, 1024)\n",
    "layer_dict['dense_7'].trainable = True # shape=(3, 4)\n",
    "layer_dict['dense_8'].trainable = True # shape=(4, 4)\n",
    "\n",
    "for layer in conv_base.layers[:280]:\n",
    "   layer.trainable = False\n",
    "for layer in conv_base.layers[280:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.2476 - acc: 0.9051 - val_loss: 0.2905 - val_acc: 0.8829\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2484 - acc: 0.9035 - val_loss: 0.2870 - val_acc: 0.8809\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2441 - acc: 0.9028 - val_loss: 0.2871 - val_acc: 0.8819\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2424 - acc: 0.9062 - val_loss: 0.2881 - val_acc: 0.8838\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2519 - acc: 0.9005 - val_loss: 0.2863 - val_acc: 0.8858\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2479 - acc: 0.8984 - val_loss: 0.2864 - val_acc: 0.8848\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2396 - acc: 0.9056 - val_loss: 0.2860 - val_acc: 0.8829\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2461 - acc: 0.9030 - val_loss: 0.2869 - val_acc: 0.8829\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2460 - acc: 0.9019 - val_loss: 0.2884 - val_acc: 0.8800\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2470 - acc: 0.9010 - val_loss: 0.2879 - val_acc: 0.8819\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2448 - acc: 0.9074 - val_loss: 0.2881 - val_acc: 0.8858\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2430 - acc: 0.9030 - val_loss: 0.2888 - val_acc: 0.8809\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2443 - acc: 0.9095 - val_loss: 0.2881 - val_acc: 0.8848\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2479 - acc: 0.9044 - val_loss: 0.2886 - val_acc: 0.8800\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2344 - acc: 0.9039 - val_loss: 0.2881 - val_acc: 0.8829\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2468 - acc: 0.9016 - val_loss: 0.2902 - val_acc: 0.8761\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2412 - acc: 0.9071 - val_loss: 0.2851 - val_acc: 0.8829\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2379 - acc: 0.9081 - val_loss: 0.2883 - val_acc: 0.8867\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2418 - acc: 0.9081 - val_loss: 0.2889 - val_acc: 0.8848\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2418 - acc: 0.9081 - val_loss: 0.2898 - val_acc: 0.8877\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2397 - acc: 0.9081 - val_loss: 0.2881 - val_acc: 0.8887\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2472 - acc: 0.9058 - val_loss: 0.2867 - val_acc: 0.8877\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2390 - acc: 0.9063 - val_loss: 0.2897 - val_acc: 0.8867\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2364 - acc: 0.9060 - val_loss: 0.2878 - val_acc: 0.8867\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2400 - acc: 0.9085 - val_loss: 0.2869 - val_acc: 0.8848\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2416 - acc: 0.9074 - val_loss: 0.2853 - val_acc: 0.8858\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2313 - acc: 0.9118 - val_loss: 0.2840 - val_acc: 0.8858\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2382 - acc: 0.9017 - val_loss: 0.2846 - val_acc: 0.8838\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2319 - acc: 0.9081 - val_loss: 0.2848 - val_acc: 0.8800\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2381 - acc: 0.9076 - val_loss: 0.2856 - val_acc: 0.8838\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2421 - acc: 0.9057 - val_loss: 0.2867 - val_acc: 0.8867\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2377 - acc: 0.9069 - val_loss: 0.2896 - val_acc: 0.8896\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2335 - acc: 0.9063 - val_loss: 0.2860 - val_acc: 0.8838\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2406 - acc: 0.9097 - val_loss: 0.2866 - val_acc: 0.8848\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2374 - acc: 0.9064 - val_loss: 0.2835 - val_acc: 0.8867\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2383 - acc: 0.9140 - val_loss: 0.2825 - val_acc: 0.8887\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2409 - acc: 0.9076 - val_loss: 0.2826 - val_acc: 0.8877\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2366 - acc: 0.9092 - val_loss: 0.2828 - val_acc: 0.8867\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2314 - acc: 0.9081 - val_loss: 0.2807 - val_acc: 0.8838\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2360 - acc: 0.9035 - val_loss: 0.2793 - val_acc: 0.8877\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2387 - acc: 0.9076 - val_loss: 0.2792 - val_acc: 0.8887\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2382 - acc: 0.9033 - val_loss: 0.2808 - val_acc: 0.8896\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2374 - acc: 0.9124 - val_loss: 0.2822 - val_acc: 0.8858\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2311 - acc: 0.9088 - val_loss: 0.2816 - val_acc: 0.8877\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2361 - acc: 0.9063 - val_loss: 0.2808 - val_acc: 0.8896\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2362 - acc: 0.9097 - val_loss: 0.2806 - val_acc: 0.8858\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2365 - acc: 0.9081 - val_loss: 0.2806 - val_acc: 0.8848\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2357 - acc: 0.9062 - val_loss: 0.2793 - val_acc: 0.8829\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2309 - acc: 0.9148 - val_loss: 0.2819 - val_acc: 0.8819\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2356 - acc: 0.9079 - val_loss: 0.2845 - val_acc: 0.8780\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2331 - acc: 0.9085 - val_loss: 0.2833 - val_acc: 0.8800\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2362 - acc: 0.9053 - val_loss: 0.2812 - val_acc: 0.8819\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2356 - acc: 0.9037 - val_loss: 0.2832 - val_acc: 0.8819\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2321 - acc: 0.9129 - val_loss: 0.2826 - val_acc: 0.8829\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2494 - acc: 0.8996 - val_loss: 0.2802 - val_acc: 0.8829\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2318 - acc: 0.9166 - val_loss: 0.2796 - val_acc: 0.8838\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2395 - acc: 0.9065 - val_loss: 0.2797 - val_acc: 0.8867\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2315 - acc: 0.9090 - val_loss: 0.2779 - val_acc: 0.8848\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2376 - acc: 0.9065 - val_loss: 0.2790 - val_acc: 0.8858\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2324 - acc: 0.9065 - val_loss: 0.2810 - val_acc: 0.8838\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2242 - acc: 0.9129 - val_loss: 0.2815 - val_acc: 0.8848\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 89s 5s/step - loss: 0.2341 - acc: 0.9099 - val_loss: 0.2815 - val_acc: 0.8848\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2410 - acc: 0.9074 - val_loss: 0.2804 - val_acc: 0.8829\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2330 - acc: 0.9076 - val_loss: 0.2805 - val_acc: 0.8838\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2316 - acc: 0.9111 - val_loss: 0.2815 - val_acc: 0.8838\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2234 - acc: 0.9143 - val_loss: 0.2821 - val_acc: 0.8848\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2318 - acc: 0.9055 - val_loss: 0.2820 - val_acc: 0.8877\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2329 - acc: 0.9067 - val_loss: 0.2839 - val_acc: 0.8858\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2284 - acc: 0.9145 - val_loss: 0.2836 - val_acc: 0.8829\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2311 - acc: 0.9081 - val_loss: 0.2831 - val_acc: 0.8819\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2347 - acc: 0.9058 - val_loss: 0.2854 - val_acc: 0.8819\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2294 - acc: 0.9168 - val_loss: 0.2842 - val_acc: 0.8829\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2287 - acc: 0.9051 - val_loss: 0.2840 - val_acc: 0.8829\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2226 - acc: 0.9099 - val_loss: 0.2856 - val_acc: 0.8809\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2366 - acc: 0.9097 - val_loss: 0.2834 - val_acc: 0.8809\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2239 - acc: 0.9104 - val_loss: 0.2824 - val_acc: 0.8800\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2255 - acc: 0.9095 - val_loss: 0.2821 - val_acc: 0.8829\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2322 - acc: 0.9101 - val_loss: 0.2827 - val_acc: 0.8800\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2268 - acc: 0.9129 - val_loss: 0.2813 - val_acc: 0.8848\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2331 - acc: 0.9152 - val_loss: 0.2798 - val_acc: 0.8838\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2283 - acc: 0.9136 - val_loss: 0.2800 - val_acc: 0.8829\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2330 - acc: 0.9101 - val_loss: 0.2823 - val_acc: 0.8771\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2330 - acc: 0.9051 - val_loss: 0.2835 - val_acc: 0.8819\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2230 - acc: 0.9124 - val_loss: 0.2860 - val_acc: 0.8761\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2299 - acc: 0.9101 - val_loss: 0.2851 - val_acc: 0.8809\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2243 - acc: 0.9136 - val_loss: 0.2869 - val_acc: 0.8848\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2279 - acc: 0.9102 - val_loss: 0.2855 - val_acc: 0.8848\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2281 - acc: 0.9113 - val_loss: 0.2862 - val_acc: 0.8800\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2214 - acc: 0.9141 - val_loss: 0.2856 - val_acc: 0.8809\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2250 - acc: 0.9163 - val_loss: 0.2870 - val_acc: 0.8800\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2278 - acc: 0.9097 - val_loss: 0.2862 - val_acc: 0.8809\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2236 - acc: 0.9079 - val_loss: 0.2841 - val_acc: 0.8809\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2220 - acc: 0.9141 - val_loss: 0.2863 - val_acc: 0.8780\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2229 - acc: 0.9104 - val_loss: 0.2833 - val_acc: 0.8790\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2343 - acc: 0.9124 - val_loss: 0.2800 - val_acc: 0.8809\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2323 - acc: 0.9058 - val_loss: 0.2794 - val_acc: 0.8848\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2333 - acc: 0.9092 - val_loss: 0.2817 - val_acc: 0.8790\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2229 - acc: 0.9145 - val_loss: 0.2810 - val_acc: 0.8800\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2264 - acc: 0.9101 - val_loss: 0.2816 - val_acc: 0.8858\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2271 - acc: 0.9118 - val_loss: 0.2803 - val_acc: 0.8858\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2239 - acc: 0.9131 - val_loss: 0.2820 - val_acc: 0.8771\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2321 - acc: 0.9072 - val_loss: 0.2804 - val_acc: 0.8819\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2244 - acc: 0.9163 - val_loss: 0.2820 - val_acc: 0.8819\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2279 - acc: 0.9101 - val_loss: 0.2798 - val_acc: 0.8829\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2259 - acc: 0.9113 - val_loss: 0.2793 - val_acc: 0.8838\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2250 - acc: 0.9138 - val_loss: 0.2776 - val_acc: 0.8829\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2324 - acc: 0.9118 - val_loss: 0.2782 - val_acc: 0.8848\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2264 - acc: 0.9129 - val_loss: 0.2778 - val_acc: 0.8819\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2276 - acc: 0.9115 - val_loss: 0.2764 - val_acc: 0.8809\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2230 - acc: 0.9115 - val_loss: 0.2757 - val_acc: 0.8838\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2294 - acc: 0.9104 - val_loss: 0.2753 - val_acc: 0.8858\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2217 - acc: 0.9193 - val_loss: 0.2790 - val_acc: 0.8848\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2192 - acc: 0.9182 - val_loss: 0.2790 - val_acc: 0.8867\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2271 - acc: 0.9136 - val_loss: 0.2789 - val_acc: 0.8829\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2244 - acc: 0.9134 - val_loss: 0.2817 - val_acc: 0.8819\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2231 - acc: 0.9150 - val_loss: 0.2784 - val_acc: 0.8896\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2220 - acc: 0.9147 - val_loss: 0.2782 - val_acc: 0.8838\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2183 - acc: 0.9136 - val_loss: 0.2791 - val_acc: 0.8848\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2228 - acc: 0.9136 - val_loss: 0.2834 - val_acc: 0.8800\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2193 - acc: 0.9193 - val_loss: 0.2802 - val_acc: 0.8819\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2298 - acc: 0.9097 - val_loss: 0.2819 - val_acc: 0.8800\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2239 - acc: 0.9152 - val_loss: 0.2814 - val_acc: 0.8790\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 85s 5s/step - loss: 0.2244 - acc: 0.9101 - val_loss: 0.2836 - val_acc: 0.8790\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2282 - acc: 0.9134 - val_loss: 0.2810 - val_acc: 0.8790\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2246 - acc: 0.9161 - val_loss: 0.2818 - val_acc: 0.8800\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2193 - acc: 0.9157 - val_loss: 0.2814 - val_acc: 0.8800\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2151 - acc: 0.9157 - val_loss: 0.2831 - val_acc: 0.8780\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2286 - acc: 0.9120 - val_loss: 0.2853 - val_acc: 0.8771\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2290 - acc: 0.9154 - val_loss: 0.2795 - val_acc: 0.8761\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2269 - acc: 0.9065 - val_loss: 0.2785 - val_acc: 0.8809\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2274 - acc: 0.9108 - val_loss: 0.2809 - val_acc: 0.8800\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2198 - acc: 0.9138 - val_loss: 0.2798 - val_acc: 0.8829\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2176 - acc: 0.9159 - val_loss: 0.2795 - val_acc: 0.8780\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2220 - acc: 0.9166 - val_loss: 0.2797 - val_acc: 0.8761\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2194 - acc: 0.9122 - val_loss: 0.2799 - val_acc: 0.8780\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2192 - acc: 0.9166 - val_loss: 0.2814 - val_acc: 0.8780\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2191 - acc: 0.9138 - val_loss: 0.2806 - val_acc: 0.8800\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2258 - acc: 0.9129 - val_loss: 0.2835 - val_acc: 0.8780\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2150 - acc: 0.9177 - val_loss: 0.2810 - val_acc: 0.8809\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2153 - acc: 0.9173 - val_loss: 0.2815 - val_acc: 0.8848\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2241 - acc: 0.9150 - val_loss: 0.2800 - val_acc: 0.8809\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2235 - acc: 0.9120 - val_loss: 0.2799 - val_acc: 0.8771\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2214 - acc: 0.9129 - val_loss: 0.2791 - val_acc: 0.8809\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2230 - acc: 0.9150 - val_loss: 0.2812 - val_acc: 0.8771\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2178 - acc: 0.9157 - val_loss: 0.2801 - val_acc: 0.8800\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2135 - acc: 0.9182 - val_loss: 0.2817 - val_acc: 0.8780\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2218 - acc: 0.9138 - val_loss: 0.2811 - val_acc: 0.8819\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2153 - acc: 0.9131 - val_loss: 0.2822 - val_acc: 0.8829\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2208 - acc: 0.9074 - val_loss: 0.2809 - val_acc: 0.8829\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2246 - acc: 0.9157 - val_loss: 0.2813 - val_acc: 0.8838\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2214 - acc: 0.9161 - val_loss: 0.2807 - val_acc: 0.8848\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2233 - acc: 0.9157 - val_loss: 0.2820 - val_acc: 0.8838\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2205 - acc: 0.9145 - val_loss: 0.2817 - val_acc: 0.8771\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2187 - acc: 0.9154 - val_loss: 0.2813 - val_acc: 0.8761\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2178 - acc: 0.9161 - val_loss: 0.2820 - val_acc: 0.8771\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2211 - acc: 0.9152 - val_loss: 0.2824 - val_acc: 0.8751\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2226 - acc: 0.9145 - val_loss: 0.2822 - val_acc: 0.8790\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2251 - acc: 0.9115 - val_loss: 0.2794 - val_acc: 0.8800\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2232 - acc: 0.9116 - val_loss: 0.2794 - val_acc: 0.8819\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2192 - acc: 0.9136 - val_loss: 0.2799 - val_acc: 0.8809\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2137 - acc: 0.9150 - val_loss: 0.2789 - val_acc: 0.8771\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2287 - acc: 0.9101 - val_loss: 0.2781 - val_acc: 0.8838\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2256 - acc: 0.9097 - val_loss: 0.2785 - val_acc: 0.8819\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2165 - acc: 0.9148 - val_loss: 0.2797 - val_acc: 0.8790\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2218 - acc: 0.9136 - val_loss: 0.2797 - val_acc: 0.8819\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2164 - acc: 0.9148 - val_loss: 0.2780 - val_acc: 0.8819\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2118 - acc: 0.9187 - val_loss: 0.2780 - val_acc: 0.8809\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2164 - acc: 0.9136 - val_loss: 0.2782 - val_acc: 0.8819\n",
      "Epoch 169/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2114 - acc: 0.9196 - val_loss: 0.2790 - val_acc: 0.8819\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2182 - acc: 0.9170 - val_loss: 0.2805 - val_acc: 0.8790\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2211 - acc: 0.9083 - val_loss: 0.2806 - val_acc: 0.8829\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2163 - acc: 0.9173 - val_loss: 0.2816 - val_acc: 0.8800\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2110 - acc: 0.9150 - val_loss: 0.2813 - val_acc: 0.8829\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2148 - acc: 0.9136 - val_loss: 0.2828 - val_acc: 0.8780\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2205 - acc: 0.9131 - val_loss: 0.2830 - val_acc: 0.8790\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2124 - acc: 0.9145 - val_loss: 0.2828 - val_acc: 0.8790\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2192 - acc: 0.9143 - val_loss: 0.2825 - val_acc: 0.8761\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2152 - acc: 0.9180 - val_loss: 0.2839 - val_acc: 0.8761\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2264 - acc: 0.9101 - val_loss: 0.2848 - val_acc: 0.8780\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2149 - acc: 0.9177 - val_loss: 0.2849 - val_acc: 0.8761\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2133 - acc: 0.9189 - val_loss: 0.2853 - val_acc: 0.8809\n",
      "Epoch 182/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2144 - acc: 0.9131 - val_loss: 0.2851 - val_acc: 0.8761\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2194 - acc: 0.9148 - val_loss: 0.2860 - val_acc: 0.8780\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2151 - acc: 0.9182 - val_loss: 0.2820 - val_acc: 0.8829\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2172 - acc: 0.9171 - val_loss: 0.2849 - val_acc: 0.8790\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2189 - acc: 0.9132 - val_loss: 0.2825 - val_acc: 0.8780\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2148 - acc: 0.9154 - val_loss: 0.2851 - val_acc: 0.8771\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2159 - acc: 0.9152 - val_loss: 0.2855 - val_acc: 0.8848\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2216 - acc: 0.9134 - val_loss: 0.2830 - val_acc: 0.8790\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2069 - acc: 0.9194 - val_loss: 0.2853 - val_acc: 0.8829\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2161 - acc: 0.9175 - val_loss: 0.2842 - val_acc: 0.8780\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2111 - acc: 0.9203 - val_loss: 0.2843 - val_acc: 0.8771\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2175 - acc: 0.9182 - val_loss: 0.2856 - val_acc: 0.8790\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2169 - acc: 0.9168 - val_loss: 0.2858 - val_acc: 0.8790\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2109 - acc: 0.9223 - val_loss: 0.2855 - val_acc: 0.8819\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2162 - acc: 0.9154 - val_loss: 0.2864 - val_acc: 0.8771\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2148 - acc: 0.9161 - val_loss: 0.2844 - val_acc: 0.8771\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2133 - acc: 0.9182 - val_loss: 0.2833 - val_acc: 0.8780\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2077 - acc: 0.9173 - val_loss: 0.2858 - val_acc: 0.8751\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2189 - acc: 0.9141 - val_loss: 0.2841 - val_acc: 0.8771\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2126 - acc: 0.9171 - val_loss: 0.2844 - val_acc: 0.8838\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2097 - acc: 0.9203 - val_loss: 0.2840 - val_acc: 0.8800\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2093 - acc: 0.9187 - val_loss: 0.2827 - val_acc: 0.8800\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2126 - acc: 0.9233 - val_loss: 0.2814 - val_acc: 0.8790\n",
      "Epoch 205/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2160 - acc: 0.9166 - val_loss: 0.2824 - val_acc: 0.8800\n",
      "Epoch 206/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2118 - acc: 0.9192 - val_loss: 0.2847 - val_acc: 0.8751\n",
      "Epoch 207/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2118 - acc: 0.9194 - val_loss: 0.2849 - val_acc: 0.8771\n",
      "Epoch 208/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2092 - acc: 0.9223 - val_loss: 0.2881 - val_acc: 0.8800\n",
      "Epoch 209/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2117 - acc: 0.9205 - val_loss: 0.2874 - val_acc: 0.8761\n",
      "Epoch 210/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2175 - acc: 0.9166 - val_loss: 0.2965 - val_acc: 0.8742\n",
      "Epoch 211/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2191 - acc: 0.9136 - val_loss: 0.2890 - val_acc: 0.8751\n",
      "Epoch 212/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2116 - acc: 0.9182 - val_loss: 0.2891 - val_acc: 0.8742\n",
      "Epoch 213/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2117 - acc: 0.9161 - val_loss: 0.2875 - val_acc: 0.8751\n",
      "Epoch 214/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2208 - acc: 0.9157 - val_loss: 0.2854 - val_acc: 0.8751\n",
      "Epoch 215/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2092 - acc: 0.9221 - val_loss: 0.2845 - val_acc: 0.8761\n",
      "Epoch 216/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2152 - acc: 0.9175 - val_loss: 0.2858 - val_acc: 0.8742\n",
      "Epoch 217/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2022 - acc: 0.9166 - val_loss: 0.2854 - val_acc: 0.8790\n",
      "Epoch 218/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2050 - acc: 0.9235 - val_loss: 0.2875 - val_acc: 0.8771\n",
      "Epoch 219/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2150 - acc: 0.9180 - val_loss: 0.2848 - val_acc: 0.8771\n",
      "Epoch 220/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2127 - acc: 0.9196 - val_loss: 0.2842 - val_acc: 0.8790\n",
      "Epoch 221/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2167 - acc: 0.9152 - val_loss: 0.2843 - val_acc: 0.8819\n",
      "Epoch 222/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2062 - acc: 0.9171 - val_loss: 0.2837 - val_acc: 0.8838\n",
      "Epoch 223/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2073 - acc: 0.9212 - val_loss: 0.2840 - val_acc: 0.8809\n",
      "Epoch 224/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2127 - acc: 0.9198 - val_loss: 0.2815 - val_acc: 0.8819\n",
      "Epoch 225/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2118 - acc: 0.9161 - val_loss: 0.2830 - val_acc: 0.8790\n",
      "Epoch 226/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2115 - acc: 0.9182 - val_loss: 0.2827 - val_acc: 0.8809\n",
      "Epoch 227/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2180 - acc: 0.9138 - val_loss: 0.2834 - val_acc: 0.8819\n",
      "Epoch 228/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2148 - acc: 0.9170 - val_loss: 0.2824 - val_acc: 0.8809\n",
      "Epoch 229/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2057 - acc: 0.9244 - val_loss: 0.2817 - val_acc: 0.8809\n",
      "Epoch 230/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2139 - acc: 0.9150 - val_loss: 0.2775 - val_acc: 0.8819\n",
      "Epoch 231/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2163 - acc: 0.9145 - val_loss: 0.2790 - val_acc: 0.8809\n",
      "Epoch 232/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2046 - acc: 0.9235 - val_loss: 0.2801 - val_acc: 0.8819\n",
      "Epoch 233/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2194 - acc: 0.9138 - val_loss: 0.2772 - val_acc: 0.8848\n",
      "Epoch 234/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2088 - acc: 0.9182 - val_loss: 0.2777 - val_acc: 0.8800\n",
      "Epoch 235/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2165 - acc: 0.9182 - val_loss: 0.2817 - val_acc: 0.8780\n",
      "Epoch 236/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2129 - acc: 0.9173 - val_loss: 0.2804 - val_acc: 0.8780\n",
      "Epoch 237/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2112 - acc: 0.9161 - val_loss: 0.2780 - val_acc: 0.8829\n",
      "Epoch 238/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2125 - acc: 0.9166 - val_loss: 0.2773 - val_acc: 0.8800\n",
      "Epoch 239/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2082 - acc: 0.9198 - val_loss: 0.2786 - val_acc: 0.8838\n",
      "Epoch 240/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2101 - acc: 0.9201 - val_loss: 0.2804 - val_acc: 0.8838\n",
      "Epoch 241/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2105 - acc: 0.9210 - val_loss: 0.2815 - val_acc: 0.8848\n",
      "Epoch 242/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2074 - acc: 0.9189 - val_loss: 0.2797 - val_acc: 0.8858\n",
      "Epoch 243/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2063 - acc: 0.9191 - val_loss: 0.2793 - val_acc: 0.8829\n",
      "Epoch 244/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2088 - acc: 0.9175 - val_loss: 0.2799 - val_acc: 0.8838\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 86s 5s/step - loss: 0.2093 - acc: 0.9171 - val_loss: 0.2816 - val_acc: 0.8809\n",
      "Epoch 246/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2092 - acc: 0.9187 - val_loss: 0.2801 - val_acc: 0.8838\n",
      "Epoch 247/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2031 - acc: 0.9235 - val_loss: 0.2791 - val_acc: 0.8858\n",
      "Epoch 248/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2096 - acc: 0.9203 - val_loss: 0.2798 - val_acc: 0.8848\n",
      "Epoch 249/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2217 - acc: 0.9141 - val_loss: 0.2804 - val_acc: 0.8809\n",
      "Epoch 250/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2095 - acc: 0.9152 - val_loss: 0.2806 - val_acc: 0.8819\n",
      "Epoch 251/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2053 - acc: 0.9171 - val_loss: 0.2820 - val_acc: 0.8809\n",
      "Epoch 252/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2078 - acc: 0.9194 - val_loss: 0.2850 - val_acc: 0.8771\n",
      "Epoch 253/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2055 - acc: 0.9187 - val_loss: 0.2812 - val_acc: 0.8809\n",
      "Epoch 254/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2111 - acc: 0.9210 - val_loss: 0.2816 - val_acc: 0.8829\n",
      "Epoch 255/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2132 - acc: 0.9166 - val_loss: 0.2835 - val_acc: 0.8800\n",
      "Epoch 256/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2052 - acc: 0.9171 - val_loss: 0.2846 - val_acc: 0.8790\n",
      "Epoch 257/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2108 - acc: 0.9191 - val_loss: 0.2819 - val_acc: 0.8800\n",
      "Epoch 258/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2073 - acc: 0.9170 - val_loss: 0.2800 - val_acc: 0.8751\n",
      "Epoch 259/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2106 - acc: 0.9187 - val_loss: 0.2813 - val_acc: 0.8761\n",
      "Epoch 260/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2040 - acc: 0.9219 - val_loss: 0.2817 - val_acc: 0.8761\n",
      "Epoch 261/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2206 - acc: 0.9115 - val_loss: 0.2824 - val_acc: 0.8742\n",
      "Epoch 262/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2132 - acc: 0.9150 - val_loss: 0.2860 - val_acc: 0.8790\n",
      "Epoch 263/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2064 - acc: 0.9223 - val_loss: 0.2878 - val_acc: 0.8800\n",
      "Epoch 264/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2095 - acc: 0.9233 - val_loss: 0.2832 - val_acc: 0.8829\n",
      "Epoch 265/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2052 - acc: 0.9189 - val_loss: 0.2842 - val_acc: 0.8790\n",
      "Epoch 266/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2104 - acc: 0.9175 - val_loss: 0.2841 - val_acc: 0.8809\n",
      "Epoch 267/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2128 - acc: 0.9175 - val_loss: 0.2863 - val_acc: 0.8809\n",
      "Epoch 268/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2081 - acc: 0.9216 - val_loss: 0.2849 - val_acc: 0.8809\n",
      "Epoch 269/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2066 - acc: 0.9219 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 270/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2071 - acc: 0.9198 - val_loss: 0.2824 - val_acc: 0.8848\n",
      "Epoch 271/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2099 - acc: 0.9163 - val_loss: 0.2819 - val_acc: 0.8838\n",
      "Epoch 272/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2058 - acc: 0.9214 - val_loss: 0.2853 - val_acc: 0.8790\n",
      "Epoch 273/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2028 - acc: 0.9224 - val_loss: 0.2821 - val_acc: 0.8780\n",
      "Epoch 274/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2114 - acc: 0.9189 - val_loss: 0.2836 - val_acc: 0.8800\n",
      "Epoch 275/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2086 - acc: 0.9177 - val_loss: 0.2847 - val_acc: 0.8800\n",
      "Epoch 276/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2040 - acc: 0.9219 - val_loss: 0.2861 - val_acc: 0.8800\n",
      "Epoch 277/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2146 - acc: 0.9212 - val_loss: 0.2839 - val_acc: 0.8809\n",
      "Epoch 278/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2145 - acc: 0.9212 - val_loss: 0.2832 - val_acc: 0.8809\n",
      "Epoch 279/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2065 - acc: 0.9194 - val_loss: 0.2822 - val_acc: 0.8800\n",
      "Epoch 280/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2050 - acc: 0.9203 - val_loss: 0.2826 - val_acc: 0.8819\n",
      "Epoch 281/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2141 - acc: 0.9150 - val_loss: 0.2788 - val_acc: 0.8809\n",
      "Epoch 282/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2076 - acc: 0.9168 - val_loss: 0.2804 - val_acc: 0.8819\n",
      "Epoch 283/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2141 - acc: 0.9155 - val_loss: 0.2781 - val_acc: 0.8829\n",
      "Epoch 284/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2054 - acc: 0.9207 - val_loss: 0.2786 - val_acc: 0.8819\n",
      "Epoch 285/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2013 - acc: 0.9269 - val_loss: 0.2786 - val_acc: 0.8829\n",
      "Epoch 286/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2149 - acc: 0.9182 - val_loss: 0.2795 - val_acc: 0.8838\n",
      "Epoch 287/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2104 - acc: 0.9178 - val_loss: 0.2839 - val_acc: 0.8829\n",
      "Epoch 288/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1988 - acc: 0.9281 - val_loss: 0.2831 - val_acc: 0.8790\n",
      "Epoch 289/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2015 - acc: 0.9224 - val_loss: 0.2840 - val_acc: 0.8771\n",
      "Epoch 290/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2033 - acc: 0.9191 - val_loss: 0.2835 - val_acc: 0.8829\n",
      "Epoch 291/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2016 - acc: 0.9233 - val_loss: 0.2820 - val_acc: 0.8780\n",
      "Epoch 292/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2002 - acc: 0.9244 - val_loss: 0.2832 - val_acc: 0.8819\n",
      "Epoch 293/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2078 - acc: 0.9201 - val_loss: 0.2824 - val_acc: 0.8800\n",
      "Epoch 294/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.2046 - acc: 0.9221 - val_loss: 0.2816 - val_acc: 0.8838\n",
      "Epoch 295/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2028 - acc: 0.9198 - val_loss: 0.2824 - val_acc: 0.8819\n",
      "Epoch 296/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2141 - acc: 0.9170 - val_loss: 0.2833 - val_acc: 0.8829\n",
      "Epoch 297/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1983 - acc: 0.9246 - val_loss: 0.2828 - val_acc: 0.8838\n",
      "Epoch 298/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2040 - acc: 0.9205 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 299/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2041 - acc: 0.9187 - val_loss: 0.2846 - val_acc: 0.8800\n",
      "Epoch 300/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2052 - acc: 0.9212 - val_loss: 0.2808 - val_acc: 0.8780\n",
      "Epoch 301/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1995 - acc: 0.9242 - val_loss: 0.2798 - val_acc: 0.8800\n",
      "Epoch 302/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1988 - acc: 0.9240 - val_loss: 0.2796 - val_acc: 0.8780\n",
      "Epoch 303/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2046 - acc: 0.9235 - val_loss: 0.2807 - val_acc: 0.8809\n",
      "Epoch 304/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1955 - acc: 0.9277 - val_loss: 0.2824 - val_acc: 0.8809\n",
      "Epoch 305/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2102 - acc: 0.9194 - val_loss: 0.2821 - val_acc: 0.8819\n",
      "Epoch 306/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2012 - acc: 0.9230 - val_loss: 0.2817 - val_acc: 0.8829\n",
      "Epoch 307/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2037 - acc: 0.9205 - val_loss: 0.2812 - val_acc: 0.8838\n",
      "Epoch 308/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2060 - acc: 0.9178 - val_loss: 0.2798 - val_acc: 0.8848\n",
      "Epoch 309/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2101 - acc: 0.9164 - val_loss: 0.2798 - val_acc: 0.8809\n",
      "Epoch 310/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2065 - acc: 0.9161 - val_loss: 0.2796 - val_acc: 0.8809\n",
      "Epoch 311/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2068 - acc: 0.9191 - val_loss: 0.2793 - val_acc: 0.8790\n",
      "Epoch 312/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2058 - acc: 0.9196 - val_loss: 0.2774 - val_acc: 0.8829\n",
      "Epoch 313/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2043 - acc: 0.9168 - val_loss: 0.2760 - val_acc: 0.8867\n",
      "Epoch 314/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2051 - acc: 0.9207 - val_loss: 0.2767 - val_acc: 0.8896\n",
      "Epoch 315/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2018 - acc: 0.9244 - val_loss: 0.2792 - val_acc: 0.8809\n",
      "Epoch 316/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2028 - acc: 0.9177 - val_loss: 0.2820 - val_acc: 0.8809\n",
      "Epoch 317/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2105 - acc: 0.9170 - val_loss: 0.2816 - val_acc: 0.8858\n",
      "Epoch 318/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2040 - acc: 0.9210 - val_loss: 0.2825 - val_acc: 0.8877\n",
      "Epoch 319/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1995 - acc: 0.9214 - val_loss: 0.2833 - val_acc: 0.8877\n",
      "Epoch 320/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2026 - acc: 0.9244 - val_loss: 0.2847 - val_acc: 0.8858\n",
      "Epoch 321/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2047 - acc: 0.9247 - val_loss: 0.2841 - val_acc: 0.8829\n",
      "Epoch 322/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2075 - acc: 0.9207 - val_loss: 0.2831 - val_acc: 0.8780\n",
      "Epoch 323/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2052 - acc: 0.9191 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 324/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1975 - acc: 0.9246 - val_loss: 0.2854 - val_acc: 0.8819\n",
      "Epoch 325/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2091 - acc: 0.9228 - val_loss: 0.2831 - val_acc: 0.8819\n",
      "Epoch 326/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2065 - acc: 0.9226 - val_loss: 0.2856 - val_acc: 0.8819\n",
      "Epoch 327/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2076 - acc: 0.9228 - val_loss: 0.2852 - val_acc: 0.8780\n",
      "Epoch 328/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2011 - acc: 0.9251 - val_loss: 0.2844 - val_acc: 0.8751\n",
      "Epoch 329/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1984 - acc: 0.9247 - val_loss: 0.2836 - val_acc: 0.8751\n",
      "Epoch 330/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1993 - acc: 0.9210 - val_loss: 0.2834 - val_acc: 0.8780\n",
      "Epoch 331/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1988 - acc: 0.9223 - val_loss: 0.2836 - val_acc: 0.8809\n",
      "Epoch 332/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2020 - acc: 0.9246 - val_loss: 0.2858 - val_acc: 0.8838\n",
      "Epoch 333/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2003 - acc: 0.9182 - val_loss: 0.2834 - val_acc: 0.8848\n",
      "Epoch 334/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1978 - acc: 0.9207 - val_loss: 0.2814 - val_acc: 0.8819\n",
      "Epoch 335/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2009 - acc: 0.9263 - val_loss: 0.2807 - val_acc: 0.8800\n",
      "Epoch 336/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1960 - acc: 0.9244 - val_loss: 0.2817 - val_acc: 0.8858\n",
      "Epoch 337/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2090 - acc: 0.9233 - val_loss: 0.2864 - val_acc: 0.8848\n",
      "Epoch 338/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2015 - acc: 0.9228 - val_loss: 0.2850 - val_acc: 0.8867\n",
      "Epoch 339/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2089 - acc: 0.9173 - val_loss: 0.2784 - val_acc: 0.8838\n",
      "Epoch 340/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2013 - acc: 0.9230 - val_loss: 0.2874 - val_acc: 0.8848\n",
      "Epoch 341/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2070 - acc: 0.9201 - val_loss: 0.2845 - val_acc: 0.8838\n",
      "Epoch 342/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1993 - acc: 0.9233 - val_loss: 0.2846 - val_acc: 0.8848\n",
      "Epoch 343/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1964 - acc: 0.9249 - val_loss: 0.2847 - val_acc: 0.8858\n",
      "Epoch 344/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1998 - acc: 0.9237 - val_loss: 0.2848 - val_acc: 0.8829\n",
      "Epoch 345/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1968 - acc: 0.9246 - val_loss: 0.2874 - val_acc: 0.8858\n",
      "Epoch 346/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1935 - acc: 0.9237 - val_loss: 0.2860 - val_acc: 0.8848\n",
      "Epoch 347/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2034 - acc: 0.9166 - val_loss: 0.2846 - val_acc: 0.8838\n",
      "Epoch 348/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2105 - acc: 0.9157 - val_loss: 0.2842 - val_acc: 0.8848\n",
      "Epoch 349/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2040 - acc: 0.9184 - val_loss: 0.2821 - val_acc: 0.8819\n",
      "Epoch 350/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2027 - acc: 0.9230 - val_loss: 0.2830 - val_acc: 0.8829\n",
      "Epoch 351/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2049 - acc: 0.9226 - val_loss: 0.2871 - val_acc: 0.8848\n",
      "Epoch 352/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1912 - acc: 0.9293 - val_loss: 0.2886 - val_acc: 0.8819\n",
      "Epoch 353/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2013 - acc: 0.9253 - val_loss: 0.2878 - val_acc: 0.8800\n",
      "Epoch 354/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2010 - acc: 0.9194 - val_loss: 0.2878 - val_acc: 0.8800\n",
      "Epoch 355/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1968 - acc: 0.9258 - val_loss: 0.2876 - val_acc: 0.8780\n",
      "Epoch 356/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2003 - acc: 0.9228 - val_loss: 0.2848 - val_acc: 0.8819\n",
      "Epoch 357/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1982 - acc: 0.9231 - val_loss: 0.2913 - val_acc: 0.8790\n",
      "Epoch 358/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2043 - acc: 0.9203 - val_loss: 0.2851 - val_acc: 0.8800\n",
      "Epoch 359/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2019 - acc: 0.9237 - val_loss: 0.2816 - val_acc: 0.8829\n",
      "Epoch 360/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2048 - acc: 0.9212 - val_loss: 0.2812 - val_acc: 0.8809\n",
      "Epoch 361/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2035 - acc: 0.9223 - val_loss: 0.2814 - val_acc: 0.8819\n",
      "Epoch 362/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1998 - acc: 0.9235 - val_loss: 0.2830 - val_acc: 0.8848\n",
      "Epoch 363/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2042 - acc: 0.9221 - val_loss: 0.2832 - val_acc: 0.8838\n",
      "Epoch 364/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1911 - acc: 0.9265 - val_loss: 0.2853 - val_acc: 0.8771\n",
      "Epoch 365/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1966 - acc: 0.9217 - val_loss: 0.2862 - val_acc: 0.8838\n",
      "Epoch 366/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1998 - acc: 0.9221 - val_loss: 0.2860 - val_acc: 0.8848\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 83s 5s/step - loss: 0.2008 - acc: 0.9233 - val_loss: 0.2848 - val_acc: 0.8867\n",
      "Epoch 368/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2050 - acc: 0.9230 - val_loss: 0.2853 - val_acc: 0.8877\n",
      "Epoch 369/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1957 - acc: 0.9221 - val_loss: 0.2858 - val_acc: 0.8858\n",
      "Epoch 370/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2066 - acc: 0.9196 - val_loss: 0.2878 - val_acc: 0.8819\n",
      "Epoch 371/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1954 - acc: 0.9254 - val_loss: 0.2859 - val_acc: 0.8819\n",
      "Epoch 372/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2015 - acc: 0.9251 - val_loss: 0.2832 - val_acc: 0.8829\n",
      "Epoch 373/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1941 - acc: 0.9253 - val_loss: 0.2830 - val_acc: 0.8848\n",
      "Epoch 374/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2054 - acc: 0.9194 - val_loss: 0.2854 - val_acc: 0.8829\n",
      "Epoch 375/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2003 - acc: 0.9260 - val_loss: 0.2843 - val_acc: 0.8819\n",
      "Epoch 376/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1913 - acc: 0.9263 - val_loss: 0.2838 - val_acc: 0.8848\n",
      "Epoch 377/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1989 - acc: 0.9237 - val_loss: 0.2844 - val_acc: 0.8819\n",
      "Epoch 378/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1965 - acc: 0.9212 - val_loss: 0.2830 - val_acc: 0.8838\n",
      "Epoch 379/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1941 - acc: 0.9269 - val_loss: 0.2818 - val_acc: 0.8838\n",
      "Epoch 380/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1961 - acc: 0.9244 - val_loss: 0.2804 - val_acc: 0.8867\n",
      "Epoch 381/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2011 - acc: 0.9253 - val_loss: 0.2829 - val_acc: 0.8838\n",
      "Epoch 382/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2035 - acc: 0.9198 - val_loss: 0.2840 - val_acc: 0.8809\n",
      "Epoch 383/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1969 - acc: 0.9260 - val_loss: 0.2838 - val_acc: 0.8838\n",
      "Epoch 384/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2006 - acc: 0.9230 - val_loss: 0.2800 - val_acc: 0.8848\n",
      "Epoch 385/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1948 - acc: 0.9217 - val_loss: 0.2822 - val_acc: 0.8848\n",
      "Epoch 386/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2041 - acc: 0.9196 - val_loss: 0.2834 - val_acc: 0.8800\n",
      "Epoch 387/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1989 - acc: 0.9254 - val_loss: 0.2849 - val_acc: 0.8790\n",
      "Epoch 388/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1974 - acc: 0.9269 - val_loss: 0.2835 - val_acc: 0.8809\n",
      "Epoch 389/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2006 - acc: 0.9256 - val_loss: 0.2850 - val_acc: 0.8848\n",
      "Epoch 390/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2017 - acc: 0.9237 - val_loss: 0.2843 - val_acc: 0.8848\n",
      "Epoch 391/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1967 - acc: 0.9283 - val_loss: 0.2811 - val_acc: 0.8838\n",
      "Epoch 392/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2048 - acc: 0.9198 - val_loss: 0.2800 - val_acc: 0.8877\n",
      "Epoch 393/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1887 - acc: 0.9256 - val_loss: 0.2822 - val_acc: 0.8858\n",
      "Epoch 394/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1974 - acc: 0.9240 - val_loss: 0.2794 - val_acc: 0.8877\n",
      "Epoch 395/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1968 - acc: 0.9196 - val_loss: 0.2817 - val_acc: 0.8829\n",
      "Epoch 396/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1948 - acc: 0.9242 - val_loss: 0.2794 - val_acc: 0.8848\n",
      "Epoch 397/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.2000 - acc: 0.9247 - val_loss: 0.2818 - val_acc: 0.8838\n",
      "Epoch 398/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1941 - acc: 0.9254 - val_loss: 0.2796 - val_acc: 0.8848\n",
      "Epoch 399/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1928 - acc: 0.9258 - val_loss: 0.2773 - val_acc: 0.8858\n",
      "Epoch 400/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1984 - acc: 0.9233 - val_loss: 0.2775 - val_acc: 0.8838\n",
      "Epoch 401/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1970 - acc: 0.9244 - val_loss: 0.2759 - val_acc: 0.8867\n",
      "Epoch 402/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1948 - acc: 0.9230 - val_loss: 0.2754 - val_acc: 0.8848\n",
      "Epoch 403/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1913 - acc: 0.9230 - val_loss: 0.2751 - val_acc: 0.8877\n",
      "Epoch 404/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1894 - acc: 0.9286 - val_loss: 0.2769 - val_acc: 0.8838\n",
      "Epoch 405/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1965 - acc: 0.9258 - val_loss: 0.2798 - val_acc: 0.8809\n",
      "Epoch 406/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2034 - acc: 0.9214 - val_loss: 0.2802 - val_acc: 0.8848\n",
      "Epoch 407/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1906 - acc: 0.9295 - val_loss: 0.2851 - val_acc: 0.8809\n",
      "Epoch 408/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1979 - acc: 0.9231 - val_loss: 0.2825 - val_acc: 0.8829\n",
      "Epoch 409/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.2039 - acc: 0.9212 - val_loss: 0.2859 - val_acc: 0.8819\n",
      "Epoch 410/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1955 - acc: 0.9260 - val_loss: 0.2880 - val_acc: 0.8838\n",
      "Epoch 411/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1974 - acc: 0.9212 - val_loss: 0.2859 - val_acc: 0.8858\n",
      "Epoch 412/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1853 - acc: 0.9302 - val_loss: 0.2835 - val_acc: 0.8896\n",
      "Epoch 413/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1935 - acc: 0.9309 - val_loss: 0.2860 - val_acc: 0.8858\n",
      "Epoch 414/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1935 - acc: 0.9237 - val_loss: 0.2928 - val_acc: 0.8848\n",
      "Epoch 415/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1974 - acc: 0.9260 - val_loss: 0.2880 - val_acc: 0.8838\n",
      "Epoch 416/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1926 - acc: 0.9261 - val_loss: 0.2852 - val_acc: 0.8838\n",
      "Epoch 417/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2005 - acc: 0.9207 - val_loss: 0.2842 - val_acc: 0.8829\n",
      "Epoch 418/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1988 - acc: 0.9233 - val_loss: 0.2827 - val_acc: 0.8848\n",
      "Epoch 419/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1922 - acc: 0.9263 - val_loss: 0.2829 - val_acc: 0.8887\n",
      "Epoch 420/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1928 - acc: 0.9263 - val_loss: 0.2840 - val_acc: 0.8858\n",
      "Epoch 421/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1965 - acc: 0.9247 - val_loss: 0.2804 - val_acc: 0.8858\n",
      "Epoch 422/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1940 - acc: 0.9279 - val_loss: 0.2854 - val_acc: 0.8848\n",
      "Epoch 423/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1931 - acc: 0.9240 - val_loss: 0.2844 - val_acc: 0.8858\n",
      "Epoch 424/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1927 - acc: 0.9244 - val_loss: 0.2852 - val_acc: 0.8819\n",
      "Epoch 425/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.1947 - acc: 0.9219 - val_loss: 0.2862 - val_acc: 0.8819\n",
      "Epoch 426/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2003 - acc: 0.9221 - val_loss: 0.2839 - val_acc: 0.8838\n",
      "Epoch 427/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1966 - acc: 0.9235 - val_loss: 0.2856 - val_acc: 0.8790\n",
      "Epoch 428/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.2000 - acc: 0.9226 - val_loss: 0.2856 - val_acc: 0.8790\n",
      "Epoch 429/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1949 - acc: 0.9184 - val_loss: 0.2875 - val_acc: 0.8800\n",
      "Epoch 430/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1952 - acc: 0.9274 - val_loss: 0.2891 - val_acc: 0.8819\n",
      "Epoch 431/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1984 - acc: 0.9299 - val_loss: 0.2841 - val_acc: 0.8809\n",
      "Epoch 432/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1925 - acc: 0.9240 - val_loss: 0.2853 - val_acc: 0.8790\n",
      "Epoch 433/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1890 - acc: 0.9297 - val_loss: 0.2849 - val_acc: 0.8848\n",
      "Epoch 434/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1880 - acc: 0.9286 - val_loss: 0.2815 - val_acc: 0.8829\n",
      "Epoch 435/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1989 - acc: 0.9235 - val_loss: 0.2828 - val_acc: 0.8848\n",
      "Epoch 436/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1880 - acc: 0.9320 - val_loss: 0.2845 - val_acc: 0.8829\n",
      "Epoch 437/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1949 - acc: 0.9269 - val_loss: 0.2860 - val_acc: 0.8829\n",
      "Epoch 438/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1905 - acc: 0.9276 - val_loss: 0.2855 - val_acc: 0.8838\n",
      "Epoch 439/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1924 - acc: 0.9200 - val_loss: 0.2864 - val_acc: 0.8838\n",
      "Epoch 440/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1922 - acc: 0.9281 - val_loss: 0.2863 - val_acc: 0.8761\n",
      "Epoch 441/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2008 - acc: 0.9261 - val_loss: 0.2871 - val_acc: 0.8780\n",
      "Epoch 442/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1944 - acc: 0.9279 - val_loss: 0.2847 - val_acc: 0.8800\n",
      "Epoch 443/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1935 - acc: 0.9281 - val_loss: 0.2868 - val_acc: 0.8790\n",
      "Epoch 444/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.1922 - acc: 0.9244 - val_loss: 0.2883 - val_acc: 0.8790\n",
      "Epoch 445/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1920 - acc: 0.9263 - val_loss: 0.2859 - val_acc: 0.8829\n",
      "Epoch 446/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2015 - acc: 0.9230 - val_loss: 0.2863 - val_acc: 0.8829\n",
      "Epoch 447/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1948 - acc: 0.9272 - val_loss: 0.2878 - val_acc: 0.8819\n",
      "Epoch 448/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.1910 - acc: 0.9276 - val_loss: 0.2863 - val_acc: 0.8800\n",
      "Epoch 449/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1882 - acc: 0.9263 - val_loss: 0.2899 - val_acc: 0.8838\n",
      "Epoch 450/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1976 - acc: 0.9230 - val_loss: 0.2884 - val_acc: 0.8829\n",
      "Epoch 451/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1979 - acc: 0.9251 - val_loss: 0.2877 - val_acc: 0.8819\n",
      "Epoch 452/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1948 - acc: 0.9242 - val_loss: 0.2836 - val_acc: 0.8838\n",
      "Epoch 453/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1967 - acc: 0.9235 - val_loss: 0.2859 - val_acc: 0.8829\n",
      "Epoch 454/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1953 - acc: 0.9270 - val_loss: 0.2844 - val_acc: 0.8819\n",
      "Epoch 455/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1901 - acc: 0.9283 - val_loss: 0.2875 - val_acc: 0.8819\n",
      "Epoch 456/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1911 - acc: 0.9230 - val_loss: 0.2855 - val_acc: 0.8829\n",
      "Epoch 457/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1948 - acc: 0.9297 - val_loss: 0.2867 - val_acc: 0.8829\n",
      "Epoch 458/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1953 - acc: 0.9261 - val_loss: 0.2865 - val_acc: 0.8800\n",
      "Epoch 459/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1955 - acc: 0.9267 - val_loss: 0.2903 - val_acc: 0.8790\n",
      "Epoch 460/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1888 - acc: 0.9274 - val_loss: 0.2887 - val_acc: 0.8819\n",
      "Epoch 461/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1862 - acc: 0.9269 - val_loss: 0.2886 - val_acc: 0.8800\n",
      "Epoch 462/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1912 - acc: 0.9246 - val_loss: 0.2899 - val_acc: 0.8838\n",
      "Epoch 463/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1941 - acc: 0.9244 - val_loss: 0.2895 - val_acc: 0.8809\n",
      "Epoch 464/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1988 - acc: 0.9212 - val_loss: 0.2913 - val_acc: 0.8780\n",
      "Epoch 465/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1896 - acc: 0.9249 - val_loss: 0.2938 - val_acc: 0.8790\n",
      "Epoch 466/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2021 - acc: 0.9253 - val_loss: 0.2919 - val_acc: 0.8809\n",
      "Epoch 467/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1946 - acc: 0.9244 - val_loss: 0.2858 - val_acc: 0.8819\n",
      "Epoch 468/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1937 - acc: 0.9267 - val_loss: 0.2849 - val_acc: 0.8848\n",
      "Epoch 469/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1924 - acc: 0.9281 - val_loss: 0.2874 - val_acc: 0.8887\n",
      "Epoch 470/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1930 - acc: 0.9235 - val_loss: 0.2869 - val_acc: 0.8829\n",
      "Epoch 471/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1884 - acc: 0.9284 - val_loss: 0.2936 - val_acc: 0.8838\n",
      "Epoch 472/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1919 - acc: 0.9242 - val_loss: 0.2953 - val_acc: 0.8848\n",
      "Epoch 473/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1847 - acc: 0.9270 - val_loss: 0.2907 - val_acc: 0.8858\n",
      "Epoch 474/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1916 - acc: 0.9272 - val_loss: 0.2887 - val_acc: 0.8800\n",
      "Epoch 475/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1866 - acc: 0.9293 - val_loss: 0.2896 - val_acc: 0.8819\n",
      "Epoch 476/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1940 - acc: 0.9254 - val_loss: 0.2921 - val_acc: 0.8780\n",
      "Epoch 477/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1909 - acc: 0.9249 - val_loss: 0.2890 - val_acc: 0.8809\n",
      "Epoch 478/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1950 - acc: 0.9237 - val_loss: 0.2897 - val_acc: 0.8877\n",
      "Epoch 479/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1908 - acc: 0.9246 - val_loss: 0.2926 - val_acc: 0.8848\n",
      "Epoch 480/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.2937 - val_acc: 0.8848\n",
      "Epoch 481/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1968 - acc: 0.9256 - val_loss: 0.2926 - val_acc: 0.8858\n",
      "Epoch 482/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1859 - acc: 0.9329 - val_loss: 0.2932 - val_acc: 0.8838\n",
      "Epoch 483/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1868 - acc: 0.9254 - val_loss: 0.2908 - val_acc: 0.8809\n",
      "Epoch 484/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1924 - acc: 0.9256 - val_loss: 0.2904 - val_acc: 0.8829\n",
      "Epoch 485/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1979 - acc: 0.9244 - val_loss: 0.2892 - val_acc: 0.8848\n",
      "Epoch 486/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1902 - acc: 0.9293 - val_loss: 0.2882 - val_acc: 0.8800\n",
      "Epoch 487/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1884 - acc: 0.9242 - val_loss: 0.2864 - val_acc: 0.8858\n",
      "Epoch 488/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1883 - acc: 0.9267 - val_loss: 0.2866 - val_acc: 0.8838\n",
      "Epoch 489/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 85s 5s/step - loss: 0.1925 - acc: 0.9290 - val_loss: 0.2885 - val_acc: 0.8790\n",
      "Epoch 490/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1892 - acc: 0.9336 - val_loss: 0.2866 - val_acc: 0.8829\n",
      "Epoch 491/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1932 - acc: 0.9203 - val_loss: 0.2856 - val_acc: 0.8800\n",
      "Epoch 492/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1837 - acc: 0.9346 - val_loss: 0.2883 - val_acc: 0.8809\n",
      "Epoch 493/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1813 - acc: 0.9366 - val_loss: 0.2898 - val_acc: 0.8800\n",
      "Epoch 494/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1953 - acc: 0.9258 - val_loss: 0.2814 - val_acc: 0.8838\n",
      "Epoch 495/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1889 - acc: 0.9304 - val_loss: 0.2842 - val_acc: 0.8809\n",
      "Epoch 496/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1948 - acc: 0.9226 - val_loss: 0.2833 - val_acc: 0.8819\n",
      "Epoch 497/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1938 - acc: 0.9240 - val_loss: 0.2831 - val_acc: 0.8858\n",
      "Epoch 498/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1859 - acc: 0.9258 - val_loss: 0.2858 - val_acc: 0.8829\n",
      "Epoch 499/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.2015 - acc: 0.9233 - val_loss: 0.2814 - val_acc: 0.8867\n",
      "Epoch 500/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1884 - acc: 0.9309 - val_loss: 0.2812 - val_acc: 0.8867\n",
      "Epoch 501/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1914 - acc: 0.9249 - val_loss: 0.2833 - val_acc: 0.8867\n",
      "Epoch 502/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1908 - acc: 0.9263 - val_loss: 0.2844 - val_acc: 0.8838\n",
      "Epoch 503/1000\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.1837 - acc: 0.9304 - val_loss: 0.2855 - val_acc: 0.8838\n",
      "Epoch 504/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1881 - acc: 0.9293 - val_loss: 0.2852 - val_acc: 0.8809\n",
      "Epoch 505/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1895 - acc: 0.9291 - val_loss: 0.2832 - val_acc: 0.8771\n",
      "Epoch 506/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1888 - acc: 0.9269 - val_loss: 0.2843 - val_acc: 0.8838\n",
      "Epoch 507/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1980 - acc: 0.9277 - val_loss: 0.2837 - val_acc: 0.8848\n",
      "Epoch 508/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1946 - acc: 0.9258 - val_loss: 0.2868 - val_acc: 0.8829\n",
      "Epoch 509/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1847 - acc: 0.9221 - val_loss: 0.2860 - val_acc: 0.8858\n",
      "Epoch 510/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1933 - acc: 0.9258 - val_loss: 0.2880 - val_acc: 0.8809\n",
      "Epoch 511/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1866 - acc: 0.9309 - val_loss: 0.2875 - val_acc: 0.8809\n",
      "Epoch 512/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1917 - acc: 0.9256 - val_loss: 0.2860 - val_acc: 0.8809\n",
      "Epoch 513/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1949 - acc: 0.9246 - val_loss: 0.2828 - val_acc: 0.8838\n",
      "Epoch 514/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.2832 - val_acc: 0.8819\n",
      "Epoch 515/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1952 - acc: 0.9260 - val_loss: 0.2842 - val_acc: 0.8858\n",
      "Epoch 516/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1913 - acc: 0.9254 - val_loss: 0.2836 - val_acc: 0.8858\n",
      "Epoch 517/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1861 - acc: 0.9302 - val_loss: 0.2849 - val_acc: 0.8848\n",
      "Epoch 518/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1889 - acc: 0.9237 - val_loss: 0.2870 - val_acc: 0.8848\n",
      "Epoch 519/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1926 - acc: 0.9217 - val_loss: 0.2825 - val_acc: 0.8809\n",
      "Epoch 520/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1919 - acc: 0.9269 - val_loss: 0.2843 - val_acc: 0.8829\n",
      "Epoch 521/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1901 - acc: 0.9295 - val_loss: 0.2816 - val_acc: 0.8809\n",
      "Epoch 522/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1917 - acc: 0.9276 - val_loss: 0.2799 - val_acc: 0.8838\n",
      "Epoch 523/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1916 - acc: 0.9265 - val_loss: 0.2844 - val_acc: 0.8848\n",
      "Epoch 524/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1954 - acc: 0.9237 - val_loss: 0.2779 - val_acc: 0.8819\n",
      "Epoch 525/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1874 - acc: 0.9260 - val_loss: 0.2790 - val_acc: 0.8819\n",
      "Epoch 526/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1886 - acc: 0.9247 - val_loss: 0.2777 - val_acc: 0.8800\n",
      "Epoch 527/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1860 - acc: 0.9299 - val_loss: 0.2769 - val_acc: 0.8819\n",
      "Epoch 528/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1889 - acc: 0.9279 - val_loss: 0.2809 - val_acc: 0.8838\n",
      "Epoch 529/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1872 - acc: 0.9293 - val_loss: 0.2870 - val_acc: 0.8809\n",
      "Epoch 530/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1821 - acc: 0.9306 - val_loss: 0.2818 - val_acc: 0.8809\n",
      "Epoch 531/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1925 - acc: 0.9297 - val_loss: 0.2794 - val_acc: 0.8819\n",
      "Epoch 532/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1844 - acc: 0.9263 - val_loss: 0.2811 - val_acc: 0.8829\n",
      "Epoch 533/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1855 - acc: 0.9346 - val_loss: 0.2829 - val_acc: 0.8790\n",
      "Epoch 534/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1893 - acc: 0.9279 - val_loss: 0.2846 - val_acc: 0.8829\n",
      "Epoch 535/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1894 - acc: 0.9265 - val_loss: 0.2834 - val_acc: 0.8780\n",
      "Epoch 536/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1827 - acc: 0.9270 - val_loss: 0.2805 - val_acc: 0.8809\n",
      "Epoch 537/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1882 - acc: 0.9247 - val_loss: 0.2833 - val_acc: 0.8819\n",
      "Epoch 538/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1909 - acc: 0.9260 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 539/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1847 - acc: 0.9302 - val_loss: 0.2853 - val_acc: 0.8848\n",
      "Epoch 540/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1862 - acc: 0.9269 - val_loss: 0.2850 - val_acc: 0.8858\n",
      "Epoch 541/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1882 - acc: 0.9313 - val_loss: 0.2808 - val_acc: 0.8819\n",
      "Epoch 542/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1808 - acc: 0.9304 - val_loss: 0.2812 - val_acc: 0.8809\n",
      "Epoch 543/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1912 - acc: 0.9297 - val_loss: 0.2799 - val_acc: 0.8809\n",
      "Epoch 544/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1936 - acc: 0.9283 - val_loss: 0.2792 - val_acc: 0.8800\n",
      "Epoch 545/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1904 - acc: 0.9240 - val_loss: 0.2759 - val_acc: 0.8867\n",
      "Epoch 546/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1839 - acc: 0.9290 - val_loss: 0.2748 - val_acc: 0.8887\n",
      "Epoch 547/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1892 - acc: 0.9246 - val_loss: 0.2783 - val_acc: 0.8800\n",
      "Epoch 548/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1963 - acc: 0.9283 - val_loss: 0.2802 - val_acc: 0.8848\n",
      "Epoch 549/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1923 - acc: 0.9235 - val_loss: 0.2829 - val_acc: 0.8819\n",
      "Epoch 550/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1839 - acc: 0.9288 - val_loss: 0.2827 - val_acc: 0.8848\n",
      "Epoch 551/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1826 - acc: 0.9260 - val_loss: 0.2862 - val_acc: 0.8829\n",
      "Epoch 552/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1786 - acc: 0.9322 - val_loss: 0.2862 - val_acc: 0.8838\n",
      "Epoch 553/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1915 - acc: 0.9258 - val_loss: 0.2820 - val_acc: 0.8838\n",
      "Epoch 554/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1886 - acc: 0.9304 - val_loss: 0.2797 - val_acc: 0.8809\n",
      "Epoch 555/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1871 - acc: 0.9306 - val_loss: 0.2813 - val_acc: 0.8877\n",
      "Epoch 556/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1840 - acc: 0.9329 - val_loss: 0.2829 - val_acc: 0.8819\n",
      "Epoch 557/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1883 - acc: 0.9290 - val_loss: 0.2816 - val_acc: 0.8848\n",
      "Epoch 558/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1833 - acc: 0.9270 - val_loss: 0.2782 - val_acc: 0.8800\n",
      "Epoch 559/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1784 - acc: 0.9316 - val_loss: 0.2803 - val_acc: 0.8790\n",
      "Epoch 560/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1905 - acc: 0.9249 - val_loss: 0.2780 - val_acc: 0.8848\n",
      "Epoch 561/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1901 - acc: 0.9256 - val_loss: 0.2789 - val_acc: 0.8848\n",
      "Epoch 562/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1836 - acc: 0.9313 - val_loss: 0.2777 - val_acc: 0.8829\n",
      "Epoch 563/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1851 - acc: 0.9297 - val_loss: 0.2754 - val_acc: 0.8829\n",
      "Epoch 564/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1807 - acc: 0.9281 - val_loss: 0.2786 - val_acc: 0.8838\n",
      "Epoch 565/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1862 - acc: 0.9295 - val_loss: 0.2762 - val_acc: 0.8819\n",
      "Epoch 566/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1825 - acc: 0.9283 - val_loss: 0.2794 - val_acc: 0.8790\n",
      "Epoch 567/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1836 - acc: 0.9277 - val_loss: 0.2790 - val_acc: 0.8829\n",
      "Epoch 568/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1846 - acc: 0.9281 - val_loss: 0.2810 - val_acc: 0.8848\n",
      "Epoch 569/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1875 - acc: 0.9293 - val_loss: 0.2820 - val_acc: 0.8867\n",
      "Epoch 570/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1858 - acc: 0.9286 - val_loss: 0.2855 - val_acc: 0.8829\n",
      "Epoch 571/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1884 - acc: 0.9302 - val_loss: 0.2792 - val_acc: 0.8829\n",
      "Epoch 572/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1858 - acc: 0.9290 - val_loss: 0.2794 - val_acc: 0.8848\n",
      "Epoch 573/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1844 - acc: 0.9309 - val_loss: 0.2768 - val_acc: 0.8887\n",
      "Epoch 574/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1824 - acc: 0.9261 - val_loss: 0.2769 - val_acc: 0.8838\n",
      "Epoch 575/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1895 - acc: 0.9286 - val_loss: 0.2759 - val_acc: 0.8848\n",
      "Epoch 576/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1860 - acc: 0.9304 - val_loss: 0.2760 - val_acc: 0.8800\n",
      "Epoch 577/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1904 - acc: 0.9281 - val_loss: 0.2776 - val_acc: 0.8790\n",
      "Epoch 578/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1806 - acc: 0.9313 - val_loss: 0.2790 - val_acc: 0.8780\n",
      "Epoch 579/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1890 - acc: 0.9269 - val_loss: 0.2796 - val_acc: 0.8819\n",
      "Epoch 580/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1832 - acc: 0.9304 - val_loss: 0.2786 - val_acc: 0.8809\n",
      "Epoch 581/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1858 - acc: 0.9276 - val_loss: 0.2800 - val_acc: 0.8819\n",
      "Epoch 582/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1798 - acc: 0.9304 - val_loss: 0.2815 - val_acc: 0.8829\n",
      "Epoch 583/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1816 - acc: 0.9350 - val_loss: 0.2785 - val_acc: 0.8819\n",
      "Epoch 584/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.1869 - acc: 0.9279 - val_loss: 0.2784 - val_acc: 0.8896\n",
      "Epoch 585/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1865 - acc: 0.9313 - val_loss: 0.2792 - val_acc: 0.8887\n",
      "Epoch 586/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1869 - acc: 0.9277 - val_loss: 0.2762 - val_acc: 0.8829\n",
      "Epoch 587/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1836 - acc: 0.9320 - val_loss: 0.2796 - val_acc: 0.8838\n",
      "Epoch 588/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1854 - acc: 0.9272 - val_loss: 0.2838 - val_acc: 0.8819\n",
      "Epoch 589/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1869 - acc: 0.9251 - val_loss: 0.2778 - val_acc: 0.8858\n",
      "Epoch 590/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1827 - acc: 0.9309 - val_loss: 0.2778 - val_acc: 0.8829\n",
      "Epoch 591/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1795 - acc: 0.9297 - val_loss: 0.2805 - val_acc: 0.8838\n",
      "Epoch 592/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1951 - acc: 0.9276 - val_loss: 0.2837 - val_acc: 0.8858\n",
      "Epoch 593/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1827 - acc: 0.9304 - val_loss: 0.2809 - val_acc: 0.8819\n",
      "Epoch 594/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1854 - acc: 0.9329 - val_loss: 0.2796 - val_acc: 0.8780\n",
      "Epoch 595/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1795 - acc: 0.9302 - val_loss: 0.2754 - val_acc: 0.8838\n",
      "Epoch 596/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1850 - acc: 0.9320 - val_loss: 0.2779 - val_acc: 0.8838\n",
      "Epoch 597/1000\n",
      "17/17 [==============================] - 88s 5s/step - loss: 0.1845 - acc: 0.9297 - val_loss: 0.2732 - val_acc: 0.8829\n",
      "Epoch 598/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1849 - acc: 0.9290 - val_loss: 0.2767 - val_acc: 0.8838\n",
      "Epoch 599/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1861 - acc: 0.9249 - val_loss: 0.2777 - val_acc: 0.8838\n",
      "Epoch 600/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1818 - acc: 0.9329 - val_loss: 0.2831 - val_acc: 0.8829\n",
      "Epoch 601/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1738 - acc: 0.9364 - val_loss: 0.2775 - val_acc: 0.8819\n",
      "Epoch 602/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1736 - acc: 0.9346 - val_loss: 0.2771 - val_acc: 0.8800\n",
      "Epoch 603/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1906 - acc: 0.9249 - val_loss: 0.2807 - val_acc: 0.8858\n",
      "Epoch 604/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1787 - acc: 0.9339 - val_loss: 0.2805 - val_acc: 0.8809\n",
      "Epoch 605/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1851 - acc: 0.9311 - val_loss: 0.2850 - val_acc: 0.8829\n",
      "Epoch 606/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1825 - acc: 0.9313 - val_loss: 0.2818 - val_acc: 0.8858\n",
      "Epoch 607/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1833 - acc: 0.9309 - val_loss: 0.2773 - val_acc: 0.8829\n",
      "Epoch 608/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1832 - acc: 0.9281 - val_loss: 0.2797 - val_acc: 0.8819\n",
      "Epoch 609/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1860 - acc: 0.9304 - val_loss: 0.2806 - val_acc: 0.8809\n",
      "Epoch 610/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1793 - acc: 0.9364 - val_loss: 0.2824 - val_acc: 0.8829\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 85s 5s/step - loss: 0.1825 - acc: 0.9293 - val_loss: 0.2832 - val_acc: 0.8838\n",
      "Epoch 612/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1729 - acc: 0.9311 - val_loss: 0.2877 - val_acc: 0.8838\n",
      "Epoch 613/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1840 - acc: 0.9332 - val_loss: 0.2831 - val_acc: 0.8887\n",
      "Epoch 614/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1868 - acc: 0.9279 - val_loss: 0.2800 - val_acc: 0.8848\n",
      "Epoch 615/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1775 - acc: 0.9334 - val_loss: 0.2766 - val_acc: 0.8877\n",
      "Epoch 616/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1799 - acc: 0.9300 - val_loss: 0.2732 - val_acc: 0.8867\n",
      "Epoch 617/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1815 - acc: 0.9304 - val_loss: 0.2768 - val_acc: 0.8877\n",
      "Epoch 618/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1818 - acc: 0.9346 - val_loss: 0.2779 - val_acc: 0.8858\n",
      "Epoch 619/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1769 - acc: 0.9341 - val_loss: 0.2831 - val_acc: 0.8829\n",
      "Epoch 620/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1797 - acc: 0.9343 - val_loss: 0.2840 - val_acc: 0.8848\n",
      "Epoch 621/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1833 - acc: 0.9300 - val_loss: 0.2822 - val_acc: 0.8867\n",
      "Epoch 622/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1773 - acc: 0.9350 - val_loss: 0.2788 - val_acc: 0.8867\n",
      "Epoch 623/1000\n",
      "17/17 [==============================] - 87s 5s/step - loss: 0.1830 - acc: 0.9313 - val_loss: 0.2812 - val_acc: 0.8838\n",
      "Epoch 624/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1866 - acc: 0.9290 - val_loss: 0.2787 - val_acc: 0.8838\n",
      "Epoch 625/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1881 - acc: 0.9235 - val_loss: 0.2816 - val_acc: 0.8848\n",
      "Epoch 626/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1797 - acc: 0.9299 - val_loss: 0.2837 - val_acc: 0.8829\n",
      "Epoch 627/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1813 - acc: 0.9286 - val_loss: 0.2856 - val_acc: 0.8848\n",
      "Epoch 628/1000\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1913 - acc: 0.9295 - val_loss: 0.2838 - val_acc: 0.8838\n",
      "Epoch 629/1000\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.1815 - acc: 0.9297 - val_loss: 0.2823 - val_acc: 0.8887\n",
      "Epoch 630/1000\n",
      "17/17 [==============================] - 85s 5s/step - loss: 0.1787 - acc: 0.9339 - val_loss: 0.2786 - val_acc: 0.8867\n",
      "Epoch 631/1000\n",
      " 1/17 [>.............................] - ETA: 1:52 - loss: 0.1621 - acc: 0.9414"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate/10),\n",
    "              metrics=['acc'])\n",
    "\n",
    "checkpoint_dir = os.path.join(work_dir, 'checkpoint/ensemble_finetuning')\n",
    "log_dir = os.path.join(work_dir, 'log/ensemble_finetuning')\n",
    "if not os.path.exists(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "\n",
    "df = get_clinical_data(csv_file)\n",
    "\n",
    "train_file_list = []\n",
    "for path, dirs, files in os.walk(train_dir):\n",
    "    train_file_list += [os.path.join(path, file) for file in files]    \n",
    "\n",
    "validation_file_list = []\n",
    "for path, dirs, files in os.walk(validation_dir):\n",
    "    validation_file_list += [os.path.join(path, file) for file in files]    \n",
    "\n",
    "model_path = os.path.join(checkpoint_dir, '{epoch:02d}-{val_acc:.4f}.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc', period=10)\n",
    "tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=False)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    custom_generator(train_file_list, df, is_train=True, non_image_data=True),\n",
    "    steps_per_epoch=math.ceil(train_set_size/batch_size),\n",
    "    callbacks=[checkpoint, tensorboard],\n",
    "    validation_data=custom_generator(validation_file_list, df, is_train=False, non_image_data=True),\n",
    "    epochs=transfer_learning_epochs,\n",
    "    validation_steps=math.ceil(validation_set_size/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images = 885\n",
      "acc: 83.73%\n",
      "auc=0.924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "df = get_clinical_data(csv_file)\n",
    "\n",
    "test_file_list, img_test, clinical_test, y_test = get_image_data(test_dir, df)\n",
    "#test_file_list = []\n",
    "#for path, dirs, files in os.walk(test_dir):\n",
    "#    test_file_list += [os.path.join(path, file) for file in files]\n",
    "#count = len(test_file_list)\n",
    "\n",
    "img_test = preprocess_input(img_test, is_train=False)\n",
    "y_pred = model.predict([img_test, clinical_test])\n",
    "\n",
    "scores = model.evaluate_generator(custom_generator(test_file_list, df, is_train=False, non_image_data=True), steps=math.ceil(test_set_size/batch_size))\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "print('auc=%0.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, clinical, y, pred in zip(file_list, clinical_test, y_test, y_pred):\n",
    "    print(file, y, pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
