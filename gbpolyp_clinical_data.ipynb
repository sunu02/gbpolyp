{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obsk/anaconda3/envs/naesa1.8/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images = 4137\n",
      "total images = 1033\n",
      "total images = 885\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Merge, Dropout\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '/share/gbpolyp/final_data'\n",
    "work_dir = '/home/obsk/workspace/gbpolyp'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'validation')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "csv_file = os.path.join(data_dir, 'clinical_data.csv')\n",
    "def get_clinical_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['name'] = df['name'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "\n",
    "    d1 = df[df['test']==0]\n",
    "\n",
    "    size_mean = d1['size'].mean()\n",
    "    size_std = d1['size'].std()\n",
    "    df['size'] = df['size'].apply(lambda x: (x - size_mean) / size_std)\n",
    "\n",
    "    age_mean = d1['age'].mean()\n",
    "    age_std = d1['age'].std()\n",
    "    df['age'] = df['age'].apply(lambda x: (x - age_mean) / age_std)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data(dir_name, df):\n",
    "    count = 0\n",
    "    for path, dir, files in os.walk(dir_name):\n",
    "            count += len(files)\n",
    "    print('total images = %d' % count)\n",
    "\n",
    "    clinical_data = np.ndarray((count, 3), dtype=np.float32)\n",
    "    y_data = np.ndarray((count, ), dtype=np.int8)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for path, dir, files in os.walk(dir_name):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(path, file_name)\n",
    "            if os.path.basename(path) == 'neoplastic': y_data[i] = 1\n",
    "            else: y_data[i] = 0\n",
    "            name = os.path.basename(file_path)[:-9]\n",
    "            try:\n",
    "                size = df[df['name']==name].iloc[0]['size']\n",
    "                multiplicity = df[df['name']==name].iloc[0]['multiplicity']\n",
    "                if multiplicity == 1: multiplicity = 0.1\n",
    "                else: multiplicity = -0.1\n",
    "                age = df[df['name']==name].iloc[0]['age']\n",
    "            except IndexError:\n",
    "                print(name)\n",
    "                size = 0\n",
    "                multiplicity = 0\n",
    "                age = 0\n",
    "            clinical_data[i] = (size, multiplicity, age)\n",
    "            i += 1\n",
    "\n",
    "    #x_data = preprocess_input(x_data)\n",
    "    \n",
    "    return clinical_data, y_data\n",
    "\n",
    "df = get_clinical_data(csv_file)\n",
    "\n",
    "clinical_train, y_train = get_data(train_dir, df)\n",
    "clinical_validation, y_validation = get_data(validation_dir, df)\n",
    "clinical_test, y_test = get_data(test_dir, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def get_model(hidden_layer):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu', input_dim=3))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(hidden_layer, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4137 samples, validate on 1033 samples\n",
      "Epoch 1/600\n",
      "4137/4137 [==============================] - 2s 410us/step - loss: 0.4090 - acc: 0.8264 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 2/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4187 - acc: 0.8214 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 3/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8245 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 4/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8269 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 5/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4010 - acc: 0.8296 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 6/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4147 - acc: 0.8267 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 7/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4169 - acc: 0.8252 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 8/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4181 - acc: 0.8245 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 9/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4017 - acc: 0.8262 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 10/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4074 - acc: 0.8274 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 11/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4096 - acc: 0.8264 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 12/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4029 - acc: 0.8308 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 13/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4083 - acc: 0.8269 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 14/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4141 - acc: 0.8260 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 15/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4063 - acc: 0.8291 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 16/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4060 - acc: 0.8298 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 17/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4057 - acc: 0.8255 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 18/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4062 - acc: 0.8301 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 19/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4134 - acc: 0.8272 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 20/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4124 - acc: 0.8238 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 21/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4078 - acc: 0.8349 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 22/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4070 - acc: 0.8233 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 23/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4080 - acc: 0.8264 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 24/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4128 - acc: 0.8274 - val_loss: 0.3285 - val_acc: 0.8674\n",
      "Epoch 25/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4076 - acc: 0.8252 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 26/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4111 - acc: 0.8245 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 27/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8293 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 28/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4046 - acc: 0.8243 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 29/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4127 - acc: 0.8245 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 30/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4145 - acc: 0.8257 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 31/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4028 - acc: 0.8313 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 32/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4144 - acc: 0.8267 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 33/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4115 - acc: 0.8252 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 34/600\n",
      "4137/4137 [==============================] - 0s 72us/step - loss: 0.4094 - acc: 0.8281 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 35/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4118 - acc: 0.8223 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 36/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4092 - acc: 0.8221 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 37/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4209 - acc: 0.8216 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 38/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4083 - acc: 0.8250 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 39/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4092 - acc: 0.8240 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 40/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8267 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 41/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4084 - acc: 0.8233 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 42/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8269 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 43/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8301 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 44/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3976 - acc: 0.8332 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 45/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8243 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 46/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4090 - acc: 0.8298 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 47/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4035 - acc: 0.8310 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 48/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4102 - acc: 0.8252 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 49/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4065 - acc: 0.8281 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 50/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4046 - acc: 0.8303 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 51/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4073 - acc: 0.8277 - val_loss: 0.3284 - val_acc: 0.8674\n",
      "Epoch 52/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4003 - acc: 0.8272 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 53/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4051 - acc: 0.8274 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 54/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4069 - acc: 0.8257 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 55/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4018 - acc: 0.8272 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 56/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4022 - acc: 0.8293 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 57/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4092 - acc: 0.8289 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 58/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4028 - acc: 0.8233 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 59/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4074 - acc: 0.8267 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 60/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4018 - acc: 0.8306 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 61/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4120 - acc: 0.8279 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 62/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4035 - acc: 0.8339 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 63/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4033 - acc: 0.8325 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 64/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4134 - acc: 0.8199 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 65/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4125 - acc: 0.8281 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 66/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8293 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 67/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4110 - acc: 0.8274 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 68/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4025 - acc: 0.8281 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 69/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4110 - acc: 0.8274 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 70/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4070 - acc: 0.8267 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 71/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4101 - acc: 0.8306 - val_loss: 0.3283 - val_acc: 0.8674\n",
      "Epoch 72/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3997 - acc: 0.8327 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 73/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4108 - acc: 0.8262 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 74/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4061 - acc: 0.8255 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 75/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4061 - acc: 0.8286 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 76/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8250 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 77/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4145 - acc: 0.8240 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 78/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4137 - acc: 0.8284 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 79/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4157 - acc: 0.8223 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 80/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4121 - acc: 0.8291 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 81/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4127 - acc: 0.8206 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 82/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8313 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 83/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8296 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 84/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4128 - acc: 0.8226 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 85/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4055 - acc: 0.8277 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 86/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8245 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 87/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4058 - acc: 0.8269 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 88/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4068 - acc: 0.8284 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 89/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4085 - acc: 0.8245 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 90/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4041 - acc: 0.8330 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 91/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4061 - acc: 0.8269 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 92/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3971 - acc: 0.8325 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 93/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8303 - val_loss: 0.3282 - val_acc: 0.8674\n",
      "Epoch 94/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4158 - acc: 0.8197 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 95/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8272 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 96/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4019 - acc: 0.8335 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 97/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4039 - acc: 0.8310 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 98/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4120 - acc: 0.8284 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 99/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4037 - acc: 0.8298 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 100/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4088 - acc: 0.8267 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 101/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4040 - acc: 0.8286 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 102/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4146 - acc: 0.8298 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 103/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4068 - acc: 0.8272 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 104/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4092 - acc: 0.8231 - val_loss: 0.3282 - val_acc: 0.8712\n",
      "Epoch 105/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8252 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 106/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4070 - acc: 0.8289 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 107/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4051 - acc: 0.8296 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 108/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4092 - acc: 0.8250 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 109/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4024 - acc: 0.8260 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 110/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4091 - acc: 0.8262 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 111/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4054 - acc: 0.8221 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 112/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4065 - acc: 0.8291 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 113/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4107 - acc: 0.8281 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 114/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4014 - acc: 0.8318 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 115/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4103 - acc: 0.8284 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 116/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4008 - acc: 0.8293 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 117/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4107 - acc: 0.8289 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 118/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4019 - acc: 0.8301 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 119/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4034 - acc: 0.8315 - val_loss: 0.3281 - val_acc: 0.8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4030 - acc: 0.8351 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 121/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4066 - acc: 0.8279 - val_loss: 0.3281 - val_acc: 0.8712\n",
      "Epoch 122/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4017 - acc: 0.8301 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 123/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4070 - acc: 0.8228 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 124/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4090 - acc: 0.8264 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 125/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4033 - acc: 0.8272 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 126/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4016 - acc: 0.8279 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 127/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4045 - acc: 0.8296 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 128/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8262 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 129/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4026 - acc: 0.8281 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 130/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8248 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 131/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4031 - acc: 0.8284 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 132/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4131 - acc: 0.8187 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 133/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4103 - acc: 0.8185 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 134/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4048 - acc: 0.8335 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 135/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8315 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 136/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4117 - acc: 0.8221 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 137/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8250 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 138/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4147 - acc: 0.8269 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 139/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4019 - acc: 0.8293 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 140/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4013 - acc: 0.8308 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 141/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3952 - acc: 0.8349 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 142/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4015 - acc: 0.8306 - val_loss: 0.3280 - val_acc: 0.8712\n",
      "Epoch 143/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4032 - acc: 0.8298 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 144/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4047 - acc: 0.8260 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 145/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4106 - acc: 0.8269 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 146/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4133 - acc: 0.8219 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 147/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4053 - acc: 0.8330 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 148/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4072 - acc: 0.8293 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 149/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3988 - acc: 0.8351 - val_loss: 0.3280 - val_acc: 0.8761\n",
      "Epoch 150/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4021 - acc: 0.8284 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 151/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3987 - acc: 0.8315 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 152/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4072 - acc: 0.8267 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 153/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3987 - acc: 0.8318 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 154/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4103 - acc: 0.8301 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 155/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4004 - acc: 0.8320 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 156/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4027 - acc: 0.8293 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 157/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4119 - acc: 0.8274 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 158/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4014 - acc: 0.8373 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 159/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4041 - acc: 0.8301 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 160/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4066 - acc: 0.8255 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 161/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4116 - acc: 0.8250 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 162/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4037 - acc: 0.8322 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 163/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8277 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 164/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8284 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 165/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8243 - val_loss: 0.3279 - val_acc: 0.8761\n",
      "Epoch 166/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4024 - acc: 0.8332 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 167/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4009 - acc: 0.8368 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 168/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4057 - acc: 0.8269 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 169/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4118 - acc: 0.8274 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 170/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4005 - acc: 0.8301 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 171/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4132 - acc: 0.8252 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 172/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8255 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 173/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4119 - acc: 0.8209 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 174/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4056 - acc: 0.8286 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 175/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3938 - acc: 0.8356 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 176/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4030 - acc: 0.8303 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 177/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4040 - acc: 0.8332 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 178/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4029 - acc: 0.8289 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 179/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4148 - acc: 0.8255 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 180/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4114 - acc: 0.8277 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 181/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4014 - acc: 0.8320 - val_loss: 0.3278 - val_acc: 0.8790\n",
      "Epoch 182/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4063 - acc: 0.8250 - val_loss: 0.3278 - val_acc: 0.8790\n",
      "Epoch 183/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4008 - acc: 0.8351 - val_loss: 0.3277 - val_acc: 0.8761\n",
      "Epoch 184/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4047 - acc: 0.8284 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 185/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4045 - acc: 0.8235 - val_loss: 0.3278 - val_acc: 0.8761\n",
      "Epoch 186/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4061 - acc: 0.8291 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 187/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4002 - acc: 0.8303 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 188/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4015 - acc: 0.8359 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 189/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4079 - acc: 0.8325 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 190/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3996 - acc: 0.8303 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 191/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3986 - acc: 0.8308 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 192/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8325 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 193/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4077 - acc: 0.8228 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 194/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4098 - acc: 0.8240 - val_loss: 0.3277 - val_acc: 0.8761\n",
      "Epoch 195/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4106 - acc: 0.8226 - val_loss: 0.3277 - val_acc: 0.8761\n",
      "Epoch 196/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4023 - acc: 0.8342 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 197/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4018 - acc: 0.8330 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 198/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4022 - acc: 0.8310 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 199/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8260 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 200/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4110 - acc: 0.8243 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 201/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4058 - acc: 0.8310 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 202/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4111 - acc: 0.8238 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 203/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4164 - acc: 0.8231 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 204/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4106 - acc: 0.8284 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 205/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4073 - acc: 0.8274 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 206/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4078 - acc: 0.8284 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 207/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4121 - acc: 0.8264 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 208/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4027 - acc: 0.8260 - val_loss: 0.3277 - val_acc: 0.8790\n",
      "Epoch 209/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4056 - acc: 0.8315 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 210/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3993 - acc: 0.8291 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 211/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4091 - acc: 0.8245 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 212/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4068 - acc: 0.8315 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 213/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8315 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 214/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4180 - acc: 0.8228 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 215/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4150 - acc: 0.8231 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 216/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4071 - acc: 0.8291 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 217/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4084 - acc: 0.8262 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 218/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4013 - acc: 0.8269 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 219/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4101 - acc: 0.8252 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 220/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4074 - acc: 0.8211 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 221/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4142 - acc: 0.8279 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 222/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4069 - acc: 0.8320 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 223/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4089 - acc: 0.8274 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 224/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4021 - acc: 0.8310 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 225/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4105 - acc: 0.8223 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 226/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4036 - acc: 0.8293 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 227/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4134 - acc: 0.8248 - val_loss: 0.3276 - val_acc: 0.8790\n",
      "Epoch 228/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3994 - acc: 0.8303 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 229/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4083 - acc: 0.8272 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 230/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4046 - acc: 0.8296 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 231/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4041 - acc: 0.8325 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 232/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4076 - acc: 0.8231 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 233/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4084 - acc: 0.8235 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 234/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4047 - acc: 0.8298 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 235/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4061 - acc: 0.8274 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 236/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4076 - acc: 0.8250 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 237/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3937 - acc: 0.8313 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4083 - acc: 0.8281 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 239/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4035 - acc: 0.8322 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 240/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4007 - acc: 0.8313 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 241/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4153 - acc: 0.8192 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 242/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4032 - acc: 0.8327 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 243/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4049 - acc: 0.8281 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 244/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4089 - acc: 0.8274 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 245/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4063 - acc: 0.8264 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 246/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4100 - acc: 0.8284 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 247/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8293 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 248/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4138 - acc: 0.8298 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 249/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4102 - acc: 0.8240 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 250/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4034 - acc: 0.8264 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 251/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4036 - acc: 0.8313 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 252/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8269 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 253/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4046 - acc: 0.8364 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 254/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8264 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 255/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4094 - acc: 0.8291 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 256/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4030 - acc: 0.8320 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 257/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4073 - acc: 0.8245 - val_loss: 0.3275 - val_acc: 0.8790\n",
      "Epoch 258/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4073 - acc: 0.8206 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 259/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4031 - acc: 0.8293 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 260/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4080 - acc: 0.8274 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 261/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4078 - acc: 0.8327 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 262/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4128 - acc: 0.8223 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 263/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4121 - acc: 0.8269 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 264/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4039 - acc: 0.8269 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 265/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4099 - acc: 0.8286 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 266/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4096 - acc: 0.8269 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 267/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4107 - acc: 0.8284 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 268/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4075 - acc: 0.8281 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 269/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4015 - acc: 0.8349 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 270/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8264 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 271/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4024 - acc: 0.8301 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 272/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4133 - acc: 0.8250 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 273/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4017 - acc: 0.8339 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 274/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4011 - acc: 0.8301 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 275/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4068 - acc: 0.8298 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 276/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4145 - acc: 0.8209 - val_loss: 0.3274 - val_acc: 0.8790\n",
      "Epoch 277/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4062 - acc: 0.8303 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 278/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4047 - acc: 0.8327 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 279/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4046 - acc: 0.8296 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 280/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4079 - acc: 0.8245 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 281/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4079 - acc: 0.8238 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 282/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4017 - acc: 0.8337 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 283/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3999 - acc: 0.8281 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 284/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4058 - acc: 0.8310 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 285/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4131 - acc: 0.8257 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 286/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4078 - acc: 0.8361 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 287/600\n",
      "4137/4137 [==============================] - 0s 68us/step - loss: 0.4038 - acc: 0.8260 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 288/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3999 - acc: 0.8320 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 289/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3981 - acc: 0.8373 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 290/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4087 - acc: 0.8298 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 291/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8199 - val_loss: 0.3273 - val_acc: 0.8790\n",
      "Epoch 292/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4136 - acc: 0.8298 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 293/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4066 - acc: 0.8289 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 294/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8313 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 295/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8272 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 296/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3995 - acc: 0.8291 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 297/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4048 - acc: 0.8325 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 298/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8293 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 299/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4105 - acc: 0.8264 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 300/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8281 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 301/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4105 - acc: 0.8274 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 302/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8281 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 303/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4032 - acc: 0.8318 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 304/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4066 - acc: 0.8303 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 305/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4027 - acc: 0.8303 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 306/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8267 - val_loss: 0.3272 - val_acc: 0.8790\n",
      "Epoch 307/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4023 - acc: 0.8252 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 308/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4128 - acc: 0.8233 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 309/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8250 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 310/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4100 - acc: 0.8260 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 311/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8313 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 312/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4051 - acc: 0.8298 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 313/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4072 - acc: 0.8315 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 314/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4105 - acc: 0.8296 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 315/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4099 - acc: 0.8262 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 316/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4062 - acc: 0.8327 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 317/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4023 - acc: 0.8342 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 318/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4035 - acc: 0.8296 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 319/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8313 - val_loss: 0.3271 - val_acc: 0.8790\n",
      "Epoch 320/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3967 - acc: 0.8368 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 321/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4054 - acc: 0.8233 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 322/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3973 - acc: 0.8337 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 323/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4007 - acc: 0.8337 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 324/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4059 - acc: 0.8325 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 325/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4094 - acc: 0.8330 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 326/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4045 - acc: 0.8318 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 327/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4035 - acc: 0.8320 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 328/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4124 - acc: 0.8238 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 329/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4121 - acc: 0.8226 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 330/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4020 - acc: 0.8291 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 331/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4031 - acc: 0.8364 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 332/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4102 - acc: 0.8330 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 333/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8320 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 334/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4042 - acc: 0.8339 - val_loss: 0.3270 - val_acc: 0.8790\n",
      "Epoch 335/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4087 - acc: 0.8235 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 336/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4046 - acc: 0.8330 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 337/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4099 - acc: 0.8291 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 338/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4011 - acc: 0.8274 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 339/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4096 - acc: 0.8260 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 340/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4096 - acc: 0.8320 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 341/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4077 - acc: 0.8291 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 342/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4008 - acc: 0.8325 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 343/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4135 - acc: 0.8252 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 344/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4087 - acc: 0.8279 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 345/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8252 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 346/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4121 - acc: 0.8272 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 347/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4047 - acc: 0.8233 - val_loss: 0.3269 - val_acc: 0.8790\n",
      "Epoch 348/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4023 - acc: 0.8332 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 349/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4087 - acc: 0.8267 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 350/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4016 - acc: 0.8298 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 351/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8335 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 352/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4069 - acc: 0.8260 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 353/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3981 - acc: 0.8306 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 354/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4089 - acc: 0.8332 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 355/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4004 - acc: 0.8342 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4062 - acc: 0.8298 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 357/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4135 - acc: 0.8289 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 358/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4073 - acc: 0.8257 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 359/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4028 - acc: 0.8339 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 360/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3967 - acc: 0.8359 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 361/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3981 - acc: 0.8320 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 362/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4168 - acc: 0.8262 - val_loss: 0.3268 - val_acc: 0.8790\n",
      "Epoch 363/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3991 - acc: 0.8301 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 364/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4105 - acc: 0.8284 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 365/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8298 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 366/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8322 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 367/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4050 - acc: 0.8293 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 368/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8274 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 369/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4125 - acc: 0.8245 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 370/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4122 - acc: 0.8281 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 371/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8289 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 372/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4153 - acc: 0.8223 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 373/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8315 - val_loss: 0.3267 - val_acc: 0.8800\n",
      "Epoch 374/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4012 - acc: 0.8344 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 375/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4120 - acc: 0.8269 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 376/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4186 - acc: 0.8233 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 377/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4066 - acc: 0.8335 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 378/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4010 - acc: 0.8337 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 379/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4027 - acc: 0.8335 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 380/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4036 - acc: 0.8327 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 381/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4078 - acc: 0.8269 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 382/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4091 - acc: 0.8291 - val_loss: 0.3267 - val_acc: 0.8790\n",
      "Epoch 383/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3979 - acc: 0.8371 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 384/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3963 - acc: 0.8407 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 385/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3992 - acc: 0.8310 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 386/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4087 - acc: 0.8279 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 387/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4105 - acc: 0.8281 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 388/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8293 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 389/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8298 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 390/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4100 - acc: 0.8248 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 391/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4024 - acc: 0.8269 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 392/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3969 - acc: 0.8339 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 393/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4020 - acc: 0.8310 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 394/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4102 - acc: 0.8293 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 395/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8216 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 396/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8335 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 397/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4138 - acc: 0.8318 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 398/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4119 - acc: 0.8291 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 399/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4135 - acc: 0.8301 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 400/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4059 - acc: 0.8262 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 401/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4028 - acc: 0.8260 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 402/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4073 - acc: 0.8231 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 403/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4109 - acc: 0.8250 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 404/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4026 - acc: 0.8296 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 405/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4036 - acc: 0.8303 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 406/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8277 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 407/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4017 - acc: 0.8313 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 408/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4113 - acc: 0.8267 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 409/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4048 - acc: 0.8322 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 410/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3929 - acc: 0.8378 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 411/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3977 - acc: 0.8356 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 412/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4079 - acc: 0.8269 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 413/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4056 - acc: 0.8310 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 414/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4149 - acc: 0.8264 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 415/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4109 - acc: 0.8286 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 416/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4064 - acc: 0.8371 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 417/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4079 - acc: 0.8272 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 418/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4162 - acc: 0.8284 - val_loss: 0.3265 - val_acc: 0.8790\n",
      "Epoch 419/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8279 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 420/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4022 - acc: 0.8298 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 421/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8221 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 422/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3902 - acc: 0.8320 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 423/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8289 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 424/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4042 - acc: 0.8293 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 425/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4004 - acc: 0.8313 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 426/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4058 - acc: 0.8322 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 427/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4048 - acc: 0.8330 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 428/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4123 - acc: 0.8308 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 429/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3966 - acc: 0.8347 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 430/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4006 - acc: 0.8318 - val_loss: 0.3264 - val_acc: 0.8790\n",
      "Epoch 431/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4037 - acc: 0.8310 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 432/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4001 - acc: 0.8306 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 433/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4087 - acc: 0.8303 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 434/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4072 - acc: 0.8303 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 435/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4119 - acc: 0.8274 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 436/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4089 - acc: 0.8274 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 437/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4027 - acc: 0.8284 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 438/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4061 - acc: 0.8306 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 439/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4010 - acc: 0.8359 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 440/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4203 - acc: 0.8306 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 441/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4060 - acc: 0.8291 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 442/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3970 - acc: 0.8380 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 443/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8364 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 444/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4031 - acc: 0.8332 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 445/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4095 - acc: 0.8267 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 446/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4001 - acc: 0.8306 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 447/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4081 - acc: 0.8313 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 448/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4093 - acc: 0.8303 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 449/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4012 - acc: 0.8315 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 450/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3977 - acc: 0.8354 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 451/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4092 - acc: 0.8277 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 452/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4137 - acc: 0.8262 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 453/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4111 - acc: 0.8313 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 454/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4120 - acc: 0.8240 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 455/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3971 - acc: 0.8264 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 456/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4048 - acc: 0.8318 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 457/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4065 - acc: 0.8238 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 458/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8318 - val_loss: 0.3263 - val_acc: 0.8780\n",
      "Epoch 459/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4065 - acc: 0.8315 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 460/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4107 - acc: 0.8262 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 461/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4014 - acc: 0.8298 - val_loss: 0.3262 - val_acc: 0.8790\n",
      "Epoch 462/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4084 - acc: 0.8250 - val_loss: 0.3262 - val_acc: 0.8790\n",
      "Epoch 463/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4054 - acc: 0.8274 - val_loss: 0.3262 - val_acc: 0.8790\n",
      "Epoch 464/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8342 - val_loss: 0.3263 - val_acc: 0.8790\n",
      "Epoch 465/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4004 - acc: 0.8293 - val_loss: 0.3262 - val_acc: 0.8790\n",
      "Epoch 466/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8301 - val_loss: 0.3262 - val_acc: 0.8790\n",
      "Epoch 467/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4001 - acc: 0.8289 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 468/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4045 - acc: 0.8368 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 469/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4082 - acc: 0.8306 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 470/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4102 - acc: 0.8221 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 471/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4069 - acc: 0.8281 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 472/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4094 - acc: 0.8291 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 473/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4117 - acc: 0.8252 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8284 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 475/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3986 - acc: 0.8354 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 476/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4080 - acc: 0.8274 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 477/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4087 - acc: 0.8260 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 478/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4031 - acc: 0.8310 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 479/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4101 - acc: 0.8303 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 480/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4047 - acc: 0.8344 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 481/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4035 - acc: 0.8279 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 482/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3989 - acc: 0.8322 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 483/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8269 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 484/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8257 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 485/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4030 - acc: 0.8325 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 486/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3956 - acc: 0.8320 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 487/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4065 - acc: 0.8313 - val_loss: 0.3262 - val_acc: 0.8780\n",
      "Epoch 488/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4063 - acc: 0.8286 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 489/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4053 - acc: 0.8293 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 490/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4028 - acc: 0.8330 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 491/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4039 - acc: 0.8325 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 492/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8262 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 493/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4021 - acc: 0.8332 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 494/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4098 - acc: 0.8274 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 495/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4092 - acc: 0.8231 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 496/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4114 - acc: 0.8264 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 497/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4013 - acc: 0.8332 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 498/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4064 - acc: 0.8327 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 499/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4097 - acc: 0.8262 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 500/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4075 - acc: 0.8262 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 501/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4147 - acc: 0.8274 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 502/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4067 - acc: 0.8293 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 503/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4024 - acc: 0.8310 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 504/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4008 - acc: 0.8318 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 505/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4079 - acc: 0.8279 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 506/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4026 - acc: 0.8359 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 507/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3992 - acc: 0.8301 - val_loss: 0.3261 - val_acc: 0.8780\n",
      "Epoch 508/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4025 - acc: 0.8291 - val_loss: 0.3260 - val_acc: 0.8790\n",
      "Epoch 509/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3985 - acc: 0.8310 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 510/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4004 - acc: 0.8347 - val_loss: 0.3260 - val_acc: 0.8790\n",
      "Epoch 511/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3956 - acc: 0.8337 - val_loss: 0.3260 - val_acc: 0.8790\n",
      "Epoch 512/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4032 - acc: 0.8274 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 513/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4041 - acc: 0.8269 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 514/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4024 - acc: 0.8308 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 515/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4035 - acc: 0.8335 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 516/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3991 - acc: 0.8286 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 517/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8267 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 518/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3988 - acc: 0.8318 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 519/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8310 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 520/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4057 - acc: 0.8262 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 521/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4084 - acc: 0.8313 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 522/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4089 - acc: 0.8298 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 523/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4116 - acc: 0.8281 - val_loss: 0.3260 - val_acc: 0.8780\n",
      "Epoch 524/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4007 - acc: 0.8308 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 525/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4045 - acc: 0.8250 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 526/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4041 - acc: 0.8233 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 527/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4044 - acc: 0.8322 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 528/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4081 - acc: 0.8219 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 529/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4050 - acc: 0.8257 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 530/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4104 - acc: 0.8277 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 531/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4107 - acc: 0.8260 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 532/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4080 - acc: 0.8339 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 533/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4077 - acc: 0.8330 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 534/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8277 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 535/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3964 - acc: 0.8376 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 536/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4100 - acc: 0.8308 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 537/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4099 - acc: 0.8267 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 538/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8279 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 539/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4035 - acc: 0.8332 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 540/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4060 - acc: 0.8303 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 541/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4059 - acc: 0.8298 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 542/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4088 - acc: 0.8303 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 543/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4122 - acc: 0.8260 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 544/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4019 - acc: 0.8376 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 545/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4058 - acc: 0.8322 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 546/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4067 - acc: 0.8332 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 547/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4078 - acc: 0.8298 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 548/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4063 - acc: 0.8335 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 549/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4002 - acc: 0.8284 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 550/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4108 - acc: 0.8260 - val_loss: 0.3259 - val_acc: 0.8780\n",
      "Epoch 551/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4006 - acc: 0.8303 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 552/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4071 - acc: 0.8322 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 553/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4114 - acc: 0.8272 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 554/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4090 - acc: 0.8322 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 555/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4004 - acc: 0.8322 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 556/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4098 - acc: 0.8277 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 557/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4032 - acc: 0.8313 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 558/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4112 - acc: 0.8231 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 559/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4052 - acc: 0.8366 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 560/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4092 - acc: 0.8257 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 561/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3956 - acc: 0.8293 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 562/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4022 - acc: 0.8279 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 563/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3951 - acc: 0.8308 - val_loss: 0.3258 - val_acc: 0.8780\n",
      "Epoch 564/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4084 - acc: 0.8262 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 565/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4012 - acc: 0.8301 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 566/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4033 - acc: 0.8313 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 567/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4086 - acc: 0.8303 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 568/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4005 - acc: 0.8351 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 569/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4049 - acc: 0.8284 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 570/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4011 - acc: 0.8272 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 571/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4043 - acc: 0.8277 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 572/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4110 - acc: 0.8202 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 573/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4031 - acc: 0.8315 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 574/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8296 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 575/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4044 - acc: 0.8315 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 576/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4038 - acc: 0.8277 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 577/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4166 - acc: 0.8310 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 578/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4115 - acc: 0.8306 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 579/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4027 - acc: 0.8313 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 580/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4021 - acc: 0.8337 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 581/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.3980 - acc: 0.8366 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 582/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3969 - acc: 0.8322 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 583/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4060 - acc: 0.8349 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 584/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4080 - acc: 0.8330 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 585/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4126 - acc: 0.8252 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 586/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4122 - acc: 0.8235 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 587/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4120 - acc: 0.8238 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 588/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4153 - acc: 0.8262 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 589/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4029 - acc: 0.8313 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 590/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4085 - acc: 0.8320 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 591/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4018 - acc: 0.8289 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4069 - acc: 0.8308 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 593/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4051 - acc: 0.8298 - val_loss: 0.3257 - val_acc: 0.8780\n",
      "Epoch 594/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4029 - acc: 0.8306 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 595/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4071 - acc: 0.8306 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 596/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4030 - acc: 0.8272 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 597/600\n",
      "4137/4137 [==============================] - 0s 70us/step - loss: 0.4070 - acc: 0.8264 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 598/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.3956 - acc: 0.8354 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 599/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4091 - acc: 0.8320 - val_loss: 0.3256 - val_acc: 0.8780\n",
      "Epoch 600/600\n",
      "4137/4137 [==============================] - 0s 69us/step - loss: 0.4066 - acc: 0.8289 - val_loss: 0.3256 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "#model = get_model(4)\n",
    "model.compile(optimizer=RMSprop(lr=0.00001), loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(clinical_train, y_train, validation_data=(clinical_validation, y_validation), epochs=600, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885/885 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33711980311884043, 0.83728813572792]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(clinical_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smoothly(history):\n",
    "    def smooth_curve(points, factor=0.8):\n",
    "      smoothed_points = []\n",
    "      for point in points:\n",
    "        if smoothed_points:\n",
    "          previous = smoothed_points[-1]\n",
    "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "          smoothed_points.append(point)\n",
    "      return smoothed_points\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "    plt.plot(epochs,\n",
    "             smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4dc40b86a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4da07c2f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_smoothly(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
